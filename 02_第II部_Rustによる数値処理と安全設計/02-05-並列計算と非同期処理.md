[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬4ç« ](02-04-Rustæ•°å€¤è¨ˆç®—ã®åŸºç¤æ§‹æ–‡.md) | [â¡ï¸ ç¬¬6ç« ](../03_ç¬¬IIIéƒ¨_GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€/03-06-GPUã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç†è§£.md)

---

# ç¬¬ 5 ç« ã€€ä¸¦åˆ—è¨ˆç®—ã¨éåŒæœŸå‡¦ç†

ã“ã®ç« ã§ã¯ã€Rustã®ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½ã‚’ç†è§£ã—ã€CPUä¸¦åˆ—è¨ˆç®—ã¨éåŒæœŸI/Oã‚’å®Ÿè£…ã—ã¾ã™ã€‚Pythonã¨ã®æ¯”è¼ƒã‚’é€šã˜ã¦ã€Rustã®ä¸¦è¡Œå‡¦ç†ã®å¼·ã¿ã¨ã€GILï¼ˆGlobal Interpreter Lockï¼‰ãŒãªã„æ©æµã‚’å­¦ã³ã¾ã™ã€‚

**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ã€ã‚¿ã‚¹ã‚¯ä¸¦åˆ—ã€éåŒæœŸå‡¦ç†ã‚’ä½¿ã„åˆ†ã‘ã€ãƒãƒ«ãƒã‚³ã‚¢ãƒ»ãƒãƒ«ãƒGPUç’°å¢ƒã§æœ€å¤§æ€§èƒ½ã‚’å¼•ãå‡ºã—ã¾ã™ã€‚

## 5.1 CPU ä¸¦åˆ—: rayon ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—

**rayon** [^1] ã¯ã€Rustã®ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€ç°¡å˜ã«ãƒãƒ«ãƒã‚³ã‚¢ã‚’æ´»ç”¨ã§ãã¾ã™ã€‚

[^1]: rayon: https://docs.rs/rayon/

### Python ã®ä¸¦åˆ—å‡¦ç†ã¨ã®æ¯”è¼ƒ

| é …ç›® | Python | Rust (rayon) |
|------|--------|--------------|
| ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ | ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ |
| GIL | ã‚ã‚Šï¼ˆä¸¦åˆ—æ€§ã‚’åˆ¶é™ï¼‰ | ãªã— |
| API | `multiprocessing`, `concurrent.futures` | `par_iter()` |
| ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ | ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ï¼ˆé«˜ã„ï¼‰ | ã‚¹ãƒ¬ãƒƒãƒ‰ï¼ˆä½ã„ï¼‰ |
| ãƒ¡ãƒ¢ãƒª | ã‚³ãƒ”ãƒ¼ãŒå¿…è¦ | å…±æœ‰å¯èƒ½ï¼ˆå®‰å…¨ï¼‰ |
| å­¦ç¿’ã‚³ã‚¹ãƒˆ | ä¸­ | ä½ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã®æ‹¡å¼µï¼‰ |

#### Python ã®åˆ¶ç´„ï¼šGIL

```python
# Python: ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¯GILã§åˆ¶é™ã•ã‚Œã‚‹
import threading
import time

def cpu_bound_task(n):
    return sum(i*i for i in range(n))

# âŒ ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¯åŠ¹æœãªã—ï¼ˆGILã®ãŸã‚ï¼‰
threads = [threading.Thread(target=cpu_bound_task, args=(10000000,)) 
           for _ in range(4)]
start = time.time()
for t in threads:
    t.start()
for t in threads:
    t.join()
print(f"Multi-thread: {time.time() - start:.2f}s")  # ~4ç§’

# âœ… ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã¯åŠ¹æœã‚ã‚Š
from multiprocessing import Pool
start = time.time()
with Pool(4) as p:
    p.map(cpu_bound_task, [10000000] * 4)
print(f"Multi-process: {time.time() - start:.2f}s")  # ~1ç§’
```

**GILã®å•é¡Œç‚¹**:
- CPUå¯†é›†ã‚¿ã‚¹ã‚¯ã§ä¸¦åˆ—åŒ–ã®æ©æµã‚’å—ã‘ã‚‰ã‚Œãªã„
- ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
- ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ã®ã‚³ã‚¹ãƒˆ

#### Rust ã®å¼·ã¿ï¼šGIL ãªã—

```rust
use rayon::prelude::*;

fn cpu_bound_task(n: usize) -> usize {
    (0..n).map(|i| i * i).sum()
}

fn main() {
    let tasks = vec![10_000_000; 4];
    
    // âœ… ç°¡å˜ã«ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åŒ–ï¼ˆGILãªã—ï¼‰
    let start = std::time::Instant::now();
    let results: Vec<usize> = tasks.par_iter()
        .map(|&n| cpu_bound_task(n))
        .collect();
    println!("Multi-thread: {:?}", start.elapsed());  // ~0.25ç§’
}
```

### rayon ã®åŸºæœ¬

#### ä¸¦åˆ—ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿

```rust
use rayon::prelude::*;

fn main() {
    let data: Vec<f64> = (0..1_000_000).map(|i| i as f64).collect();
    
    // ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰
    let sum: f64 = data.iter().map(|x| x * x).sum();
    
    // ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ï¼ˆpar_iter ã«å¤‰ãˆã‚‹ã ã‘ï¼‰
    let sum_parallel: f64 = data.par_iter().map(|x| x * x).sum();
    
    assert_eq!(sum, sum_parallel);
}
```

**Python ã¨ã®æ¯”è¼ƒ**:

```python
# Python: NumPyã¯GILã‚’å›é¿ï¼ˆCå®Ÿè£…ï¼‰
import numpy as np

data = np.arange(1_000_000, dtype=np.float64)
result = (data ** 2).sum()  # NumPyãŒå†…éƒ¨ã§ä¸¦åˆ—åŒ–
```

```rust
// Rust: æ˜ç¤ºçš„ãªä¸¦åˆ—åŒ–
let sum_parallel: f64 = data.par_iter().map(|x| x * x).sum();
```

#### ä¸¦åˆ—ã‚½ãƒ¼ãƒˆ

```rust
use rayon::prelude::*;

fn main() {
    let mut data: Vec<i32> = (0..1_000_000).rev().collect();
    
    // ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰
    data.sort();
    
    // ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰
    data.par_sort();  // rayonã®ã‚½ãƒ¼ãƒˆã¯ä¸¦åˆ—åŒ–æ¸ˆã¿
}
```

#### ã‚«ã‚¹ã‚¿ãƒ ä¸¦åˆ—å‡¦ç†

```rust
use rayon::prelude::*;
use ndarray::Array2;

// è¡Œåˆ—ã®å„è¡Œã‚’ä¸¦åˆ—å‡¦ç†
fn process_rows_parallel(matrix: &Array2<f64>) -> Vec<f64> {
    (0..matrix.nrows())
        .into_par_iter()
        .map(|i| {
            let row = matrix.row(i);
            row.iter().map(|&x| x * x).sum()
        })
        .collect()
}

fn main() {
    let matrix = Array2::from_shape_fn((1000, 1000), |(i, j)| (i + j) as f64);
    let result = process_rows_parallel(&matrix);
    println!("Processed {} rows", result.len());
}
```

### ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°

rayonã¯**ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°**ã«ã‚ˆã‚Šã€è² è·ã‚’è‡ªå‹•çš„ã«åˆ†æ•£ã—ã¾ã™ï¼š

```rust
use rayon::prelude::*;

fn expensive_computation(n: usize) -> usize {
    // è² è·ãŒä¸å‡ä¸€
    std::thread::sleep(std::time::Duration::from_millis(n as u64));
    n * n
}

fn main() {
    let tasks = vec![100, 10, 200, 50, 150];
    
    // ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãŒè‡ªå‹•çš„ã«è² è·åˆ†æ•£
    let results: Vec<usize> = tasks.par_iter()
        .map(|&n| expensive_computation(n))
        .collect();
}
```

### æ€§èƒ½æ¯”è¼ƒ

**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**ï¼ˆ100ä¸‡è¦ç´ ã®é…åˆ—å‡¦ç†ï¼‰:

| å®Ÿè£… | æ™‚é–“ | ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ— |
|------|------|--------------|
| Pythonï¼ˆãƒ«ãƒ¼ãƒ—ï¼‰ | 850 ms | 1x |
| Pythonï¼ˆNumPyï¼‰ | 25 ms | 34x |
| Rustï¼ˆã‚·ãƒ³ã‚°ãƒ«ï¼‰ | 15 ms | 57x |
| Rustï¼ˆrayon, 8ã‚³ã‚¢ï¼‰ | 2.5 ms | 340x |

## 5.2 éåŒæœŸ I/O ã¨è¨ˆç®—ã®åˆ†é›¢

Rustã®**async/await**ã¯ã€I/Oå¾…ã¡æ™‚é–“ã‚’æœ‰åŠ¹æ´»ç”¨ã—ã¾ã™ã€‚Python ã® `asyncio` ã¨æ¯”è¼ƒã—ãªãŒã‚‰è§£èª¬ã—ã¾ã™ã€‚

### Python ã® asyncio ã¨ã®æ¯”è¼ƒ

| é …ç›® | Python (asyncio) | Rust (tokio) |
|------|-----------------|--------------|
| ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  | ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ | ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰å¯¾å¿œ |
| æ§‹æ–‡ | `async def`, `await` | `async fn`, `.await` |
| ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ  | æˆç†Ÿ | æ€¥é€Ÿã«æˆé•·ä¸­ |
| æ€§èƒ½ | ä¸­ | é«˜ |
| å‹å®‰å…¨æ€§ | å‹•çš„ | é™çš„ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ãƒã‚§ãƒƒã‚¯ï¼‰ |

#### Python ã® asyncio

```python
import asyncio
import aiohttp

async def fetch_url(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    urls = ['http://example.com'] * 10
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
    print(f"Fetched {len(results)} pages")

asyncio.run(main())
```

#### Rust ã® async/await

```rust
use tokio;
use reqwest;

async fn fetch_url(url: &str) -> Result<String, reqwest::Error> {
    let body = reqwest::get(url).await?.text().await?;
    Ok(body)
}

#[tokio::main]
async fn main() {
    let urls = vec!["http://example.com"; 10];
    
    let tasks: Vec<_> = urls.iter()
        .map(|url| fetch_url(url))
        .collect();
    
    let results = futures::future::join_all(tasks).await;
    println!("Fetched {} pages", results.len());
}
```

### éåŒæœŸã¨GPUè¨ˆç®—ã®çµ„ã¿åˆã‚ã›

GPUè¨ˆç®—ã¯éåŒæœŸI/Oã¨ç›¸æ€§ãŒè‰¯ã„ï¼š

```rust
use tokio;
use std::sync::Arc;

struct GpuContext {
    // GPU ãƒªã‚½ãƒ¼ã‚¹
}

async fn gpu_inference(ctx: Arc<GpuContext>, data: Vec<f32>) -> Vec<f32> {
    // GPUè¨ˆç®—ã‚’éåŒæœŸã§å®Ÿè¡Œ
    tokio::task::spawn_blocking(move || {
        // å®Ÿéš›ã®GPUè¨ˆç®—ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
        gpu_compute(&ctx, &data)
    }).await.unwrap()
}

async fn process_batch(ctx: Arc<GpuContext>, batch: Vec<Vec<f32>>) {
    let tasks: Vec<_> = batch.into_iter()
        .map(|data| gpu_inference(ctx.clone(), data))
        .collect();
    
    let results = futures::future::join_all(tasks).await;
    // çµæœã‚’å‡¦ç†
}

fn gpu_compute(ctx: &GpuContext, data: &[f32]) -> Vec<f32> {
    // GPUè¨ˆç®—ã®å®Ÿè£…
    data.iter().map(|x| x * 2.0).collect()
}

#[tokio::main]
async fn main() {
    let ctx = Arc::new(GpuContext {});
    let batch = vec![vec![1.0; 100]; 10];
    process_batch(ctx, batch).await;
}
```

### è¨ˆç®—ã¨I/Oã®åˆ†é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³

```rust
use tokio;
use tokio::sync::mpsc;

async fn data_loader(tx: mpsc::Sender<Vec<f32>>) {
    // I/O: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    for i in 0..100 {
        let data = load_data_from_disk(i).await;
        tx.send(data).await.unwrap();
    }
}

async fn model_inference(mut rx: mpsc::Receiver<Vec<f32>>) {
    // è¨ˆç®—: GPUã§æ¨è«–
    while let Some(data) = rx.recv().await {
        let result = perform_inference(data).await;
        // çµæœã‚’ä¿å­˜
    }
}

#[tokio::main]
async fn main() {
    let (tx, rx) = mpsc::channel(10);  // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º10
    
    // ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã¨æ¨è«–ã‚’ä¸¦è¡Œå®Ÿè¡Œ
    tokio::join!(
        data_loader(tx),
        model_inference(rx)
    );
}

async fn load_data_from_disk(i: usize) -> Vec<f32> {
    // ãƒ•ã‚¡ã‚¤ãƒ«I/O
    tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
    vec![i as f32; 100]
}

async fn perform_inference(data: Vec<f32>) -> Vec<f32> {
    // GPUæ¨è«–
    tokio::task::spawn_blocking(move || {
        std::thread::sleep(std::time::Duration::from_millis(50));
        data
    }).await.unwrap()
}
```

## 5.3 ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¨ã‚¢ãƒ­ã‚±ãƒ¼ã‚¿æœ€é©åŒ–

### Python ã¨ã®æ¯”è¼ƒï¼šãƒ¡ãƒ¢ãƒªç®¡ç†

| é …ç›® | Python | Rust |
|------|--------|------|
| GC | å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆ + GC | ãªã—ï¼ˆæ‰€æœ‰æ¨©ï¼‰ |
| ã‚¢ãƒ­ã‚±ãƒ¼ã‚¿ | çµ„ã¿è¾¼ã¿ï¼ˆå¤‰æ›´ä¸å¯ï¼‰ | ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ |
| ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ­ãƒ¼ã‚«ãƒ« | `threading.local` | `thread_local!` |
| ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ« | å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª | æ¨™æº–ã‚µãƒãƒ¼ãƒˆ |

### ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ­ã‚±ãƒ¼ã‚¿

```rust
use std::alloc::{GlobalAlloc, Layout, System};
use std::sync::atomic::{AtomicUsize, Ordering};

struct CountingAllocator;

static ALLOCATED: AtomicUsize = AtomicUsize::new(0);

unsafe impl GlobalAlloc for CountingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let ret = System.alloc(layout);
        if !ret.is_null() {
            ALLOCATED.fetch_add(layout.size(), Ordering::SeqCst);
        }
        ret
    }

    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        System.dealloc(ptr, layout);
        ALLOCATED.fetch_sub(layout.size(), Ordering::SeqCst);
    }
}

#[global_allocator]
static GLOBAL: CountingAllocator = CountingAllocator;

fn main() {
    let v = vec![1, 2, 3, 4, 5];
    println!("Allocated: {} bytes", ALLOCATED.load(Ordering::SeqCst));
}
```

### ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«

```rust
use rayon::ThreadPoolBuilder;

fn main() {
    // ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«
    let pool = ThreadPoolBuilder::new()
        .num_threads(8)
        .stack_size(4 * 1024 * 1024)  // 4MB ã‚¹ã‚¿ãƒƒã‚¯
        .build()
        .unwrap();
    
    pool.install(|| {
        // ã“ã®ã‚¹ã‚³ãƒ¼ãƒ—å†…ã®ä¸¦åˆ—å‡¦ç†ã¯
        // ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¼ãƒ«ã‚’ä½¿ç”¨
        (0..1000).into_par_iter().for_each(|i| {
            // å‡¦ç†
        });
    });
}
```

**Python ã¨ã®æ¯”è¼ƒ**:

```python
# Python: concurrent.futures
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=8) as executor:
    results = executor.map(lambda x: x * x, range(1000))
```

## 5.4 ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§ã‚’ä¿ã¤ã‚¹ãƒ¬ãƒƒãƒ‰é€šä¿¡è¨­è¨ˆ

Rustã®å‹ã‚·ã‚¹ãƒ†ãƒ ã¯ã€**ãƒ‡ãƒ¼ã‚¿ç«¶åˆã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«é˜²æ­¢**ã—ã¾ã™ã€‚

### Python ã¨ã®æ¯”è¼ƒï¼šã‚¹ãƒ¬ãƒƒãƒ‰å®‰å…¨æ€§

| æ¦‚å¿µ | Python | Rust |
|------|--------|------|
| ãƒ‡ãƒ¼ã‚¿ç«¶åˆ | ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼ | ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ |
| ãƒ­ãƒƒã‚¯ | `threading.Lock` | `Mutex<T>` |
| æ¡ä»¶å¤‰æ•° | `threading.Condition` | `Condvar` |
| åŸå­æ“ä½œ | ãªã—ï¼ˆGILä¾å­˜ï¼‰ | `AtomicUsize` ç­‰ |
| ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚° | `queue.Queue` | `mpsc::channel` |

#### Python ã®ãƒ‡ãƒ¼ã‚¿ç«¶åˆ

```python
# Python: ãƒ‡ãƒ¼ã‚¿ç«¶åˆï¼ˆGILã§å¶ç„¶é˜²ãŒã‚Œã‚‹ï¼‰
import threading

counter = 0

def increment():
    global counter
    for _ in range(100000):
        counter += 1  # åŸå­æ“ä½œã§ã¯ãªã„

threads = [threading.Thread(target=increment) for _ in range(10)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(counter)  # 1000000æœªæº€ã®å¯èƒ½æ€§ï¼ˆGILã§ãŸã¾ãŸã¾é˜²ãŒã‚Œã‚‹ã“ã¨ã‚‚ï¼‰
```

#### Rust ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ãƒã‚§ãƒƒã‚¯

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // âŒ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ç«¶åˆã‚’æ¤œå‡º
    // let mut counter = 0;
    // let handle = thread::spawn(|| {
    //     counter += 1;  // ã‚¨ãƒ©ãƒ¼ï¼æ‰€æœ‰æ¨©é•å
    // });
    
    // âœ… æ­£ã—ã„å®Ÿè£…: Mutex ã§ä¿è­·
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];
    
    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            for _ in 0..100000 {
                let mut num = counter.lock().unwrap();
                *num += 1;
            }
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("Result: {}", *counter.lock().unwrap());  // å¿…ãš 1000000
}
```

### Send ã¨ Sync ãƒˆãƒ¬ã‚¤ãƒˆ

Rustã®ä¸¦è¡Œå®‰å…¨æ€§ã¯ã€**Send** ã¨ **Sync** ãƒˆãƒ¬ã‚¤ãƒˆã§è¡¨ç¾ã•ã‚Œã¾ã™ï¼š

| ãƒˆãƒ¬ã‚¤ãƒˆ | æ„å‘³ | ä¾‹ |
|---------|------|-----|
| `Send` | ä»–ã‚¹ãƒ¬ãƒƒãƒ‰ã«æ‰€æœ‰æ¨©ã‚’ç§»å‹•å¯èƒ½ | `Vec<T>`, `String` |
| `Sync` | è¤‡æ•°ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰åŒæ™‚å‚ç…§å¯èƒ½ | `Arc<T>`, `&T` |
| `!Send` | ã‚¹ãƒ¬ãƒƒãƒ‰é–“ç§»å‹•ä¸å¯ | `Rc<T>`, ç”Ÿãƒã‚¤ãƒ³ã‚¿ |
| `!Sync` | å…±æœ‰å‚ç…§ä¸å¯ | `Cell<T>`, `RefCell<T>` |

```rust
use std::sync::Arc;
use std::thread;

fn main() {
    // Arc<T> ã¯ Send + Sync
    let data = Arc::new(vec![1, 2, 3]);
    let handle = thread::spawn(move || {
        println!("{:?}", data);
    });
    handle.join().unwrap();
    
    // âŒ Rc<T> ã¯ !Send ãªã®ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼
    // use std::rc::Rc;
    // let data = Rc::new(vec![1, 2, 3]);
    // thread::spawn(move || {
    //     println!("{:?}", data);  // ã‚¨ãƒ©ãƒ¼ï¼
    // });
}
```

## 5.5 ãƒãƒ£ãƒãƒ«ã¨å…±æœ‰çŠ¶æ…‹ã®ä½¿ã„åˆ†ã‘

### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚° vs å…±æœ‰ãƒ¡ãƒ¢ãƒª

| ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | Python | Rust | é©ã—ãŸç”¨é€” |
|-----------|--------|------|----------|
| **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°** | `queue.Queue` | `mpsc::channel` | ç–çµåˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç† |
| **å…±æœ‰ãƒ¡ãƒ¢ãƒª** | `threading.Lock` | `Arc<Mutex<T>>` | å¯†çµåˆã€é »ç¹ãªã‚¢ã‚¯ã‚»ã‚¹ |

### mpsc ãƒãƒ£ãƒãƒ«

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();
    
    // é€ä¿¡å´
    thread::spawn(move || {
        let vals = vec!["hello", "from", "the", "thread"];
        for val in vals {
            tx.send(val).unwrap();
            thread::sleep(Duration::from_millis(100));
        }
    });
    
    // å—ä¿¡å´
    for received in rx {
        println!("Got: {}", received);
    }
}
```

**Python ã¨ã®æ¯”è¼ƒ**:

```python
# Python
import queue
import threading
import time

q = queue.Queue()

def sender():
    for val in ["hello", "from", "the", "thread"]:
        q.put(val)
        time.sleep(0.1)

thread = threading.Thread(target=sender)
thread.start()

while not q.empty() or thread.is_alive():
    try:
        item = q.get(timeout=0.2)
        print(f"Got: {item}")
    except queue.Empty:
        pass
```

### Producer-Consumer ãƒ‘ã‚¿ãƒ¼ãƒ³

```rust
use std::sync::{Arc, Mutex};
use std::sync::mpsc;
use std::thread;

fn producer_consumer_example() {
    let (tx, rx) = mpsc::channel();
    
    // Producer
    for i in 0..5 {
        let tx = tx.clone();
        thread::spawn(move || {
            for j in 0..10 {
                tx.send(i * 10 + j).unwrap();
            }
        });
    }
    drop(tx);  // å…ƒã®txã‚’ãƒ‰ãƒ­ãƒƒãƒ—
    
    // Consumer
    let handle = thread::spawn(move || {
        let mut sum = 0;
        for received in rx {
            sum += received;
        }
        sum
    });
    
    let result = handle.join().unwrap();
    println!("Sum: {}", result);
}
```

### æ€§èƒ½æ¯”è¼ƒã¨é¸æŠæŒ‡é‡

**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**ï¼ˆ100ä¸‡å›ã®ãƒ‡ãƒ¼ã‚¿è»¢é€ï¼‰:

| å®Ÿè£… | æ™‚é–“ | å‚™è€ƒ |
|------|------|------|
| Python `queue.Queue` | 850 ms | GIL + ãƒ­ãƒƒã‚¯ |
| Python `multiprocessing.Queue` | 3200 ms | ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ |
| Rust `mpsc::channel` | 120 ms | ãƒ­ãƒƒã‚¯ãƒ•ãƒªãƒ¼ |
| Rust `Arc<Mutex<Vec<T>>>` | 95 ms | å…±æœ‰ãƒ¡ãƒ¢ãƒª |
| Rust `crossbeam::channel` | 80 ms | æœ€é©åŒ–ç‰ˆ |

**é¸æŠæŒ‡é‡**:

```
ãƒ‡ãƒ¼ã‚¿å…±æœ‰ãŒå¿…è¦ï¼Ÿ
  â†’ Yes â†’ é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼Ÿ
      â†’ Yes â†’ Arc<Mutex<T>> ã¾ãŸã¯ Arc<RwLock<T>>
      â†’ No â†’ mpsc::channel
  â†’ No â†’ æ‰€æœ‰æ¨©ã‚’ç§»å‹•ï¼ˆmoveï¼‰
```

### å®Ÿè·µä¾‹ï¼šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†

**ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹é€ ã®å¯è¦–åŒ–**:

```mermaid
graph LR
    subgraph Stage1[Stage 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿]
        R1[Read] --> Q1[Queue 1]
    end
    subgraph Stage2[Stage 2: å‡¦ç†]
        Q1 --> P1[Process *2] --> Q2[Queue 2]
    end
    subgraph Stage3[Stage 3: ã•ã‚‰ã«å‡¦ç†]
        Q2 --> P2[Process +1] --> Q3[Queue 3]
    end
    Q3 --> OUT[çµæœ]
    
    style R1 fill:#e1f5ff
    style P1 fill:#ffe1f5
    style P2 fill:#ffe1f5
    style OUT fill:#e1ffe1
```

```rust
use std::sync::mpsc;
use std::thread;

fn pipeline_example() {
    let (tx1, rx1) = mpsc::channel();
    let (tx2, rx2) = mpsc::channel();
    let (tx3, rx3) = mpsc::channel();
    
    // Stage 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    thread::spawn(move || {
        for i in 0..100 {
            tx1.send(i).unwrap();
        }
    });
    
    // Stage 2: å‡¦ç†
    thread::spawn(move || {
        for val in rx1 {
            let processed = val * 2;
            tx2.send(processed).unwrap();
        }
    });
    
    // Stage 3: ã•ã‚‰ã«å‡¦ç†
    thread::spawn(move || {
        for val in rx2 {
            let processed = val + 1;
            tx3.send(processed).unwrap();
        }
    });
    
    // çµæœåé›†
    let results: Vec<i32> = rx3.iter().collect();
    println!("Processed {} items", results.len());
}

fn main() {
    pipeline_example();
}
```

**Python ç‰ˆ**:

```python
import queue
import threading

def pipeline_example():
    q1 = queue.Queue()
    q2 = queue.Queue()
    q3 = queue.Queue()
    
    def stage1():
        for i in range(100):
            q1.put(i)
        q1.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
    
    def stage2():
        while True:
            val = q1.get()
            if val is None:
                break
            q2.put(val * 2)
        q2.put(None)
    
    def stage3():
        while True:
            val = q2.get()
            if val is None:
                break
            q3.put(val + 1)
        q3.put(None)
    
    threads = [
        threading.Thread(target=stage1),
        threading.Thread(target=stage2),
        threading.Thread(target=stage3),
    ]
    
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    
    results = []
    while not q3.empty():
        val = q3.get()
        if val is not None:
            results.append(val)
    
    print(f"Processed {len(results)} items")
```

### ã¾ã¨ã‚ï¼šRust vs Python ä¸¦è¡Œå‡¦ç†

| é …ç›® | Python ã®å¼·ã¿ | Rust ã®å¼·ã¿ |
|------|-------------|------------|
| **å­¦ç¿’æ›²ç·š** | ç·©ã‚„ã‹ | æ€¥ï¼ˆæ‰€æœ‰æ¨©ï¼‰ |
| **é–‹ç™ºé€Ÿåº¦** | é€Ÿã„ | ä¸­ç¨‹åº¦ |
| **å®Ÿè¡Œé€Ÿåº¦** | ä¸­ï¼ˆGILåˆ¶ç´„ï¼‰ | é«˜ï¼ˆGILãªã—ï¼‰ |
| **ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§** | ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  | ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ |
| **ãƒ‡ãƒ¼ã‚¿ç«¶åˆ** | å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ | ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ |
| **I/Oä¸¦è¡Œæ€§** | å„ªç§€ï¼ˆasyncioï¼‰ | å„ªç§€ï¼ˆtokioï¼‰ |
| **CPUä¸¦åˆ—æ€§** | é™å®šçš„ï¼ˆGILï¼‰ | å„ªç§€ï¼ˆrayonï¼‰ |
| **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ** | æˆç†Ÿ | æ€¥æˆé•·ä¸­ |

**æ¨å¥¨ã•ã‚Œã‚‹ä½¿ã„åˆ†ã‘**:
- **ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒ»ç ”ç©¶**: Pythonï¼ˆé–‹ç™ºé€Ÿåº¦å„ªå…ˆï¼‰
- **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ»é«˜æ€§èƒ½**: Rustï¼ˆæ€§èƒ½ãƒ»å®‰å…¨æ€§å„ªå…ˆï¼‰
- **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰**: Pythonã§ãƒ­ã‚¸ãƒƒã‚¯Rustã§è¨ˆç®—ã‚«ãƒ¼ãƒãƒ«ï¼ˆPyO3çµŒç”±ï¼‰

æ¬¡ç« ï¼ˆç¬¬IIIéƒ¨ï¼‰ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã CPUä¸¦åˆ—å‡¦ç†ã®çŸ¥è­˜ã‚’åŸºã«ã€GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ä¸–ç•Œã«è¸ã¿è¾¼ã¿ã¾ã™ã€‚
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬4ç« : Rustæ•°å€¤è¨ˆç®—ã®åŸºç¤æ§‹æ–‡](02-04-Rustæ•°å€¤è¨ˆç®—ã®åŸºç¤æ§‹æ–‡.md) | [â¡ï¸ ç¬¬6ç« : GPUã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç†è§£](../03_ç¬¬IIIéƒ¨_GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€/03-06-GPUã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç†è§£.md)