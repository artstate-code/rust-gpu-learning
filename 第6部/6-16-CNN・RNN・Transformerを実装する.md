# 第 16 章　CNN・RNN・Transformer を実装する

この章では、代表的なニューラルネットワークアーキテクチャをRustで実装します。

## 16.1 Convolution 層とバックプロパゲーション

（執筆中）

## 16.2 Im2Col / Winograd / FFT による畳み込み最適化

（執筆中）

## 16.3 LSTM/GRU のメモリアクセス最適化

（執筆中）

## 16.4 Transformer の注意機構を Rust で構築

（執筆中）

## 16.5 Flash Attention / Multi-Query Attention の実装

（執筆中）

## 16.6 推論速度・メモリ比較

（執筆中）
