[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬21ç« ](../06_ç¬¬VIéƒ¨_ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã¨å®Ÿè·µ/06-21-å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ.md)

---

# ç¬¬ 19 ç« ã€€Rust ã§ã® ML ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®é€²åŒ–

ã“ã®ç« ã§ã¯ã€Rustæ©Ÿæ¢°å­¦ç¿’ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®ç¾çŠ¶ã‚’ä¿¯ç°ã—ã€ä»Šå¾Œã®å±•æœ›ã‚’ç¤ºã—ã¾ã™ã€‚ä¸»è¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ç‰¹å¾´ã€Python/TensorFlowã¨ã®é–¢ä¿‚ã€RustãŒæ‹…ã†ã¹ãå½¹å‰²ã«ã¤ã„ã¦è­°è«–ã—ã¾ã™ã€‚

**ç›®çš„**: Rustã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®å…¨ä½“åƒã‚’ç†è§£ã—ã€ä»Šå¾Œã®å­¦ç¿’æ–¹å‘æ€§ã‚’å®šã‚ã¾ã™ã€‚

## 19.1 Burn / Candle / Linfa / dfdx ã®æ–¹å‘æ€§

Rustæ©Ÿæ¢°å­¦ç¿’ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¤‡æ•°ã®ç‹¬ç«‹ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒä¸¦è¡Œã—ã¦ç™ºå±•ã—ã¦ã„ã¾ã™ [^1]ã€‚

[^1]: Awesome Rust Machine Learning: https://github.com/vaaaaanquish/Awesome-Rust-MachineLearning

### ä¸»è¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ¯”è¼ƒ

|| ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | é–‹ç™ºå…ƒ | è¨­è¨ˆæ€æƒ³ | ä¸»ãªç”¨é€” | æˆç†Ÿåº¦ |
||------------|--------|---------|---------|--------|
|| **Burn** | ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ | PyTorché¢¨API | å­¦ç¿’ãƒ»æ¨è«– | ä¸­ï¼ˆæ´»ç™ºï¼‰ |
|| **Candle** | HuggingFace | è»½é‡ãƒ»æ¨è«–ç‰¹åŒ– | æ¨è«– | ä¸­ï¼ˆæˆé•·ä¸­ï¼‰ |
|| **Linfa** | Rust-ML | scikit-learné¢¨ | ä¼çµ±çš„ML | ä¸­ |
|| **dfdx** | ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ | è‡ªå‹•å¾®åˆ†ç‰¹åŒ– | ç ”ç©¶ | ä½ï¼ˆå®Ÿé¨“çš„ï¼‰ |
|| **tch-rs** | Laurent Mazare | LibTorch ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚° | å­¦ç¿’ãƒ»æ¨è«– | é«˜ï¼ˆå®‰å®šï¼‰ |
|| **tract** | Sonos | ONNXæ¨è«– | æ¨è«–å°‚ç”¨ | é«˜ï¼ˆå•†ç”¨å®Ÿç¸¾ï¼‰ |

### Burnï¼šRust-Native ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°

**Burn** [^2] ã¯ã€Rustã§æ›¸ã‹ã‚ŒãŸæœ¬æ ¼çš„ãªãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚

[^2]: Burn: https://github.com/tracel-ai/burn

**ç‰¹å¾´**:

- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰éä¾å­˜**: WGPUã€CUDAã€CPUã€WebAssemblyã«å¯¾å¿œ
- **å‹å®‰å…¨**: Rustã®å‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨
- **è‡ªå‹•å¾®åˆ†**: ãƒ†ãƒ¼ãƒ—ãƒ™ãƒ¼ã‚¹è‡ªå‹•å¾®åˆ†
- **ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ**: ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå®¹æ˜“

**åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹**:

```rust
use burn::{
    config::Config,
    module::Module,
    nn::{Linear, LinearConfig, Relu},
    tensor::{backend::Backend, Tensor},
};

#[derive(Module, Debug)]
pub struct Model<B: Backend> {
    linear1: Linear<B>,
    linear2: Linear<B>,
    activation: Relu,
}

impl<B: Backend> Model<B> {
    pub fn forward(&self, input: Tensor<B, 2>) -> Tensor<B, 2> {
        let x = self.linear1.forward(input);
        let x = self.activation.forward(x);
        self.linear2.forward(x)
    }
}

// ä½¿ç”¨ä¾‹
fn main() {
    use burn::backend::Wgpu;
    
    let device = Default::default();
    let model: Model<Wgpu> = Model {
        linear1: LinearConfig::new(10, 20).init(&device),
        linear2: LinearConfig::new(20, 5).init(&device),
        activation: Relu::new(),
    };
    
    let input = Tensor::<Wgpu, 2>::random([2, 10], burn::tensor::Distribution::Default, &device);
    let output = model.forward(input);
    
    println!("Output shape: {:?}", output.shape());
}
```

**Burnã®æ–¹å‘æ€§**:

- âœ… **ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **: WebGPUå¯¾å¿œã§ãƒ–ãƒ©ã‚¦ã‚¶æ¨è«–
- âœ… **ãƒ¢ãƒã‚¤ãƒ«**: iOS/Androidå¯¾å¿œè¨ˆç”»
- â³ **åˆ†æ•£å­¦ç¿’**: å°†æ¥çš„ã«å®Ÿè£…äºˆå®š
- â³ **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ **: ãƒ¢ãƒ‡ãƒ«zooæ‹¡å……ä¸­

### Candleï¼šHuggingFace ã®è»½é‡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

**Candle** [^3] ã¯ã€HuggingFaceãŒé–‹ç™ºã™ã‚‹è»½é‡æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

[^3]: Candle: https://github.com/huggingface/candle

**ç‰¹å¾´**:

- **è»½é‡**: ä¾å­˜é–¢ä¿‚ãŒæœ€å°
- **æ¨è«–ç‰¹åŒ–**: å­¦ç¿’æ©Ÿèƒ½ã¯é™å®šçš„
- **Transformerså¯¾å¿œ**: GPTã€BERTã€Whisperãªã©
- **é‡å­åŒ–**: INT8/FP16ã‚µãƒãƒ¼ãƒˆ

**ä½¿ç”¨ä¾‹ï¼ˆGPT-2æ¨è«–ï¼‰**:

```rust
use candle::{DType, Device, Tensor};
use candle_transformers::models::gpt2::{Config, GPT};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let device = Device::cuda_if_available(0)?;
    
    // GPT-2 ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    let config = Config::gpt2();
    let vb = unsafe { candle_nn::VarBuilder::from_mmaped_safetensors(
        &["gpt2.safetensors"],
        DType::F32,
        &device,
    )? };
    let model = GPT::load(vb, config)?;
    
    // ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆçœç•¥ï¼‰
    let input_ids = Tensor::new(&[15496u32, 318], &device)?;
    
    // æ¨è«–
    let logits = model.forward(&input_ids)?;
    
    println!("Logits shape: {:?}", logits.dims());
    
    Ok(())
}
```

**Candleã®æ–¹å‘æ€§**:

- âœ… **Transformers**: ä¸»è¦ãƒ¢ãƒ‡ãƒ«ã®Rustå®Ÿè£…
- âœ… **é‡å­åŒ–**: GGUFã€GPTQå¯¾å¿œ
- â³ **å­¦ç¿’**: é™å®šçš„ã ãŒæ‹¡å……äºˆå®š
- â³ **æ¨è«–æœ€é©åŒ–**: FlashAttentionçµ±åˆ

### Linfaï¼šä¼çµ±çš„æ©Ÿæ¢°å­¦ç¿’

**Linfa** [^4] ã¯ã€scikit-learnã«ç›¸å½“ã™ã‚‹Rustãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

[^4]: Linfa: https://github.com/rust-ml/linfa

**ç‰¹å¾´**:

- **ä¼çµ±çš„ML**: SVMã€æ±ºå®šæœ¨ã€K-Meansã€PCAãªã©
- **ç´”Rust**: å¤–éƒ¨ä¾å­˜ãªã—ï¼ˆCPUå°‚ç”¨ï¼‰
- **å‹å®‰å…¨**: ndarrayãƒ™ãƒ¼ã‚¹

**ä½¿ç”¨ä¾‹**:

```rust
use linfa::prelude::*;
use linfa_linear::LinearRegression;
use ndarray::array;

fn main() {
    // ãƒ‡ãƒ¼ã‚¿æº–å‚™
    let x = array![[1.0], [2.0], [3.0], [4.0], [5.0]];
    let y = array![2.0, 4.0, 6.0, 8.0, 10.0];
    let dataset = Dataset::new(x, y);
    
    // ç·šå½¢å›å¸°
    let model = LinearRegression::default().fit(&dataset).unwrap();
    
    // äºˆæ¸¬
    let x_test = array![[6.0]];
    let prediction = model.predict(&x_test);
    
    println!("Prediction: {:?}", prediction);  // ~12.0
}
```

**Linfaã®æ–¹å‘æ€§**:

- âœ… **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ‹¡å……**: ç¶™ç¶šçš„ã«è¿½åŠ 
- â³ **GPUå¯¾å¿œ**: è¨ˆç”»æ®µéš
- â³ **ä¸¦åˆ—åŒ–**: rayonãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–

### dfdxï¼šè‡ªå‹•å¾®åˆ†ç‰¹åŒ–

**dfdx** [^5] ã¯ã€å‹ãƒ¬ãƒ™ãƒ«è‡ªå‹•å¾®åˆ†ã‚’å®Ÿè£…ã™ã‚‹å®Ÿé¨“çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚

[^5]: dfdx: https://github.com/coreylowman/dfdx

**ç‰¹å¾´**:

- **å‹ãƒ¬ãƒ™ãƒ«è‡ªå‹•å¾®åˆ†**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«è¨ˆç®—ã‚°ãƒ©ãƒ•æ§‹ç¯‰
- **ã‚¼ãƒ­ã‚³ã‚¹ãƒˆ**: ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã—
- **å®Ÿé¨“çš„**: ç ”ç©¶ãƒ»æ•™è‚²ç›®çš„

**ä½¿ç”¨ä¾‹**:

```rust
use dfdx::prelude::*;

fn main() {
    let dev: Cpu = Default::default();
    
    // ãƒ¢ãƒ‡ãƒ«å®šç¾©
    let model: (Linear<2, 5>, ReLU, Linear<5, 1>) = dev.build_module::<f32>();
    
    // å…¥åŠ›
    let x: Tensor<Rank1<2>, f32, _> = dev.tensor([1.0, 2.0]);
    
    // é †ä¼æ’­ï¼ˆè‡ªå‹•å¾®åˆ†å¯¾å¿œï¼‰
    let y = model.forward(x.traced());
    
    // é€†ä¼æ’­
    let grads = y.mean().backward();
    
    println!("Gradients: {:?}", grads);
}
```

### ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é¸æŠã‚¬ã‚¤ãƒ‰

|| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | æ¨å¥¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | ç†ç”± |
||------------|----------------|------|
|| **å­¦ç¿’ï¼ˆGPUï¼‰** | tch-rs | å®‰å®šã€cuDNNå¯¾å¿œ |
|| **å­¦ç¿’ï¼ˆã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰** | Burn | WebGPUå¯¾å¿œ |
|| **æ¨è«–ï¼ˆTransformerï¼‰** | Candle | HuggingFaceã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ  |
|| **æ¨è«–ï¼ˆONNXï¼‰** | tract | å•†ç”¨å®Ÿç¸¾ã‚ã‚Š |
|| **ä¼çµ±çš„ML** | Linfa | ç´”Rust |
|| **ç ”ç©¶ãƒ»å®Ÿé¨“** | dfdx | å‹ãƒ¬ãƒ™ãƒ«æœ€é©åŒ– |
|| **ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—** | Python | ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ  |

## 19.2 PyTorch/TensorFlow ã¨ã® API äº’æ›æˆ¦ç•¥

### äº’æ›æ€§ã®ç¾çŠ¶

**å®Œå…¨äº’æ›ã¯å›°é›£**:

- Pythonç‰¹æœ‰ã®å‹•çš„å‹ä»˜ã‘
- NumPy/PyTorchã®åºƒç¯„ãªAPI
- Pythonã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¨ã®æ·±ã„çµ±åˆ

**å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:

1. **ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°**: tch-rsï¼ˆLibTorchï¼‰ã€tensorflow-rust
2. **ONNX**: ä¸­é–“è¡¨ç¾ã§äº’æ›
3. **APIæ¨¡å€£**: Burnãªã©

### tch-rsï¼šLibTorch ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°

**tch-rs** [^6] ã¯ã€PyTorchã®C++ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆLibTorchï¼‰ã¸ã®ç›´æ¥ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã§ã™ã€‚

[^6]: tch-rs: https://github.com/LaurentMazare/tch-rs

**åˆ©ç‚¹**:

- âœ… PyTorchãƒ¢ãƒ‡ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨
- âœ… cuDNN/cuBLAS ã®æœ€é©åŒ–
- âœ… é«˜ã„äº’æ›æ€§

**æ¬ ç‚¹**:

- âŒ LibTorchã¸ã®ä¾å­˜
- âŒ ãƒ“ãƒ«ãƒ‰ãŒè¤‡é›‘
- âŒ Rustã‚‰ã—ã„è¨­è¨ˆã§ã¯ãªã„

**ãƒ¢ãƒ‡ãƒ«å…±æœ‰ã®ä¾‹**:

```python
# Pythonï¼ˆPyTorchï¼‰ã§ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
import torch

model = torch.nn.Sequential(
    torch.nn.Linear(10, 20),
    torch.nn.ReLU(),
    torch.nn.Linear(20, 1)
)

# TorchScript ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
traced = torch.jit.trace(model, torch.randn(1, 10))
traced.save("model.pt")
```

```rust
// Rustï¼ˆtch-rsï¼‰ã§æ¨è«–
use tch::{CModule, Tensor};

fn main() {
    let model = CModule::load("model.pt").unwrap();
    let input = Tensor::randn(&[1, 10], tch::kind::FLOAT_CPU);
    let output = model.forward_ts(&[input]).unwrap();
    
    println!("Output: {:?}", output);
}
```

### ONNXï¼šæ¨™æº–ä¸­é–“è¡¨ç¾

**ONNX** [^7] ã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã®äº’æ›æ€§ã‚’æä¾›ã—ã¾ã™ã€‚

[^7]: ONNX: https://onnx.ai/

**ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**:

```
PyTorch/TensorFlow â†’ ONNX â†’ Rust (tract/onnxruntime-rs)
```

**åˆ©ç‚¹**:

- âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯éä¾å­˜
- âœ… æœ€é©åŒ–ï¼ˆã‚°ãƒ©ãƒ•æœ€é©åŒ–ï¼‰
- âœ… å•†ç”¨ç’°å¢ƒã§åºƒãä½¿ç”¨

**æ¬ ç‚¹**:

- âŒ å­¦ç¿’ã¯éå¯¾å¿œï¼ˆæ¨è«–ã®ã¿ï¼‰
- âŒ ä¸€éƒ¨ã®æ¼”ç®—å­æœªã‚µãƒãƒ¼ãƒˆ

**Python â†’ ONNX â†’ Rust**:

```python
# Python: ãƒ¢ãƒ‡ãƒ«ã‚’ONNXã¸
import torch
import torch.onnx

model = MyModel()
dummy_input = torch.randn(1, 3, 224, 224)

torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    input_names=["input"],
    output_names=["output"]
)
```

```rust
// Rust: ONNXã‹ã‚‰æ¨è«–
use tract_onnx::prelude::*;

fn main() -> TractResult<()> {
    let model = tract_onnx::onnx()
        .model_for_path("model.onnx")?
        .into_optimized()?
        .into_runnable()?;
    
    let input = Tensor::from_shape(
        &[1, 3, 224, 224],
        &vec![0.0f32; 3 * 224 * 224]
    )?;
    
    let result = model.run(tvec!(input.into()))?;
    
    Ok(())
}
```

### APIæ¨¡å€£æˆ¦ç•¥

**Burn** ã¯ã€PyTorché¢¨ã®APIã‚’æä¾›:

**PyTorch**:

```python
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(10, 5)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        return self.relu(self.linear(x))
```

**Burnï¼ˆé¡ä¼¼ï¼‰**:

```rust
use burn::module::Module;
use burn::nn::{Linear, LinearConfig, Relu};

#[derive(Module, Debug)]
pub struct MyModel<B: Backend> {
    linear: Linear<B>,
    relu: Relu,
}

impl<B: Backend> MyModel<B> {
    pub fn forward(&self, x: Tensor<B, 2>) -> Tensor<B, 2> {
        self.relu.forward(self.linear.forward(x))
    }
}
```

**é¡ä¼¼ç‚¹**:

- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ 
- forward ãƒ¡ã‚½ãƒƒãƒ‰
- å±¤ã®çµ„ã¿åˆã‚ã›

**ç›¸é•ç‚¹**:

- Rustã®å‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆBackendå‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
- æ‰€æœ‰æ¨©ãƒ»å€Ÿç”¨
- ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ãƒã‚§ãƒƒã‚¯

### ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

**å®Ÿç”¨çš„ãªæˆ¦ç•¥**:

|| ãƒ•ã‚§ãƒ¼ã‚º | è¨€èª | ç†ç”± |
||---------|------|------|
|| 1. ç ”ç©¶ãƒ»ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ— | Python | é–‹ç™ºé€Ÿåº¦ |
|| 2. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ | Python | ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ  |
|| 3. ãƒ¢ãƒ‡ãƒ«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ | ONNX | äº’æ›æ€§ |
|| 4. æ¨è«–ã‚µãƒ¼ãƒ | Rust | æ€§èƒ½ãƒ»ä¿¡é ¼æ€§ |
|| 5. ã‚¨ãƒƒã‚¸ãƒ‡ãƒ—ãƒ­ã‚¤ | Rust | çœãƒ¡ãƒ¢ãƒª |

**å®Ÿè£…ä¾‹**:

```rust
// Rustæ¨è«–ã‚µãƒ¼ãƒï¼ˆActix-Web + tractï¼‰
use actix_web::{web, App, HttpServer};
use tract_onnx::prelude::*;

struct AppState {
    model: RunnableModel<TypedFact, Box<dyn TypedOp>, TypedModel>,
}

async fn predict(
    data: web::Json<Vec<f32>>,
    state: web::Data<AppState>,
) -> web::Json<Vec<f32>> {
    let input = Tensor::from_shape(&[1, 10], &data.0).unwrap();
    let result = state.model.run(tvec!(input.into())).unwrap();
    let output: Vec<f32> = result[0].to_array_view::<f32>().unwrap()
                                   .iter().cloned().collect();
    web::Json(output)
}

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    let model = tract_onnx::onnx()
        .model_for_path("model.onnx").unwrap()
        .into_optimized().unwrap()
        .into_runnable().unwrap();
    
    let state = web::Data::new(AppState { model });
    
    HttpServer::new(move || {
        App::new()
            .app_data(state.clone())
            .route("/predict", web::post().to(predict))
    })
    .bind("0.0.0.0:8080")?
    .run()
    .await
}
```

## 19.3 Rust ãŒæ‹…ã†é«˜ä¿¡é ¼ ML ã‚¤ãƒ³ãƒ•ãƒ©ã®æœªæ¥

### Rustã®å¼·ã¿ãŒæ´»ãã‚‹é ˜åŸŸ

|| é ˜åŸŸ | Rustã®åˆ©ç‚¹ | Python ã®èª²é¡Œ |
||------|-----------|--------------|
|| **æ¨è«–ã‚µãƒ¼ãƒ** | ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€ãƒ¡ãƒ¢ãƒªå®‰å…¨ | GCåœæ­¢ã€ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ |
|| **ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹** | çœãƒ¡ãƒ¢ãƒªã€å˜ä¸€ãƒã‚¤ãƒŠãƒª | ä¾å­˜é–¢ä¿‚è¤‡é›‘ |
|| **çµ„ã¿è¾¼ã¿ML** | bare-metalå¯¾å¿œ | Pythonä¸å¯ |
|| **ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ã‚¹ãƒ†ãƒ ** | ãƒ¡ãƒ¢ãƒªå®‰å…¨ä¿è¨¼ | å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ |
|| **ä¸¦è¡Œå‡¦ç†** | Send/Syncä¿è¨¼ | GILåˆ¶ç´„ |

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ï¼šè‡ªå‹•é‹è»¢

**è‡ªå‹•é‹è»¢ã‚·ã‚¹ãƒ†ãƒ ã®è¦ä»¶**:

- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§**: 10msä»¥å†…ã®å¿œç­”
- **ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§**: ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ä¸å¯
- **æ±ºå®šè«–æ€§**: å†ç¾å¯èƒ½ãªæŒ™å‹•
- **çœé›»åŠ›**: ãƒãƒƒãƒ†ãƒªãƒ¼é§†å‹•

**Pythonã®é™ç•Œ**:

- GCåœæ­¢ã«ã‚ˆã‚‹é…å»¶
- å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã®ãƒªã‚¹ã‚¯
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®äºˆæ¸¬å›°é›£

**Rustã®é©åˆæ€§**:

âœ… æ±ºå®šè«–çš„å®Ÿè¡Œ
âœ… ãƒ¡ãƒ¢ãƒªå®‰å…¨ä¿è¨¼
âœ… ã‚¼ãƒ­ã‚³ã‚¹ãƒˆãƒ©ã‚¤ãƒ ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
âœ… bare-metalå¯¾å¿œ

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ï¼šé‡‘èå–å¼•

**é«˜é »åº¦å–å¼•ï¼ˆHFTï¼‰**:

- **è¶…ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: ãƒã‚¤ã‚¯ãƒ­ç§’å˜ä½
- **é«˜ä¿¡é ¼æ€§**: ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ä¸å¯
- **ç›£æŸ»å¯èƒ½æ€§**: å‹•ä½œã®å®Œå…¨è¨˜éŒ²

**Rustã®å®Ÿè£…ä¾‹**:

```rust
use std::time::Instant;

struct TradingModel {
    model: tract_onnx::prelude::RunnableModel</* ... */>,
}

impl TradingModel {
    fn predict(&self, market_data: &[f32]) -> Result<Action, Error> {
        let start = Instant::now();
        
        // æ¨è«–å®Ÿè¡Œ
        let input = Tensor::from_shape(&[1, market_data.len()], market_data)?;
        let result = self.model.run(tvec!(input.into()))?;
        let output: f32 = result[0].to_scalar()?;
        
        let latency = start.elapsed();
        
        // SLAé•åãƒã‚§ãƒƒã‚¯
        if latency.as_micros() > 100 {
            log::warn!("Latency SLA violated: {:?}", latency);
        }
        
        Ok(if output > 0.5 { Action::Buy } else { Action::Sell })
    }
}
```

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ï¼šåŒ»ç™‚è¨ºæ–­

**è¦ä»¶**:

- **è¦åˆ¶å¯¾å¿œ**: FDAæ‰¿èªãªã©
- **ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£**: å…¨æ±ºå®šã®è¨˜éŒ²
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: æ‚£è€…ãƒ‡ãƒ¼ã‚¿ä¿è­·

**Rustã®åˆ©ç‚¹**:

- å‹å®‰å…¨ã«ã‚ˆã‚‹ä¸å¤‰æ¡ä»¶ä¿è¨¼
- æ‰€æœ‰æ¨©ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¼æ´©é˜²æ­¢
- ãƒ¡ãƒ¢ãƒªå®‰å…¨ã«ã‚ˆã‚‹è„†å¼±æ€§ä½æ¸›

## 19.4 ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹æ´»å‹•

### Rust ML ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£

**ä¸»è¦ãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**:

|| ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ | URL | æ´»å‹•å†…å®¹ |
||-----------|-----|---------|
|| **Rust ML WG** | https://github.com/rust-ml | æ¨™æº–åŒ–æ¨é€² |
|| **Burn Discord** | https://discord.gg/uPEBbYYDB6 | Burné–‹ç™º |
|| **Rust Users Forum** | https://users.rust-lang.org/ | è³ªå•ãƒ»è­°è«– |

### è²¢çŒ®æ–¹æ³•

**åˆå¿ƒè€…å‘ã‘**:

1. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ”¹å–„**: èª¤å­—ä¿®æ­£ã€ä¾‹è¿½åŠ 
2. **ãƒã‚°å ±å‘Š**: Issueã§å ±å‘Š
3. **ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰**: ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ä½œæˆ

**ä¸­ç´šè€…å‘ã‘**:

1. **ãƒã‚°ä¿®æ­£**: "good first issue" ã‚¿ã‚°
2. **ãƒ†ã‚¹ãƒˆè¿½åŠ **: ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„**: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

**ä¸Šç´šè€…å‘ã‘**:

1. **æ–°æ©Ÿèƒ½å®Ÿè£…**: RFCææ¡ˆ
2. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ”¹å–„**: è¨­è¨ˆè­°è«–
3. **ä»–è¨€èªãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°**: FFIå®Ÿè£…

### æ¨å¥¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

**å­¦ç¿’ã«é©ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**:

|| ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | é›£æ˜“åº¦ | å­¦ã¹ã‚‹å†…å®¹ |
||------------|--------|----------|
|| **Linfa** | ä½ã€œä¸­ | ä¼çµ±çš„MLã€ndarray |
|| **Burn** | ä¸­ | ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€WebGPU |
|| **tract** | é«˜ | ONNXã€ã‚°ãƒ©ãƒ•æœ€é©åŒ– |
|| **tch-rs** | ä¸­ | PyTorché€£æº |

## 19.5 ä»Šå¾Œã®å­¦ç¿’ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### åˆç´šï¼ˆ1-3ãƒ¶æœˆï¼‰

**ç›®æ¨™**: Rustã®åŸºç¤ã¨MLåŸºç¤ã‚’ç¿’å¾—

1. **Rustè¨€èª**:
   - The Rust Programming Languageï¼ˆå…¬å¼æœ¬ï¼‰
   - æ‰€æœ‰æ¨©ãƒ»å€Ÿç”¨ãƒ»ãƒ©ã‚¤ãƒ•ã‚¿ã‚¤ãƒ 

2. **ç·šå½¢ä»£æ•°**:
   - ndarray ã®ä½¿ã„æ–¹
   - è¡Œåˆ—æ¼”ç®—ã®å®Ÿè£…

3. **æ©Ÿæ¢°å­¦ç¿’åŸºç¤**:
   - Linfa ã§ä¼çµ±çš„ML
   - ç·šå½¢å›å¸°ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°

**å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**:

- [ ] ç·šå½¢å›å¸°ã‚’ã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…
- [ ] Linfaã§ Iris åˆ†é¡
- [ ] ndarray ã§GEMMå®Ÿè£…

### ä¸­ç´šï¼ˆ3-6ãƒ¶æœˆï¼‰

**ç›®æ¨™**: ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°

1. **ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°**:
   - tch-rs ã§ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
   - è‡ªå‹•å¾®åˆ†ã®ç†è§£

2. **GPUåŸºç¤**:
   - CUDAæ¦‚å¿µ
   - wgpu ã§ç°¡å˜ãªã‚«ãƒ¼ãƒãƒ«

3. **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**:
   - Burn ã®ä½¿ã„æ–¹
   - Candle ã§Transformeræ¨è«–

**å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**:

- [ ] MNIST ã‚’ tch-rs ã§å­¦ç¿’
- [ ] ã‚«ã‚¹ã‚¿ãƒ CUDAã‚«ãƒ¼ãƒãƒ«å®Ÿè£…
- [ ] Burn ã§ ResNet æ§‹ç¯‰

### ä¸Šç´šï¼ˆ6-12ãƒ¶æœˆï¼‰

**ç›®æ¨™**: æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿç”¨

1. **æœ€é©åŒ–**:
   - ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
   - ã‚«ãƒ¼ãƒãƒ«æœ€é©åŒ–
   - ãƒ¡ãƒ¢ãƒªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

2. **ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ**:
   - æ¨è«–ã‚µãƒ¼ãƒæ§‹ç¯‰
   - åˆ†æ•£æ¨è«–
   - ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

3. **å°‚é–€åˆ†é‡**:
   - Transformerså®Ÿè£…
   - é‡å­åŒ–
   - ã‚¨ãƒƒã‚¸ãƒ‡ãƒ—ãƒ­ã‚¤

**å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**:

- [ ] æœ¬ç•ªæ¨è«–ã‚µãƒ¼ãƒæ§‹ç¯‰
- [ ] Flash Attentionå®Ÿè£…
- [ ] Jetson ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

### ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆï¼ˆ12ãƒ¶æœˆä»¥ä¸Šï¼‰

**ç›®æ¨™**: ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¸ã®è²¢çŒ®

1. **ç ”ç©¶**:
   - æœ€æ–°è«–æ–‡ã®å®Ÿè£…
   - æ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ææ¡ˆ

2. **ãƒ„ãƒ¼ãƒ«é–‹ç™º**:
   - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ”¹å–„
   - æ–°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé–‹ç™º

3. **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**:
   - RFCææ¡ˆ
   - ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°

**å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**:

- [ ] OSS ã¸ã®å¤§å‹PR
- [ ] æ–°MLæ‰‹æ³•ã®Rustå®Ÿè£…
- [ ] ãƒ–ãƒ­ã‚°ãƒ»è¬›æ¼”ã§çŸ¥è¦‹å…±æœ‰

### æ¨å¥¨ãƒªã‚½ãƒ¼ã‚¹

**æ›¸ç±**:

- "The Rust Programming Language" (å…¬å¼)
- "Programming Massively Parallel Processors" (GPU)
- "Deep Learning" (Ian Goodfellow)

**ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ã‚¹**:

- Rust by Example
- CUDA Training Series (NVIDIA)
- Fast.ai (MLåŸºç¤)

**è«–æ–‡**:

- Attention Is All You Need
- FlashAttention
- ONNX: Open Neural Network Exchange

### æœ€å¾Œã«

**Rustã¯æ©Ÿæ¢°å­¦ç¿’ã®æœªæ¥ã«ãŠã‘ã‚‹é‡è¦ãªé¸æŠè‚¢ã§ã™**:

âœ… **æ€§èƒ½**: C/C++ã«åŒ¹æ•µ
âœ… **å®‰å…¨æ€§**: ãƒ¡ãƒ¢ãƒªå®‰å…¨ä¿è¨¼
âœ… **ç”Ÿç”£æ€§**: ãƒ¢ãƒ€ãƒ³ãªè¨€èªæ©Ÿèƒ½
âœ… **ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ **: æ€¥é€Ÿã«æˆé•·ä¸­

**ã—ã‹ã—ã€ã¾ã ç™ºå±•é€”ä¸Š**:

â³ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æˆç†Ÿåº¦
â³ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å……å®Ÿ
â³ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è¦æ¨¡

**ã‚ãªãŸã®è²¢çŒ®ãŒæœªæ¥ã‚’ä½œã‚Šã¾ã™**:

ã“ã®æœ¬ã§å­¦ã‚“ã çŸ¥è­˜ã‚’æ´»ã‹ã—ã€Rust ML ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®ç™ºå±•ã«è²¢çŒ®ã—ã¦ãã ã•ã„ã€‚ãƒã‚°å ±å‘Šã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ”¹å–„ã€ã‚³ãƒ¼ãƒ‰è²¢çŒ®ã€ã©ã‚“ãªå½¢ã§ã‚‚æ­“è¿ã§ã™ã€‚

**Happy Learning and Happy Coding! ğŸ¦€âœ¨**

---

## å‚è€ƒæ–‡çŒ®

[^1] Awesome Rust Machine Learning: https://github.com/vaaaaanquish/Awesome-Rust-MachineLearning

[^2] Burn: https://github.com/tracel-ai/burn

[^3] Candle: https://github.com/huggingface/candle

[^4] Linfa: https://github.com/rust-ml/linfa

[^5] dfdx: https://github.com/coreylowman/dfdx

[^6] tch-rs: https://github.com/LaurentMazare/tch-rs

[^7] ONNX: https://onnx.ai/
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬21ç« : å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ](../06_ç¬¬VIéƒ¨_ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã¨å®Ÿè·µ/06-21-å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ.md)