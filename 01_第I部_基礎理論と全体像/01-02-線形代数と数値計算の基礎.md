[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬1ç« ](01-01-GPUãƒã‚¤ãƒ†ã‚£ãƒ–æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã‹.md) | [â¡ï¸ ç¬¬3ç« ](01-03-è‡ªå‹•å¾®åˆ†ã®ä»•çµ„ã¿.md)

---

# ç¬¬ 2 ç« ã€€ç·šå½¢ä»£æ•°ã¨æ•°å€¤è¨ˆç®—ã®åŸºç¤

æœ¬ç« ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã§é »å‡ºã™ã‚‹ç·šå½¢ä»£æ•°ã®åŸºæœ¬æ¦‚å¿µã¨ã€æ•°å€¤è¨ˆç®—ã«ãŠã‘ã‚‹å®Ÿè£…ä¸Šã®æ³¨æ„ç‚¹ã‚’å–ã‚Šä¸Šã’ã¾ã™ã€‚ç‰¹ã«ã€è¡Œåˆ—ç©ï¼ˆGEMMï¼‰ã¨ç•³ã¿è¾¼ã¿ï¼ˆCONVï¼‰ã«ã¤ã„ã¦ã€æ•°å¼ãƒ»ã‚³ãƒ¼ãƒ‰ãƒ»æ´»ç”¨äº‹ä¾‹ã‚’äº¤ãˆã¦è©³è¿°ã—ã¾ã™ã€‚

## 2.1 ãƒ™ã‚¯ãƒˆãƒ«ãƒ»è¡Œåˆ—ãƒ»ãƒ†ãƒ³ã‚½ãƒ«

### åŸºæœ¬çš„ãªå®šç¾©

| åç§°             | æ¬¡å…ƒ   | å½¢çŠ¶è¡¨è¨˜     | å…·ä½“ä¾‹        | ç”¨é€”                  |
| ---------------- | ------ | ------------ | ------------- | --------------------- |
| **ã‚¹ã‚«ãƒ©ãƒ¼**     | 0 æ¬¡å…ƒ | ()           | 3.14          | æå¤±å€¤ã€å­¦ç¿’ç‡        |
| **ãƒ™ã‚¯ãƒˆãƒ«**     | 1 æ¬¡å…ƒ | (n,)         | [1, 2, 3]     | åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«      |
| **è¡Œåˆ—**         | 2 æ¬¡å…ƒ | (m, n)       | [[1,2],[3,4]] | é‡ã¿è¡Œåˆ—              |
| **3 éšãƒ†ãƒ³ã‚½ãƒ«** | 3 æ¬¡å…ƒ | (d, m, n)    | RGB ç”»åƒ      | ç”»åƒï¼ˆCÃ—HÃ—Wï¼‰         |
| **4 éšãƒ†ãƒ³ã‚½ãƒ«** | 4 æ¬¡å…ƒ | (b, d, m, n) | ãƒãƒƒãƒç”»åƒ    | ãƒŸãƒ‹ãƒãƒƒãƒï¼ˆNÃ—CÃ—HÃ—Wï¼‰ |

**ãƒ†ãƒ³ã‚½ãƒ«**ã¯å¤šæ¬¡å…ƒé…åˆ—ã®ä¸€èˆ¬åŒ–ã§ã‚ã‚Šã€æ©Ÿæ¢°å­¦ç¿’ã§ã¯ä»¥ä¸‹ã®å½¢çŠ¶ãŒé »å‡ºã—ã¾ã™ï¼š

**ç”»åƒãƒ‡ãƒ¼ã‚¿**: \((N, C, H, W)\)

- N: ãƒãƒƒãƒã‚µã‚¤ã‚º
- C: ãƒãƒ£ãƒãƒ«æ•°ï¼ˆRGB ãªã‚‰ 3ï¼‰
- H: é«˜ã•ï¼ˆHeightï¼‰
- W: å¹…ï¼ˆWidthï¼‰

**ç³»åˆ—ãƒ‡ãƒ¼ã‚¿**: \((N, T, D)\)

- N: ãƒãƒƒãƒã‚µã‚¤ã‚º
- T: æ™‚ç³»åˆ—é•·ï¼ˆTime stepsï¼‰
- D: ç‰¹å¾´æ¬¡å…ƒ

### å½¢çŠ¶ã¨ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®é‡è¦æ€§

ãƒ†ãƒ³ã‚½ãƒ«ã®**å½¢çŠ¶**ï¼ˆshapeï¼‰ã¯å„æ¬¡å…ƒã®ã‚µã‚¤ã‚ºã€**ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰**ï¼ˆstrideï¼‰ã¯éš£æ¥è¦ç´ é–“ã®ãƒ¡ãƒ¢ãƒªã‚ªãƒ•ã‚»ãƒƒãƒˆã§ã™ã€‚

**å…·ä½“ä¾‹**: 3Ã—4 è¡Œåˆ—ï¼ˆrow-major é…ç½®ï¼‰

```rust
// Rust ã§ã®ä¾‹
use ndarray::Array2;

let matrix = Array2::from_shape_vec((3, 4), vec![
    1.0, 2.0, 3.0, 4.0,   // 1è¡Œç›®
    5.0, 6.0, 7.0, 8.0,   // 2è¡Œç›®
    9.0, 10.0, 11.0, 12.0 // 3è¡Œç›®
]).unwrap();

println!("å½¢çŠ¶: {:?}", matrix.shape());      // [3, 4]
println!("ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {:?}", matrix.strides()); // [4, 1]
// ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ [4, 1] ã®æ„å‘³ï¼š
// - æ¬¡ã®è¡Œã«ç§»å‹•ã™ã‚‹ã«ã¯ 4 è¦ç´ åˆ†é€²ã‚€
// - æ¬¡ã®åˆ—ã«ç§»å‹•ã™ã‚‹ã«ã¯ 1 è¦ç´ åˆ†é€²ã‚€
```

**ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å¯è¦–åŒ–**:

```mermaid
graph LR
    subgraph Memory[ãƒ¡ãƒ¢ãƒªä¸Šã®é…ç½® row-major]
        M0[1] --> M1[2] --> M2[3] --> M3[4]
        M3 --> M4[5] --> M5[6] --> M6[7] --> M7[8]
        M7 --> M8[9] --> M9[10] --> M10[11] --> M11[12]
    end
    
    subgraph Matrix[è«–ç†çš„ãªè¡Œåˆ— 3Ã—4]
        R0[1 2 3 4]
        R1[5 6 7 8]
        R2[9 10 11 12]
    end
    
    style M0 fill:#e1f5ff
    style M4 fill:#ffe1f5
    style M8 fill:#e1ffe1
```

**ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ [4, 1] ã®æ„å‘³**:
- æ¬¡ã®è¡Œ: 4è¦ç´ åˆ†é€²ã‚€ï¼ˆ1â†’5, 5â†’9ï¼‰
- æ¬¡ã®åˆ—: 1è¦ç´ åˆ†é€²ã‚€ï¼ˆ1â†’2, 2â†’3ï¼‰

**ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®è¨ˆç®—**:
\[
\text{offset}(i, j) = i \times \text{stride}[0] + j \times \text{stride}[1] = 4i + j
\]

### Python ã¨ Rust ã§ã®ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œ

**Python (NumPy)**:

```python
import numpy as np

# 3æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ«ã®ä½œæˆ
tensor = np.random.randn(2, 3, 4)  # å½¢çŠ¶: (2, 3, 4)
print(f"å½¢çŠ¶: {tensor.shape}")
print(f"ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {tensor.strides}")  # ãƒã‚¤ãƒˆå˜ä½
print(f"è¦ç´ æ•°: {tensor.size}")
print(f"æ¬¡å…ƒæ•°: {tensor.ndim}")

# ã‚¹ãƒ©ã‚¤ã‚¹æ“ä½œï¼ˆãƒ“ãƒ¥ãƒ¼ï¼šã‚³ãƒ”ãƒ¼ãªã—ï¼‰
sub_tensor = tensor[:, 1:, :]  # å½¢çŠ¶: (2, 2, 4)
print(f"ã‚¹ãƒ©ã‚¤ã‚¹å¾Œã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {sub_tensor.strides}")
```

**Rust (ndarray)**:

```rust
use ndarray::{Array3, s};
use ndarray_rand::RandomExt;
use ndarray_rand::rand_distr::StandardNormal;

// 3æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ«ã®ä½œæˆ
let tensor: Array3<f64> = Array3::random((2, 3, 4), StandardNormal);
println!("å½¢çŠ¶: {:?}", tensor.shape());        // [2, 3, 4]
println!("ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {:?}", tensor.strides()); // [12, 4, 1]ï¼ˆè¦ç´ æ•°å˜ä½ï¼‰
println!("è¦ç´ æ•°: {}", tensor.len());
println!("æ¬¡å…ƒæ•°: {}", tensor.ndim());

// ã‚¹ãƒ©ã‚¤ã‚¹æ“ä½œï¼ˆãƒ“ãƒ¥ãƒ¼ï¼šã‚³ãƒ”ãƒ¼ãªã—ï¼‰
let sub_tensor = tensor.slice(s![.., 1.., ..]);  // å½¢çŠ¶: [2, 2, 4]
println!("ã‚¹ãƒ©ã‚¤ã‚¹å¾Œã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {:?}", sub_tensor.strides());
```

**ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®é•ã„**:

- NumPy: ãƒã‚¤ãƒˆå˜ä½ï¼ˆf64 ãªã‚‰ 8 ã®å€æ•°ï¼‰
- ndarray: è¦ç´ æ•°å˜ä½ï¼ˆå‹ã«ä¾ã‚‰ãšæ•´æ•°ï¼‰

## 2.2 è¡Œåˆ—ç©ã¨ç•³ã¿è¾¼ã¿ã®è¨ˆç®—é‡

### ç•³ã¿è¾¼ã¿æ¼”ç®—ï¼ˆConvolutionï¼‰ã®è©³ç´°

**ç•³ã¿è¾¼ã¿**ã¯ CNNï¼ˆConvolutional Neural Networkã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã®ä¸­æ ¸æ¼”ç®—ã§ã€ç”»åƒã®å±€æ‰€çš„ãªç‰¹å¾´ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

#### 2 æ¬¡å…ƒç•³ã¿è¾¼ã¿ã®æ•°å­¦çš„å®šç¾©

å…¥åŠ› \(X\) ã¨ã‚«ãƒ¼ãƒãƒ«ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ï¼‰\(W\) ã®ç•³ã¿è¾¼ã¿ï¼š

\[
Y*{ij} = \sum*{m=0}^{K*h-1} \sum*{n=0}^{K*w-1} X*{i+m, j+n} \times W\_{mn}
\]

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:

- å…¥åŠ›ã‚µã‚¤ã‚º: \(H \times W\)
- ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º: \(K_h \times K_w\)
- å‡ºåŠ›ã‚µã‚¤ã‚º: \((H - K_h + 1) \times (W - K_w + 1)\)ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒ»ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ãªã—ã®å ´åˆï¼‰

#### å…·ä½“çš„ãªè¨ˆç®—ä¾‹

**å…¥åŠ›ç”»åƒ** \(X\) (5Ã—5):

```
1  2  3  4  5
6  7  8  9  10
11 12 13 14 15
16 17 18 19 20
21 22 23 24 25
```

**ã‚«ãƒ¼ãƒãƒ«ï¼ˆã‚¨ãƒƒã‚¸æ¤œå‡ºãƒ•ã‚£ãƒ«ã‚¿ï¼‰** \(W\) (3Ã—3):

```
-1  0  1
-2  0  2
-1  0  1
```

**å‡ºåŠ›ã®è¨ˆç®—**ï¼ˆå·¦ä¸Šã®è¦ç´ ï¼‰:
\[
Y*{0,0} = \sum*{m=0}^{2} \sum*{n=0}^{2} X*{m,n} \times W\_{m,n}
\]

\[
= (1 \times -1) + (2 \times 0) + (3 \times 1) + (6 \times -2) + (7 \times 0) + (8 \times 2) + (11 \times -1) + (12 \times 0) + (13 \times 1)
\]

\[
= -1 + 0 + 3 - 12 + 0 + 16 - 11 + 0 + 13 = 8
\]

#### Rust ã§ã®å®Ÿè£…

```rust
// 2D ç•³ã¿è¾¼ã¿ã®ç´ æœ´ãªå®Ÿè£…
fn conv2d_naive(
    input: &[f32],   // å…¥åŠ›ç”»åƒï¼ˆHÃ—Wï¼‰
    kernel: &[f32],  // ã‚«ãƒ¼ãƒãƒ«ï¼ˆKhÃ—Kwï¼‰
    output: &mut [f32], // å‡ºåŠ›ï¼ˆOhÃ—Owï¼‰
    h: usize, w: usize,        // å…¥åŠ›ã‚µã‚¤ã‚º
    kh: usize, kw: usize       // ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
) {
    let oh = h - kh + 1;  // å‡ºåŠ›ã®é«˜ã•
    let ow = w - kw + 1;  // å‡ºåŠ›ã®å¹…

    for i in 0..oh {
        for j in 0..ow {
            let mut sum = 0.0;
            for m in 0..kh {
                for n in 0..kw {
                    sum += input[(i + m) * w + (j + n)] * kernel[m * kw + n];
                }
            }
            output[i * ow + j] = sum;
        }
    }
}

// ä½¿ç”¨ä¾‹
fn main() {
    let input = vec![
        1.0, 2.0, 3.0, 4.0, 5.0,
        6.0, 7.0, 8.0, 9.0, 10.0,
        11.0, 12.0, 13.0, 14.0, 15.0,
        16.0, 17.0, 18.0, 19.0, 20.0,
        21.0, 22.0, 23.0, 24.0, 25.0,
    ];

    let kernel = vec![
        -1.0, 0.0, 1.0,
        -2.0, 0.0, 2.0,
        -1.0, 0.0, 1.0,
    ];

    let mut output = vec![0.0; 3 * 3];  // 3Ã—3 ã®å‡ºåŠ›

    conv2d_naive(&input, &kernel, &mut output, 5, 5, 3, 3);

    println!("å‡ºåŠ›: {:?}", output);
}
```

#### è¨ˆç®—é‡ã®åˆ†æ

**ç´ æœ´ãªå®Ÿè£…ã®è¨ˆç®—é‡**:

å…¥åŠ›: \(C*{in} \times H \times W\)  
ã‚«ãƒ¼ãƒãƒ«: \(C*{out} \times C*{in} \times K_h \times K_w\)  
å‡ºåŠ›: \(C*{out} \times H*{out} \times W*{out}\)

\[
\text{è¨ˆç®—é‡} = C*{out} \times H*{out} \times W*{out} \times C*{in} \times K_h \times K_w \times 2
\]

**å…·ä½“ä¾‹**: ResNet-50 ã®æœ€åˆã®ç•³ã¿è¾¼ã¿å±¤

- å…¥åŠ›: \(3 \times 224 \times 224\)
- ã‚«ãƒ¼ãƒãƒ«: \(64 \times 3 \times 7 \times 7\)
- ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: 2
- å‡ºåŠ›: \(64 \times 112 \times 112\)

è¨ˆç®—é‡: \(64 \times 112 \times 112 \times 3 \times 7 \times 7 \times 2 \approx 118\) MFLOPS

### ç•³ã¿è¾¼ã¿ã®æœ€é©åŒ–æ‰‹æ³•

ç•³ã¿è¾¼ã¿ã«ã¯è¤‡æ•°ã®å®Ÿè£…æ–¹æ³•ãŒã‚ã‚Šã€ã‚µã‚¤ã‚ºã‚„ç”¨é€”ã«ã‚ˆã£ã¦æœ€é©ãªæ‰‹æ³•ãŒç•°ãªã‚Šã¾ã™ã€‚

| æ‰‹æ³•              | è¨ˆç®—é‡                           | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | é©ã—ãŸå ´é¢     |
| ----------------- | -------------------------------- | ------------ | -------------- |
| **ç´ æœ´ãªå®Ÿè£…**    | \(O(C*{out}H_oW_oC*{in}K_hK_w)\) | å°           | å°è¦æ¨¡ã‚«ãƒ¼ãƒãƒ« |
| **im2col + GEMM** | \(O(C*{out}H_oW_oC*{in}K_hK_w)\) | å¤§           | å¤§è¦æ¨¡ãƒãƒƒãƒ   |
| **FFT ç•³ã¿è¾¼ã¿**  | \(O(C*{out}C*{in}HW\log(HW))\)   | å¤§           | å¤§è¦æ¨¡ã‚«ãƒ¼ãƒãƒ« |
| **Winograd**      | \(O(C*{out}H_oW_oC*{in})\)       | ä¸­           | 3Ã—3 ã‚«ãƒ¼ãƒãƒ«   |

#### im2colï¼ˆImage to Columnï¼‰ã«ã‚ˆã‚‹ GEMM ã¸ã®å¤‰æ›

im2col ã¯ç•³ã¿è¾¼ã¿ã‚’è¡Œåˆ—ç©ã«å¤‰æ›ã™ã‚‹æ‰‹æ³•ã§ã€æœ€é©åŒ–ã•ã‚ŒãŸ BLAS ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ´»ç”¨ã§ãã¾ã™ [^8]ã€‚

**ã‚¢ã‚¤ãƒ‡ã‚¢**: ç•³ã¿è¾¼ã¿ã®å„ä½ç½®ã§ä½¿ã†å…¥åŠ›ãƒ‘ãƒƒãƒã‚’åˆ—ã¨ã—ã¦å±•é–‹ã™ã‚‹ã€‚

**ä¾‹**: 5Ã—5 å…¥åŠ›ã€3Ã—3 ã‚«ãƒ¼ãƒãƒ«

**im2col å¤‰æ›å¾Œã®è¡Œåˆ—**ï¼ˆå„åˆ—ãŒ 1 ã¤ã®å‡ºåŠ›ä½ç½®ã«å¯¾å¿œï¼‰:

```
ä½ç½®(0,0) ä½ç½®(0,1) ä½ç½®(0,2) ...
1         2         3         ...
2         3         4         ...
3         4         5         ...
6         7         8         ...
7         8         9         ...
8         9         10        ...
11        12        13        ...
12        13        14        ...
13        14        15        ...
```

**è¡Œåˆ—ç©ã¨ã—ã¦è¨ˆç®—**:
\[
\text{Output} = \text{Kernel} \times \text{im2col}(X)
\]

ã‚«ãƒ¼ãƒãƒ«ã¯ \((C*{out} \times (C*{in} \times K*h \times K_w))\) è¡Œåˆ—ã€im2col å¾Œã¯ \(((C*{in} \times K_h \times K_w) \times (H_o \times W_o))\) è¡Œåˆ—ã€‚

**Rust ã§ã®å®Ÿè£…ä¾‹**:

```rust
use ndarray::{Array2, Array4, s};

// im2col å¤‰æ›ï¼ˆç°¡ç•¥ç‰ˆï¼‰
fn im2col(
    input: &Array4<f32>,  // (N, C, H, W)
    kernel_h: usize,
    kernel_w: usize,
) -> Array2<f32> {
    let (n, c, h, w) = input.dim();
    let out_h = h - kernel_h + 1;
    let out_w = w - kernel_w + 1;

    let col_size = c * kernel_h * kernel_w;
    let num_patches = n * out_h * out_w;

    let mut col = Array2::<f32>::zeros((col_size, num_patches));

    let mut patch_idx = 0;
    for batch in 0..n {
        for i in 0..out_h {
            for j in 0..out_w {
                let mut row_idx = 0;
                for ch in 0..c {
                    for kh in 0..kernel_h {
                        for kw in 0..kernel_w {
                            col[[row_idx, patch_idx]] = input[[batch, ch, i + kh, j + kw]];
                            row_idx += 1;
                        }
                    }
                }
                patch_idx += 1;
            }
        }
    }

    col
}

// ç•³ã¿è¾¼ã¿ã‚’ GEMM ã§è¨ˆç®—
fn conv2d_gemm(
    input: &Array4<f32>,     // (N, C_in, H, W)
    weight: &Array4<f32>,    // (C_out, C_in, Kh, Kw)
) -> Array4<f32> {
    let (n, c_in, h, w) = input.dim();
    let (c_out, _, kh, kw) = weight.dim();
    let out_h = h - kh + 1;
    let out_w = w - kw + 1;

    // im2col å¤‰æ›
    let col = im2col(input, kh, kw);

    // ã‚«ãƒ¼ãƒãƒ«ã‚’è¡Œåˆ—ã«å¤‰å½¢: (C_out, C_in*Kh*Kw)
    let weight_mat = weight.view().into_shape((c_out, c_in * kh * kw)).unwrap();

    // è¡Œåˆ—ç©: (C_out, C_in*Kh*Kw) Ã— (C_in*Kh*Kw, N*H_out*W_out)
    let output_mat = weight_mat.dot(&col);

    // å‡ºåŠ›ã‚’4æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰å½¢
    output_mat.into_shape((c_out, n, out_h, out_w))
        .unwrap()
        .permuted_axes([1, 0, 2, 3])  // (N, C_out, H_out, W_out)
}
```

**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ä»£å„Ÿ**:

- im2col ã¯ãƒ¡ãƒ¢ãƒªã‚’å¤§é‡ã«æ¶ˆè²»ã™ã‚‹ï¼ˆ\(C\_{in} \times K_h \times K_w \times H_o \times W_o\)ï¼‰
- ä¾‹: ãƒãƒƒãƒ 128ã€å…¥åŠ› 64Ã—56Ã—56ã€ã‚«ãƒ¼ãƒãƒ« 3Ã—3 ã®å ´åˆã€ç´„ 1.8 GB å¿…è¦

#### Winograd ç•³ã¿è¾¼ã¿

Winograd ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€å°ã•ãªã‚«ãƒ¼ãƒãƒ«ï¼ˆç‰¹ã« 3Ã—3ï¼‰ã®ç•³ã¿è¾¼ã¿ã‚’é«˜é€ŸåŒ–ã™ã‚‹æ‰‹æ³•ã§ã™ [^9]ã€‚ä¹—ç®—å›æ•°ã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚

**åŠ¹æœ**: 3Ã—3 ã‚«ãƒ¼ãƒãƒ«ã®å ´åˆã€ä¹—ç®—å›æ•°ã‚’ç´„ 2.25 å€å‰Šæ¸›ï¼ˆ9 å› â†’ 4 å›ï¼‰

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: åŠ ç®—å›æ•°ã¯å¢—åŠ ã—ã€æ•°å€¤èª¤å·®ãŒå¤§ãããªã‚‹å ´åˆãŒã‚ã‚‹ã€‚

### æ´»ç”¨äº‹ä¾‹: CNN ã§ã®ç•³ã¿è¾¼ã¿

#### LeNet-5ï¼ˆæ‰‹æ›¸ãæ•°å­—èªè­˜ï¼‰

```rust
// LeNet-5 ã®ç¬¬1ç•³ã¿è¾¼ã¿å±¤ã®ä¾‹
// å…¥åŠ›: 1Ã—32Ã—32ï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒï¼‰
// å‡ºåŠ›: 6Ã—28Ã—28ï¼ˆ6ã¤ã®ç‰¹å¾´ãƒãƒƒãƒ—ï¼‰

use ndarray::{Array4, Axis};

fn lenet_conv1(input: &Array4<f32>) -> Array4<f32> {
    // input shape: (batch, 1, 32, 32)
    // kernel shape: (6, 1, 5, 5)

    let batch_size = input.shape()[0];
    let mut output = Array4::<f32>::zeros((batch_size, 6, 28, 28));

    // 6ã¤ã®ã‚«ãƒ¼ãƒãƒ«ã§ç•³ã¿è¾¼ã¿
    for b in 0..batch_size {
        for out_ch in 0..6 {
            // ç•³ã¿è¾¼ã¿æ¼”ç®—ï¼ˆå®Ÿéš›ã«ã¯æœ€é©åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼‰
            // conv2d_naive() ã‚’å‘¼ã³å‡ºã™
        }
    }

    output
}
```

**è¨ˆç®—é‡**: \(6 \times 28 \times 28 \times 1 \times 5 \times 5 \times 2 \approx 118\) KFLOPS/ã‚µãƒ³ãƒ—ãƒ«

#### ResNetï¼ˆç”»åƒåˆ†é¡ï¼‰

ResNet ã¯æ·±ã„ CNN ã§ã€ç•³ã¿è¾¼ã¿ã‚’å¤šæ®µã«ç©ã¿é‡ã­ã¾ã™ [^10]ã€‚

**ç‰¹å¾´**:

- æ®‹å·®æ¥ç¶šï¼ˆResidual Connectionï¼‰ã«ã‚ˆã‚Šæ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å­¦ç¿’å¯èƒ½ã«
- ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ§‹é€ ï¼ˆ1Ã—1 â†’ 3Ã—3 â†’ 1Ã—1ï¼‰ã§è¨ˆç®—é‡å‰Šæ¸›

**ResNet-50 ã®è¨ˆç®—é‡**: ç´„ 4 GFLOPS/ç”»åƒ

### è¨ˆç®—é‡ã®å®Ÿæ¸¬ä¾‹

| ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯    | å…¥åŠ›ã‚µã‚¤ã‚º | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | è¨ˆç®—é‡      | GPU æ¨è«–æ™‚é–“ï¼ˆRTX 4090ï¼‰ |
| --------------- | ---------- | ------------ | ----------- | ------------------------ |
| LeNet-5         | 32Ã—32Ã—1    | 60K          | 0.4 MFLOPS  | 0.05 ms                  |
| AlexNet         | 224Ã—224Ã—3  | 61M          | 720 MFLOPS  | 1.2 ms                   |
| VGG-16          | 224Ã—224Ã—3  | 138M         | 15.5 GFLOPS | 5.8 ms                   |
| ResNet-50       | 224Ã—224Ã—3  | 25.6M        | 4.1 GFLOPS  | 2.1 ms                   |
| EfficientNet-B0 | 224Ã—224Ã—3  | 5.3M         | 390 MFLOPS  | 1.5 ms                   |

[^8]: Chellapilla, K., Puri, S., & Simard, P. (2006). "High performance convolutional neural networks for document processing." International Workshop on Frontiers in Handwriting Recognition.
[^9]: Lavin, A., & Gray, S. (2016). "Fast Algorithms for Convolutional Neural Networks." CVPR 2016. arXiv:1509.09308
[^10]: He, K., Zhang, X., Ren, S., & Sun, J. (2016). "Deep Residual Learning for Image Recognition." CVPR 2016. arXiv:1512.03385

## 2.3 ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡

### Row-Major vs Column-Major

è¡Œåˆ—ã®ãƒ¡ãƒ¢ãƒªé…ç½®ã«ã¯ 2 ã¤ã®æ–¹å¼ãŒã‚ã‚Šã¾ã™ï¼š

| é…ç½®æ–¹å¼                         | é…åˆ—é †åº | ä½¿ç”¨è¨€èª/ãƒ©ã‚¤ãƒ–ãƒ©ãƒª          | ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ï¼ˆ3Ã—4 è¡Œåˆ—ï¼‰ |
| -------------------------------- | -------- | ---------------------------- | ---------------------- |
| **Row-Major** (C order)          | è¡Œå„ªå…ˆ   | C, C++, Python (NumPy), Rust | [4, 1]                 |
| **Column-Major** (Fortran order) | åˆ—å„ªå…ˆ   | Fortran, MATLAB, R           | [1, 3]                 |

**å…·ä½“ä¾‹**: 3Ã—4 è¡Œåˆ—

```
A = | 1  2  3  4  |
    | 5  6  7  8  |
    | 9  10 11 12 |
```

**Row-Major (C order)**: ãƒ¡ãƒ¢ãƒªä¸Šã¯ `[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]`  
**Column-Major (Fortran order)**: ãƒ¡ãƒ¢ãƒªä¸Šã¯ `[1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12]`

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ã¸ã®å½±éŸ¿

**CPU ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®éšå±¤**:

| ãƒ¬ãƒ™ãƒ«           | ã‚µã‚¤ã‚º       | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·          | ç”¨é€”             |
| ---------------- | ------------ | ------------------- | ---------------- |
| **L1**           | 32 ï½ 64 KB  | 4 ã‚µã‚¤ã‚¯ãƒ«          | æœ€ã‚‚é »ç¹ãªãƒ‡ãƒ¼ã‚¿ |
| **L2**           | 256KB ï½ 1MB | 10 ï½ 20 ã‚µã‚¤ã‚¯ãƒ«   | ã‚„ã‚„é »ç¹ãªãƒ‡ãƒ¼ã‚¿ |
| **L3**           | 8 ï½ 32 MB   | 40 ï½ 75 ã‚µã‚¤ã‚¯ãƒ«   | å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥   |
| **ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒª** | 8 ï½ 128 GB  | 100 ï½ 300 ã‚µã‚¤ã‚¯ãƒ« | ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿   |

**ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ©ã‚¤ãƒ³ã‚µã‚¤ã‚º**: é€šå¸¸ 64 ãƒã‚¤ãƒˆï¼ˆf32 ãªã‚‰ 16 è¦ç´ ã€f64 ãªã‚‰ 8 è¦ç´ ï¼‰

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã®ä¾‹

**éåŠ¹ç‡ãªåˆ—ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆRow-Major è¡Œåˆ—ï¼‰**:

```rust
// åˆ—ã”ã¨ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹å¤šç™ºï¼‰
fn sum_columns_slow(matrix: &Array2<f32>) -> Vec<f32> {
    let (rows, cols) = matrix.dim();
    let mut sums = vec![0.0; cols];

    for j in 0..cols {
        for i in 0..rows {
            sums[j] += matrix[[i, j]];  // éé€£ç¶šã‚¢ã‚¯ã‚»ã‚¹
        }
    }
    sums
}
```

**åŠ¹ç‡çš„ãªè¡Œã‚¢ã‚¯ã‚»ã‚¹**:

```rust
// è¡Œã”ã¨ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡é«˜ï¼‰
fn sum_columns_fast(matrix: &Array2<f32>) -> Vec<f32> {
    let (rows, cols) = matrix.dim();
    let mut sums = vec![0.0; cols];

    for i in 0..rows {
        for j in 0..cols {
            sums[j] += matrix[[i, j]];  // é€£ç¶šã‚¢ã‚¯ã‚»ã‚¹
        }
    }
    sums
}
```

**æ€§èƒ½å·®**: å¤§ããªè¡Œåˆ—ï¼ˆ10000Ã—10000ï¼‰ã§ã¯ã€**10 ï½ 50 å€**ã®æ€§èƒ½å·®ãŒå‡ºã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

### ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼ˆã‚¿ã‚¤ãƒªãƒ³ã‚°ï¼‰ã«ã‚ˆã‚‹æœ€é©åŒ–

**ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°**ã¯ã€è¡Œåˆ—ã‚’å°ã•ãªãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«åã‚ã‚‹æ‰‹æ³•ã§ã™ [^11]ã€‚

**ç´ æœ´ãªè¡Œåˆ—ç©**:

```rust
fn matmul_naive(a: &[f32], b: &[f32], c: &mut [f32], n: usize) {
    for i in 0..n {
        for j in 0..n {
            for k in 0..n {
                c[i * n + j] += a[i * n + k] * b[k * n + j];
            }
        }
    }
}
```

**ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ç‰ˆ**:

```rust
fn matmul_blocked(a: &[f32], b: &[f32], c: &mut [f32], n: usize, block_size: usize) {
    // ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«å‡¦ç†
    for i0 in (0..n).step_by(block_size) {
        for j0 in (0..n).step_by(block_size) {
            for k0 in (0..n).step_by(block_size) {
                // ãƒ–ãƒ­ãƒƒã‚¯å†…ã®è¨ˆç®—
                for i in i0..std::cmp::min(i0 + block_size, n) {
                    for j in j0..std::cmp::min(j0 + block_size, n) {
                        let mut sum = c[i * n + j];
                        for k in k0..std::cmp::min(k0 + block_size, n) {
                            sum += a[i * n + k] * b[k * n + j];
                        }
                        c[i * n + j] = sum;
                    }
                }
            }
        }
    }
}
```

**ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã®é¸æŠ**:

- L1 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«åã¾ã‚‹ã‚µã‚¤ã‚º: é€šå¸¸ 32 ï½ 64
- å®Ÿæ¸¬ã§æœ€é©å€¤ã‚’æ±ºå®šï¼ˆCPU ä¾å­˜ï¼‰

**æ€§èƒ½æ”¹å–„**: 1024Ã—1024 è¡Œåˆ—ã§ã€ç´ æœ´ãªå®Ÿè£…ã¨æ¯”ã¹ã¦ **5 ï½ 10 å€** é«˜é€ŸåŒ–

### ãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ

**ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ**ï¼ˆalignmentï¼‰ã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒç‰¹å®šã®ã‚¢ãƒ‰ãƒ¬ã‚¹å¢ƒç•Œã«é…ç½®ã•ã‚Œã‚‹ã“ã¨ã‚’æŒ‡ã—ã¾ã™ã€‚

```rust
use std::alloc::{alloc, Layout};

// 64 ãƒã‚¤ãƒˆã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªç¢ºä¿ï¼ˆSIMD æœ€é©åŒ–ç”¨ï¼‰
unsafe {
    let layout = Layout::from_size_align(1024 * 4, 64).unwrap();
    let ptr = alloc(layout) as *mut f32;

    // ptr ã¯ 64 ãƒã‚¤ãƒˆå¢ƒç•Œã«é…ç½®ã•ã‚Œã‚‹
}
```

**åŠ¹æœ**:

- SIMD å‘½ä»¤ã®åŠ¹ç‡ãŒå‘ä¸Š
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ©ã‚¤ãƒ³ã®å¢ƒç•Œã‚’ã¾ãŸãŒãªã„

## 2.4 BLAS/LAPACK ã®ä»•çµ„ã¿ã¨å½¹å‰²

### BLAS ã®éšå±¤æ§‹é€ 

**BLAS** (Basic Linear Algebra Subprogramsã€åŸºæœ¬ç·šå½¢ä»£æ•°ã‚µãƒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ ) ã¯ã€ç·šå½¢ä»£æ•°æ¼”ç®—ã®æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ [^12]ã€‚

| ãƒ¬ãƒ™ãƒ«      | æ¼”ç®—å†…å®¹         | è¨ˆç®—é‡ | ä»£è¡¨çš„ãªé–¢æ•°    |
| ----------- | ---------------- | ------ | --------------- |
| **Level 1** | ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—     | O(n)   | axpy, dot, norm |
| **Level 2** | è¡Œåˆ—ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ç© | O(nÂ²)  | gemv, ger       |
| **Level 3** | è¡Œåˆ—ãƒ»è¡Œåˆ—ç©     | O(nÂ³)  | gemm, trmm      |

**GEMM** (GEneral Matrix Multiply) ã¯ Level 3 ã®ä¸­æ ¸é–¢æ•°ï¼š

\[
C := \alpha \cdot op(A) \cdot op(B) + \beta \cdot C
\]

ã“ã“ã§ã€\(op(X)\) ã¯ \(X\) ã¾ãŸã¯ \(X^T\)

### ä¸»è¦ãª BLAS å®Ÿè£…

| å®Ÿè£…                 | ç‰¹å¾´                            | æ€§èƒ½     | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹           |
| -------------------- | ------------------------------- | -------- | -------------------- |
| **OpenBLAS**         | ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã€å¹…åºƒã„ CPU å¯¾å¿œ | é«˜       | BSD                  |
| **Intel MKL**        | Intel CPU ã«æœ€é©åŒ–              | æ¥µã‚ã¦é«˜ | å•†ç”¨ï¼ˆæ¡ä»¶ä»˜ãç„¡æ–™ï¼‰ |
| **BLIS**             | ãƒ¢ãƒ€ãƒ³ãªè¨­è¨ˆã€æ‹¡å¼µæ€§            | é«˜       | BSD                  |
| **Apple Accelerate** | macOS æ¨™æº–                      | é«˜       | ç„¡æ–™                 |

### GPU å‘ã‘ BLAS

| å®Ÿè£…        | å¯¾å¿œ GPU    | æ€§èƒ½     | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹           |
| ----------- | ----------- | -------- | -------------------- |
| **cuBLAS**  | NVIDIA      | æ¥µã‚ã¦é«˜ | CUDA Toolkitï¼ˆç„¡æ–™ï¼‰ |
| **rocBLAS** | AMD         | é«˜       | MIT                  |
| **clBLAS**  | OpenCL å¯¾å¿œ | ä¸­       | Apache 2.0           |

**æ€§èƒ½æ¯”è¼ƒ**ï¼ˆ4096Ã—4096 è¡Œåˆ—ç©ã€å˜ç²¾åº¦ï¼‰:

| å®Ÿè£…                 | å®Ÿè¡Œæ™‚é–“ | GFLOPS |
| -------------------- | -------- | ------ |
| ç´ æœ´ãªå®Ÿè£…ï¼ˆCPUï¼‰    | 35000 ms | 4      |
| OpenBLASï¼ˆ16 ã‚³ã‚¢ï¼‰  | 450 ms   | 300    |
| Intel MKLï¼ˆ16 ã‚³ã‚¢ï¼‰ | 320 ms   | 425    |
| cuBLASï¼ˆRTX 4090ï¼‰   | 2.5 ms   | 54000  |

### Rust ã‹ã‚‰ BLAS ã‚’ä½¿ã†

**ndarray-linalg ã‚’ä½¿ã£ãŸä¾‹**:

```rust
use ndarray::{Array2, arr2};
use ndarray_linalg::*;

fn main() {
    // è¡Œåˆ—ã®ä½œæˆ
    let a = arr2(&[[1.0, 2.0], [3.0, 4.0]]);
    let b = arr2(&[[5.0, 6.0], [7.0, 8.0]]);

    // è¡Œåˆ—ç©ï¼ˆå†…éƒ¨ã§ BLAS ã‚’å‘¼ã³å‡ºã™ï¼‰
    let c = a.dot(&b);
    println!("{:?}", c);

    // LUåˆ†è§£ï¼ˆLAPACK ã‚’å‘¼ã³å‡ºã™ï¼‰
    let (lu, pivot) = a.factorize_into().unwrap();

    // å›ºæœ‰å€¤è¨ˆç®—ï¼ˆLAPACK ã‚’å‘¼ã³å‡ºã™ï¼‰
    let eigenvalues = a.eigenvalues().unwrap();
    println!("å›ºæœ‰å€¤: {:?}", eigenvalues);
}
```

**Cargo.toml ã®è¨­å®š**:

```toml
[dependencies]
ndarray = "0.15"
ndarray-linalg = { version = "0.16", features = ["openblas-static"] }

[features]
default = []
intel-mkl = ["ndarray-linalg/intel-mkl-static"]
```

### LAPACK ã®å½¹å‰²

**LAPACK** (Linear Algebra PACKage) ã¯ã€BLAS ã®ä¸Šã«æ§‹ç¯‰ã•ã‚ŒãŸé«˜åº¦ãªç·šå½¢ä»£æ•°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

**ä¸»ãªæ©Ÿèƒ½**:

- é€£ç«‹ä¸€æ¬¡æ–¹ç¨‹å¼ã®æ±‚è§£
- å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—
- ç‰¹ç•°å€¤åˆ†è§£ï¼ˆSVDï¼‰
- QR åˆ†è§£ã€Cholesky åˆ†è§£

**æ©Ÿæ¢°å­¦ç¿’ã§ã®ç”¨é€”**:

- ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰: SVD ã‚’ä½¿ç”¨
- ç·šå½¢å›å¸°: QR åˆ†è§£ã‚„æ­£è¦æ–¹ç¨‹å¼
- ã‚«ãƒ¼ãƒãƒ«æ³•: å›ºæœ‰å€¤åˆ†è§£

### Python ã¨ Rust ã® BLAS åˆ©ç”¨æ¯”è¼ƒ

**Python (NumPy)**:

```python
import numpy as np

# NumPy ã¯è‡ªå‹•çš„ã« BLAS ã‚’ä½¿ç”¨
a = np.random.randn(1000, 1000)
b = np.random.randn(1000, 1000)
c = a @ b  # å†…éƒ¨ã§ BLAS ã® gemm ã‚’å‘¼ã³å‡ºã—

# ã©ã® BLAS ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
np.show_config()
```

**Rust (ndarray)**:

```rust
use ndarray::Array2;
use ndarray_rand::RandomExt;
use ndarray_rand::rand_distr::StandardNormal;

// BLAS feature ã‚’æœ‰åŠ¹ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
let a: Array2<f64> = Array2::random((1000, 1000), StandardNormal);
let b: Array2<f64> = Array2::random((1000, 1000), StandardNormal);
let c = a.dot(&b);  // BLAS æœ‰åŠ¹ãªã‚‰ gemm ã‚’å‘¼ã³å‡ºã—
```

**æ³¨æ„ç‚¹**:

- Rust ã§ã¯ BLAS ã®ãƒªãƒ³ã‚¯ã‚’æ˜ç¤ºçš„ã«è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹
- ãƒ“ãƒ«ãƒ‰æ™‚ã®ä¾å­˜é–¢ä¿‚ãŒè¤‡é›‘ã«ãªã‚‹å ´åˆãŒã‚ã‚‹
- ä¸€åº¦è¨­å®šã™ã‚Œã°ã€Python ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã‚‹

[^11]: Lam, M. S., Rothberg, E. E., & Wolf, M. E. (1991). "The cache performance and optimizations of blocked algorithms." ACM SIGPLAN Notices, 26(4), 63-74.
[^12]: Lawson, C. L., Hanson, R. J., Kincaid, D. R., & Krogh, F. T. (1979). "Basic linear algebra subprograms for Fortran usage." ACM Transactions on Mathematical Software, 5(3), 308-323.

### æ•°å€¤å®‰å®šæ€§ã¨ç²¾åº¦

#### æµ®å‹•å°æ•°ç‚¹æ•°ã®é™ç•Œ

**IEEE 754 æµ®å‹•å°æ•°ç‚¹æ•°**ã®è¡¨ç¾ç¯„å›²ï¼š

| å‹      | ä»®æ•°éƒ¨ | æŒ‡æ•°éƒ¨ | ç²¾åº¦ï¼ˆ10 é€²ï¼‰ | ç¯„å›²       |
| ------- | ------ | ------ | ------------- | ---------- |
| **f32** | 23 bit | 8 bit  | ç´„ 7 æ¡       | Â±3.4Ã—10Â³â¸  |
| **f64** | 52 bit | 11 bit | ç´„ 16 æ¡      | Â±1.8Ã—10Â³â°â¸ |

**ä¸¸ã‚èª¤å·®ã®ä¾‹**:

```rust
fn main() {
    let a: f32 = 0.1 + 0.2;
    let b: f32 = 0.3;
    println!("{} == {}: {}", a, b, a == b);  // false!
    println!("å·®: {}", (a - b).abs());        // 1.490116e-8
}
```

#### Kahan åŠ ç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

å¤§é‡ã®å€¤ã‚’åŠ ç®—ã™ã‚‹éš›ã€**Kahan åŠ ç®—**ï¼ˆè£œå„ŸåŠ ç®—ï¼‰ã§èª¤å·®ã‚’æ¸›ã‚‰ã›ã¾ã™ [^13]ã€‚

```rust
// ç´ æœ´ãªåŠ ç®—ï¼ˆèª¤å·®ãŒè“„ç©ï¼‰
fn sum_naive(values: &[f32]) -> f32 {
    values.iter().sum()
}

// Kahan åŠ ç®—ï¼ˆèª¤å·®è£œå„Ÿï¼‰
fn sum_kahan(values: &[f32]) -> f32 {
    let mut sum = 0.0;
    let mut compensation = 0.0;  // èª¤å·®ã®è£œå„Ÿé …

    for &value in values {
        let y = value - compensation;
        let t = sum + y;
        compensation = (t - sum) - y;
        sum = t;
    }
    sum
}

// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
fn main() {
    let values: Vec<f32> = (0..1_000_000).map(|i| 1.0 / (i as f32 + 1.0)).collect();

    let naive = sum_naive(&values);
    let kahan = sum_kahan(&values);
    let reference = values.iter().map(|&x| x as f64).sum::<f64>() as f32;

    println!("ç´ æœ´ãªåŠ ç®—: {}, èª¤å·®: {:.2e}", naive, (naive - reference).abs());
    println!("KahanåŠ ç®—: {}, èª¤å·®: {:.2e}", kahan, (kahan - reference).abs());
}
```

**çµæœä¾‹**:

- ç´ æœ´ãªåŠ ç®—ã®èª¤å·®: ç´„ 1.2Ã—10â»Â³
- Kahan åŠ ç®—ã®èª¤å·®: ç´„ 3.5Ã—10â»âµï¼ˆç´„ 30 å€æ”¹å–„ï¼‰

#### æ•°å€¤å®‰å®šæ€§ã®ä¾‹ï¼šã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°

**ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹**ã¯æ·±å±¤å­¦ç¿’ã®å‡ºåŠ›å±¤ã§ã‚ˆãä½¿ã‚ã‚Œã¾ã™ï¼š

\[
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}
\]

**å•é¡Œ**: \(x_i\) ãŒå¤§ãã„ã¨ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã€å°ã•ã„ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼

**å®‰å®šåŒ–æ‰‹æ³•**: æœ€å¤§å€¤ã‚’å¼•ã

\[
\text{softmax}(x_i) = \frac{e^{x_i - \max(x)}}{\sum_j e^{x_j - \max(x)}}
\]

```rust
use ndarray::{Array1, Axis};

// ä¸å®‰å®šãªå®Ÿè£…
fn softmax_unstable(x: &Array1<f32>) -> Array1<f32> {
    let exp_x = x.mapv(|v| v.exp());
    let sum = exp_x.sum();
    exp_x / sum
}

// å®‰å®šãªå®Ÿè£…
fn softmax_stable(x: &Array1<f32>) -> Array1<f32> {
    let max_x = x.fold(f32::NEG_INFINITY, |a, &b| a.max(b));
    let exp_x = x.mapv(|v| (v - max_x).exp());
    let sum = exp_x.sum();
    exp_x / sum
}

fn main() {
    let x = Array1::from(vec![1000.0, 1001.0, 1002.0]);

    // ä¸å®‰å®šç‰ˆã¯ inf ã«ãªã‚‹
    println!("ä¸å®‰å®š: {:?}", softmax_unstable(&x));  // [NaN, NaN, NaN]

    // å®‰å®šç‰ˆã¯æ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹
    println!("å®‰å®š: {:?}", softmax_stable(&x));      // [0.09, 0.24, 0.67]
}
```

### å®Ÿå‹™çš„ãªæœ€é©åŒ–æˆ¦ç•¥

| æ®µéš                    | æ‰‹æ³•                       | åŠ¹æœ          | å®Ÿè£…ã‚³ã‚¹ãƒˆ |
| ----------------------- | -------------------------- | ------------- | ---------- |
| **1. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ** | æœ€é©ãªè¨ˆç®—é‡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | 10 ï½ 1000 å€ | ä½ï½ä¸­     |
| **2. BLAS/LAPACK åˆ©ç”¨** | æœ€é©åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ´»ç”¨     | 5 ï½ 50 å€    | ä½         |
| **3. ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ** | ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡åŒ–           | 2 ï½ 10 å€    | ä¸­         |
| **4. ä¸¦åˆ—åŒ–**           | ãƒãƒ«ãƒã‚³ã‚¢æ´»ç”¨             | ã‚³ã‚¢æ•°å€      | ä¸­ï½é«˜     |
| **5. SIMD**             | ãƒ™ã‚¯ãƒˆãƒ«å‘½ä»¤               | 2 ï½ 8 å€     | é«˜         |
| **6. GPU ç§»æ¤**         | å¤§è¦æ¨¡ä¸¦åˆ—åŒ–               | 10 ï½ 100 å€  | é«˜         |

**æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:

1. **ã¾ãš BLAS ã‚’ä½¿ã†**ï¼ˆæœ€ã‚‚åŠ¹æœãŒé«˜ãã€ã‚³ã‚¹ãƒˆãŒä½ã„ï¼‰
2. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã§ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®š
3. ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«å¯¾ã—ã¦ä¸Šè¨˜ã®æ‰‹æ³•ã‚’é©ç”¨
4. å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãªã‚‰ GPU ã‚’æ¤œè¨

### ã¾ã¨ã‚

æœ¬ç« ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã§é »å‡ºã™ã‚‹ç·šå½¢ä»£æ•°æ¼”ç®—ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å†…å®¹ã‚’å­¦ã³ã¾ã—ãŸï¼š

**ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ**:

- **ãƒ†ãƒ³ã‚½ãƒ«**: å¤šæ¬¡å…ƒé…åˆ—ã®å½¢çŠ¶ã¨ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ãŒãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã«ç›´çµ
- **GEMM**: è¡Œåˆ—ç©ã¯æ©Ÿæ¢°å­¦ç¿’ã®ä¸­æ ¸æ¼”ç®—ã§ã€BLAS ã«ã‚ˆã‚‹æœ€é©åŒ–ãŒä¸å¯æ¬ 
- **CONV**: ç•³ã¿è¾¼ã¿ã¯è¤‡æ•°ã®å®Ÿè£…æ‰‹æ³•ãŒã‚ã‚Šã€ç”¨é€”ã«å¿œã˜ã¦é¸æŠ
- **ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§ããå·¦å³
- **BLAS/LAPACK**: æœ€é©åŒ–ã•ã‚ŒãŸç·šå½¢ä»£æ•°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ´»ç”¨ãŒé‡è¦
- **æ•°å€¤å®‰å®šæ€§**: æµ®å‹•å°æ•°ç‚¹èª¤å·®ã«æ³¨æ„ã—ã€å®‰å®šåŒ–æ‰‹æ³•ã‚’é©ç”¨

## 2.5 æ•°å€¤å®‰å®šæ€§ã¨ç²¾åº¦

æ©Ÿæ¢°å­¦ç¿’ã®å®Ÿè£…ã§ã¯ã€**æ•°å€¤å®‰å®šæ€§**ãŒäºˆæ¸¬ç²¾åº¦ã‚„ãƒ¢ãƒ‡ãƒ«ã®åæŸæ€§ã«ç›´æ¥å½±éŸ¿ã—ã¾ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€æµ®å‹•å°æ•°ç‚¹æ¼”ç®—ã®ç‰¹æ€§ã‚’ç†è§£ã—ã€å®Ÿè·µçš„ãªå®‰å®šåŒ–æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

### æµ®å‹•å°æ•°ç‚¹æ•°ã®é™ç•Œ

#### IEEE 754 æ¨™æº–

ç¾ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã€**IEEE 754**æ¨™æº–ã«å¾“ã£ãŸæµ®å‹•å°æ•°ç‚¹æ¼”ç®—ã‚’è¡Œã„ã¾ã™ [^14]ã€‚

| å‹ | ãƒ“ãƒƒãƒˆæ•° | æŒ‡æ•°éƒ¨ | ä»®æ•°éƒ¨ | ç²¾åº¦ï¼ˆ10é€²ï¼‰ | ç¯„å›² |
|-----|---------|--------|--------|-------------|------|
| `f32` | 32 | 8 | 23 | ç´„7æ¡ | Â±10<sup>Â±38</sup> |
| `f64` | 64 | 11 | 52 | ç´„16æ¡ | Â±10<sup>Â±308</sup> |
| `f16` | 16 | 5 | 10 | ç´„3æ¡ | Â±10<sup>Â±4</sup> |
| `bf16` | 16 | 8 | 7 | ç´„2æ¡ | Â±10<sup>Â±38</sup> |

[^14]: IEEE Standard for Floating-Point Arithmetic (IEEE 754-2008)

#### æ©Ÿæ¢°ã‚¤ãƒ—ã‚·ãƒ­ãƒ³

**æ©Ÿæ¢°ã‚¤ãƒ—ã‚·ãƒ­ãƒ³**ï¼ˆÎµï¼‰ã¯ã€ã€Œ1.0 + Îµ > 1.0ã€ã¨ãªã‚‹æœ€å°ã®æ­£ã®æ•°ã§ã™ï¼š

```rust
fn main() {
    let eps_f32 = f32::EPSILON;  // ç´„ 1.19e-7
    let eps_f64 = f64::EPSILON;  // ç´„ 2.22e-16
    
    println!("f32 epsilon: {:.3e}", eps_f32);
    println!("f64 epsilon: {:.3e}", eps_f64);
    
    // èª¤å·®ã®è“„ç©
    let mut sum = 0.0f32;
    for _ in 0..10_000_000 {
        sum += 0.1;
    }
    println!("Expected: {}, Actual: {}", 1_000_000.0, sum);
    // Expected: 1000000, Actual: 1000000.06...ï¼ˆèª¤å·®ãŒè“„ç©ï¼‰
}
```

#### æ¡è½ã¡ï¼ˆCancellationï¼‰

è¿‘ã„å€¤ã®æ¸›ç®—ã§æœ‰åŠ¹æ¡æ•°ãŒå¤±ã‚ã‚Œã‚‹ç¾è±¡ï¼š

```rust
fn main() {
    let a = 1.23456789f64;
    let b = 1.23456788f64;
    let diff = a - b;  // 1e-8
    
    // ç›¸å¯¾èª¤å·®ãŒå¤§ãããªã‚‹
    let relative_error = (diff - 1e-8).abs() / 1e-8;
    println!("Relative error: {:.3e}", relative_error);
}
```

### æ•°å€¤ä¸å®‰å®šã®å…¸å‹ä¾‹

#### 1. Softmax é–¢æ•°ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼

**æ•°å¼**:
\[
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}
\]

**å•é¡Œ**: \(x_i\) ãŒå¤§ãã„ã¨ \(e^{x_i}\) ãŒã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼

```rust
// âŒ ä¸å®‰å®šãªå®Ÿè£…
fn softmax_naive(x: &[f64]) -> Vec<f64> {
    let exp_x: Vec<f64> = x.iter().map(|&xi| xi.exp()).collect();
    let sum: f64 = exp_x.iter().sum();
    exp_x.iter().map(|&e| e / sum).collect()
}

// âœ… å®‰å®šãªå®Ÿè£…ï¼ˆLog-Sum-Exp ãƒˆãƒªãƒƒã‚¯ï¼‰
fn softmax_stable(x: &[f64]) -> Vec<f64> {
    let x_max = x.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
    let exp_x: Vec<f64> = x.iter().map(|&xi| (xi - x_max).exp()).collect();
    let sum: f64 = exp_x.iter().sum();
    exp_x.iter().map(|&e| e / sum).collect()
}

fn main() {
    let x = vec![1000.0, 1001.0, 999.0];
    
    // softmax_naive(&x);  // ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ï¼
    let result = softmax_stable(&x);
    println!("{:?}", result);  // [0.244, 0.665, 0.090]
}
```

**æ•°å­¦çš„è§£èª¬**:
\[
\text{softmax}(x_i) = \frac{e^{x_i - c}}{\sum_{j} e^{x_j - c}}
\]
ã“ã“ã§ \(c = \max(x)\) ã¨ã™ã‚Œã°ã€\(x_i - c \leq 0\) ã¨ãªã‚Šã€ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ã’ã¾ã™ã€‚

#### 2. ãƒ­ã‚°å’ŒæŒ‡æ•°ï¼ˆLog-Sum-Expï¼‰

```rust
// âŒ ä¸å®‰å®š
fn logsumexp_naive(x: &[f64]) -> f64 {
    x.iter().map(|&xi| xi.exp()).sum::<f64>().ln()
}

// âœ… å®‰å®š
fn logsumexp_stable(x: &[f64]) -> f64 {
    let x_max = x.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
    let sum = x.iter().map(|&xi| (xi - x_max).exp()).sum::<f64>();
    x_max + sum.ln()
}
```

**æ•°å¼**:
\[
\log \sum_i e^{x_i} = c + \log \sum_i e^{x_i - c}
\]

#### 3. æ¨™æº–åå·®ã®è¨ˆç®—

**ä¸å®‰å®šãª2ãƒ‘ã‚¹æ³•**:
\[
\sigma = \sqrt{\frac{1}{n}\sum_i (x_i - \mu)^2}
\]

```rust
// âŒ 2ãƒ‘ã‚¹ï¼ˆå¹³å‡â†’åˆ†æ•£ï¼‰ã§æ¡è½ã¡ã®å¯èƒ½æ€§
fn std_twopass(x: &[f64]) -> f64 {
    let mean = x.iter().sum::<f64>() / x.len() as f64;
    let variance = x.iter()
        .map(|&xi| (xi - mean).powi(2))
        .sum::<f64>() / x.len() as f64;
    variance.sqrt()
}

// âœ… Welford ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
fn std_welford(x: &[f64]) -> f64 {
    let mut mean = 0.0;
    let mut m2 = 0.0;
    
    for (i, &xi) in x.iter().enumerate() {
        let delta = xi - mean;
        mean += delta / (i + 1) as f64;
        let delta2 = xi - mean;
        m2 += delta * delta2;
    }
    
    (m2 / x.len() as f64).sqrt()
}
```

**Welfordã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åˆ©ç‚¹**:
- 1ãƒ‘ã‚¹ã§è¨ˆç®—å¯èƒ½
- æ•°å€¤çš„ã«å®‰å®š
- ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰è¨ˆç®—ãŒå¯èƒ½

### æ··åˆç²¾åº¦å­¦ç¿’

**Mixed Precision Training** [^15] ã¯ã€FP16ï¼ˆåŠç²¾åº¦ï¼‰ã¨FP32ï¼ˆå˜ç²¾åº¦ï¼‰ã‚’çµ„ã¿åˆã‚ã›ã¦ã€é€Ÿåº¦ã¨ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã—ãªãŒã‚‰ç²¾åº¦ã‚’ä¿ã¤æ‰‹æ³•ã§ã™ã€‚

[^15]: Micikevicius, P., et al. (2017). "Mixed Precision Training." https://arxiv.org/abs/1710.03740

#### ç²¾åº¦æ¯”è¼ƒ

| å‹ | ãƒ¡ãƒ¢ãƒª | è¨ˆç®—é€Ÿåº¦ | ç²¾åº¦ | ä¸»ãªç”¨é€” |
|----|--------|---------|------|----------|
| FP64 | 8 bytes | 1x | æœ€é«˜ | ç§‘å­¦è¨ˆç®— |
| FP32 | 4 bytes | 2x | é«˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
| FP16 | 2 bytes | 4-8x | ä¸­ | é †ä¼æ’­ |
| BF16 | 2 bytes | 4-8x | ä¸­é«˜ | å­¦ç¿’å…¨ä½“ |

**BFloat16ï¼ˆBrain Float16ï¼‰** ã¯ã€GoogleãŒTPUå‘ã‘ã«é–‹ç™ºã—ãŸå½¢å¼ã§ã€FP32ã¨åŒã˜æŒ‡æ•°éƒ¨ç¯„å›²ã‚’æŒã¤ãŸã‚ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã—ã«ãã„ç‰¹æ€§ãŒã‚ã‚Šã¾ã™ã€‚

#### å®Ÿè£…ä¾‹ï¼ˆæ¦‚å¿µï¼‰

```rust
struct MixedPrecisionTrainer {
    model_fp32: Model,      // ãƒã‚¹ã‚¿ãƒ¼é‡ã¿ï¼ˆFP32ï¼‰
    model_fp16: Model,      // è¨ˆç®—ç”¨é‡ã¿ï¼ˆFP16ï¼‰
    loss_scale: f32,        // æå¤±ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
}

impl MixedPrecisionTrainer {
    fn train_step(&mut self, x: Tensor, y: Tensor) {
        // 1. FP16ã§é †ä¼æ’­
        let pred_fp16 = self.model_fp16.forward(x.to_fp16());
        
        // 2. æå¤±ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢ï¼‰
        let loss = (pred_fp16 - y.to_fp16()).pow(2).mean() * self.loss_scale;
        
        // 3. FP16ã§é€†ä¼æ’­
        let grads_fp16 = loss.backward();
        
        // 4. å‹¾é…ã‚’ã‚¢ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ï¼†FP32ã«å¤‰æ›
        let grads_fp32 = (grads_fp16 / self.loss_scale).to_fp32();
        
        // 5. FP32ã§é‡ã¿æ›´æ–°
        self.model_fp32.update(grads_fp32);
        
        // 6. FP32 â†’ FP16 ã«ã‚³ãƒ”ãƒ¼
        self.model_fp16.copy_from(&self.model_fp32);
    }
}
```

**æå¤±ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**ã®ç†ç”±ï¼š
FP16ã¯æŒ‡æ•°ç¯„å›²ãŒç‹­ã„ãŸã‚ã€å°ã•ãªå‹¾é…ãŒã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ï¼ˆ0ã«ãªã‚‹ï¼‰ã—ã¾ã™ã€‚æå¤±ã‚’1024å€ãªã©ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€å‹¾é…ã‚‚å¤§ãããªã‚Šã€ç²¾åº¦ãŒä¿ãŸã‚Œã¾ã™ã€‚

### æ•°å€¤çš„ã«å®‰å®šãªè¡Œåˆ—æ¼”ç®—

#### LUåˆ†è§£ã®éƒ¨åˆ†ãƒ”ãƒœãƒƒãƒˆé¸æŠ

```rust
use nalgebra as na;

fn solve_linear_system(a: &na::DMatrix<f64>, b: &na::DVector<f64>) -> na::DVector<f64> {
    // âœ… LUåˆ†è§£ï¼ˆéƒ¨åˆ†ãƒ”ãƒœãƒƒãƒˆé¸æŠä»˜ãï¼‰
    let lu = a.clone().lu();
    lu.solve(b).expect("System is singular")
}
```

**ãƒ”ãƒœãƒƒãƒˆé¸æŠ**ã«ã‚ˆã‚Šã€å°ã•ãªæ•°ã§ã®é™¤ç®—ã‚’é¿ã‘ã€æ•°å€¤å®‰å®šæ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚

#### QRåˆ†è§£ã«ã‚ˆã‚‹æœ€å°äºŒä¹—æ³•

```rust
use nalgebra as na;

fn least_squares(a: &na::DMatrix<f64>, b: &na::DVector<f64>) -> na::DVector<f64> {
    // âœ… QRåˆ†è§£ï¼ˆæ­£è¦æ–¹ç¨‹å¼ã‚ˆã‚Šå®‰å®šï¼‰
    let qr = a.clone().qr();
    qr.solve(b).expect("No solution")
}

// âŒ æ­£è¦æ–¹ç¨‹å¼ï¼ˆA^T A ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚æ¡ä»¶æ•°ãŒæ‚ªåŒ–ï¼‰
fn least_squares_unstable(a: &na::DMatrix<f64>, b: &na::DVector<f64>) -> na::DVector<f64> {
    let ata = a.transpose() * a;
    let atb = a.transpose() * b;
    ata.lu().solve(&atb).expect("Singular")
}
```

**æ¡ä»¶æ•°ã®æ‚ªåŒ–**:
\[
\kappa(A^T A) = \kappa(A)^2
\]
æ­£è¦æ–¹ç¨‹å¼ã§ã¯æ¡ä»¶æ•°ãŒ2ä¹—ã«ãªã‚‹ãŸã‚ã€æ•°å€¤èª¤å·®ãŒå¢—å¹…ã•ã‚Œã¾ã™ã€‚

### å®Ÿè·µçš„ãªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

| é …ç›® | ãƒã‚§ãƒƒã‚¯å†…å®¹ | æ¨å¥¨æ‰‹æ³• |
|------|------------|---------|
| **Softmax** | å¤§ããªå€¤ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã—ãªã„ï¼Ÿ | Maxæ¸›ç®— |
| **Log-Sum-Exp** | æ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹ï¼Ÿ | Maxæ¸›ç®— + log |
| **åˆ†æ•£è¨ˆç®—** | 1ãƒ‘ã‚¹ã§å®‰å®šè¨ˆç®—ã§ãã‚‹ï¼Ÿ | Welfordã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  |
| **è¡Œåˆ—åˆ†è§£** | å°ã•ãªæ•°ã§é™¤ç®—ã—ã¦ã„ãªã„ï¼Ÿ | ãƒ”ãƒœãƒƒãƒˆé¸æŠ |
| **æœ€å°äºŒä¹—** | æ­£è¦æ–¹ç¨‹å¼ã‚’é¿ã‘ã¦ã„ã‚‹ï¼Ÿ | QRåˆ†è§£ |
| **æ··åˆç²¾åº¦** | å‹¾é…ãŒã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã—ãªã„ï¼Ÿ | æå¤±ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° |
| **èª¤å·®è“„ç©** | é•·ã„ãƒ«ãƒ¼ãƒ—ã§åŠ ç®—ã—ã¦ã„ã‚‹ï¼Ÿ | KahanåŠ ç®— |

### Pythonã¨ã®æ¯”è¼ƒ

| è¦³ç‚¹ | Python/NumPy | Rust |
|------|-------------|------|
| ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç²¾åº¦ | f64 | æ˜ç¤ºçš„ã«æŒ‡å®š |
| ç²¾åº¦å¤‰æ› | æš—é»™çš„ | æ˜ç¤ºçš„ï¼ˆ`.as_()`, `into()`ï¼‰ |
| ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ | ä¾‹å¤–ï¼ˆ`FloatingPointError`ï¼‰ | ç„¡é™å¤§ï¼ˆ`inf`ï¼‰ |
| NaNå‡¦ç† | ä¼æ’­ã™ã‚‹ãŒè­¦å‘Šã‚ã‚Š | ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ä¼æ’­ |
| æ•°å€¤å®‰å®šæ€§ | NumPyå†…éƒ¨ã§å¯¾å¿œæ¸ˆã¿ | è‡ªå‰ã§å®Ÿè£…å¿…è¦ |

```python
# Python: NumPyã¯è‡ªå‹•çš„ã«å®‰å®šãªå®Ÿè£…
import numpy as np
x = np.array([1000, 1001, 999])
result = np.exp(x) / np.exp(x).sum()  # NumPyãŒå†…éƒ¨ã§å®‰å®šåŒ–
```

```rust
// Rust: æ˜ç¤ºçš„ã«å®‰å®šåŒ–ãŒå¿…è¦
let x = vec![1000.0, 1001.0, 999.0];
let result = softmax_stable(&x);  // è‡ªåˆ†ã§å®Ÿè£…
```

### ã¾ã¨ã‚

**æ•°å€¤å®‰å®šæ€§ã®é‡è¦åŸå‰‡**:
1. **å¤§ããªæ•°ã¨å°ã•ãªæ•°ã®æ¼”ç®—ã‚’é¿ã‘ã‚‹**ï¼ˆæ¡è½ã¡é˜²æ­¢ï¼‰
2. **ãƒ­ã‚°ç©ºé–“ã§è¨ˆç®—**ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢ï¼‰
3. **å®‰å®šãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é¸æŠ**ï¼ˆQRåˆ†è§£ > æ­£è¦æ–¹ç¨‹å¼ï¼‰
4. **æ··åˆç²¾åº¦ã§ã¯æå¤±ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢ï¼‰
5. **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§æ¤œè¨¼**ï¼ˆæ¥µç«¯ãªå€¤ã§ãƒ†ã‚¹ãƒˆï¼‰

**æ¬¡ç« ã¸ã®æ©‹æ¸¡ã—**:  
ç¬¬ 3 ç« ã§ã¯ã€æ·±å±¤å­¦ç¿’ã®å¿ƒè‡“éƒ¨ã§ã‚ã‚‹**è‡ªå‹•å¾®åˆ†**ï¼ˆAutomatic Differentiationï¼‰ã®ä»•çµ„ã¿ã‚’ã€è¨ˆç®—ã‚°ãƒ©ãƒ•ã€ãƒ†ãƒ¼ãƒ—è¨­è¨ˆã€ãƒ¡ãƒ¢ãƒªç®¡ç†ã®è¦³ç‚¹ã‹ã‚‰è©³è¿°ã—ã¾ã™ã€‚Rust ã®æ‰€æœ‰æ¨©ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«è‡ªå‹•å¾®åˆ†ã®å®Ÿè£…ã«å½¹ç«‹ã¤ã‹ã‚‚è¦‹ã¦ã„ãã¾ã™ã€‚

[^13]: Kahan, W. (1965). "Further remarks on reducing truncation errors." Communications of the ACM, 8(1), 40.
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬1ç« : GPUãƒã‚¤ãƒ†ã‚£ãƒ–æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã‹](01-01-GPUãƒã‚¤ãƒ†ã‚£ãƒ–æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã‹.md) | [â¡ï¸ ç¬¬3ç« : è‡ªå‹•å¾®åˆ†ã®ä»•çµ„ã¿](01-03-è‡ªå‹•å¾®åˆ†ã®ä»•çµ„ã¿.md)