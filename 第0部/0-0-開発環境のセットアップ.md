# ç¬¬ 0 ç« ã€€é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã“ã®ç« ã§ã¯ã€Rustã«ã‚ˆã‚‹GPUæ©Ÿæ¢°å­¦ç¿’é–‹ç™ºã«å¿…è¦ãªç’°å¢ƒæ§‹ç¯‰ã‚’ã€åˆå¿ƒè€…ãŒã¤ã¾ãšãã‚„ã™ã„ãƒã‚¤ãƒ³ãƒˆã‚’å«ã‚ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚PythonçµŒé¨“è€…ãŒã‚¹ãƒ ãƒ¼ã‚ºã«Rust+GPUé–‹ç™ºã«ç§»è¡Œã§ãã‚‹ã‚ˆã†ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§æ¯”è¼ƒã¨èª¬æ˜ã‚’è¡Œã„ã¾ã™ã€‚

**ç›®çš„**: æœ¬æ›¸ã®å­¦ç¿’ã«å¿…è¦ãªãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³ã‚’æ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€æœ€åˆã®GPUãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å‹•ä½œã•ã›ã‚‹ã“ã¨ã§ã€é–‹ç™ºç’°å¢ƒãŒæ­£ã—ãæ§‹ç¯‰ã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚

## 0.1 Rust ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š

### Rust ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

Rustã®å…¬å¼ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼**rustup**ã‚’ä½¿ç”¨ã—ã¦ã€Rustãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

#### Linux / macOS / WSL

```bash
# rustup ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# ã‚·ã‚§ãƒ«è¨­å®šã®èª­ã¿è¾¼ã¿
source $HOME/.cargo/env

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
rustc --version
cargo --version
```

#### Windows

Windowsã§ã¯ã€Visual Studio C++ Build ToolsãŒå¿…è¦ã§ã™ï¼š

1. **Visual Studio Build Tools** ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«  
   https://visualstudio.microsoft.com/visual-cpp-build-tools/  
   â€» ã€ŒC++ã«ã‚ˆã‚‹ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—é–‹ç™ºã€ã‚’é¸æŠ

2. **rustup** ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«  
   https://rustup.rs/ ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å®Ÿè¡Œ

3. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
   ```powershell
   rustc --version
   cargo --version
   ```

### Rust ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

| ã‚³ãƒãƒ³ãƒ‰ | èª¬æ˜ |
|---------|------|
| `rustup update` | æœ€æ–°ç‰ˆã¸æ›´æ–° |
| `rustup default stable` | å®‰å®šç‰ˆã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰ |
| `rustup default nightly` | æœ€æ–°æ©Ÿèƒ½ç‰ˆã‚’ä½¿ç”¨ |
| `rustup show` | ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º |

æœ¬æ›¸ã§ã¯**stableç‰ˆ**ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€ä¸€éƒ¨ã®GPUã‚¯ãƒ¬ãƒ¼ãƒˆã¯nightlyç‰ˆã®æ©Ÿèƒ½ã‚’å¿…è¦ã¨ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

### Python ã¨ã®æ¯”è¼ƒ

| é …ç›® | Python | Rust |
|------|--------|------|
| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ | pip / conda | cargo |
| ä»®æƒ³ç’°å¢ƒ | venv / conda env | ãªã—ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå˜ä½ã§ä¾å­˜ç®¡ç†ï¼‰ |
| ä¾å­˜é–¢ä¿‚ãƒ•ã‚¡ã‚¤ãƒ« | requirements.txt | Cargo.toml |
| ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚é–“ | çŸ­ã„ | ã‚„ã‚„é•·ã„ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãŒå¿…è¦ï¼‰ |

## 0.2 CUDA Toolkit / ROCm ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«ã¯ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ™ãƒ³ãƒ€ãƒ¼ãŒæä¾›ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆãŒå¿…è¦ã§ã™ã€‚

### NVIDIA GPU ã®å ´åˆï¼ˆCUDAï¼‰

#### CUDA Toolkit ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

**å¿…è¦ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶**:
- NVIDIA GPUï¼ˆCompute Capability 3.5ä»¥ä¸Šï¼‰
- Linux / Windows / WSL2
- ååˆ†ãªãƒ‡ã‚£ã‚¹ã‚¯ç©ºãå®¹é‡ï¼ˆ3GBä»¥ä¸Šï¼‰

**ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †**ï¼ˆLinux Ubuntuä¾‹ï¼‰:

```bash
# NVIDIA GPUã®ç¢ºèª
lspci | grep -i nvidia

# ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
nvidia-smi

# CUDA Toolkit 12.x ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-3

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
nvcc --version
```

**Windows ã®å ´åˆ**:
1. CUDA Toolkit ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰  
   https://developer.nvidia.com/cuda-downloads
2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’å®Ÿè¡Œï¼ˆExpress installã‚’æ¨å¥¨ï¼‰
3. ç’°å¢ƒå¤‰æ•°ãŒè‡ªå‹•è¨­å®šã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª

#### cuDNN ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

**cuDNN**ï¼ˆCUDA Deep Neural Network libraryï¼‰[^1] ã¯ã€æ·±å±¤å­¦ç¿’å‘ã‘ã®é«˜åº¦ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

1. NVIDIA Developer Program ã«ç™»éŒ²ï¼ˆç„¡æ–™ï¼‰
   https://developer.nvidia.com/cudnn

2. cuDNN ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆCUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¯¾å¿œã—ãŸã‚‚ã®ï¼‰

3. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆLinuxä¾‹ï¼‰:
   ```bash
   tar -xvf cudnn-linux-x86_64-8.x.x.x_cudaX.Y-archive.tar.xz
   sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda/include
   sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda/lib64
   sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
   ```

#### CUDA ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œè¡¨

| CUDA Toolkit | cuDNN | å¯¾å¿œ GPU Compute Capability | PyTorch äº’æ› |
|--------------|-------|---------------------------|-------------|
| 12.3 | 8.9 | 3.5 - 9.0 | 2.1+ |
| 12.1 | 8.9 | 3.5 - 9.0 | 2.0+ |
| 11.8 | 8.7 | 3.5 - 9.0 | 1.13+ |

[^1]: cuDNN ã¯ç•³ã¿è¾¼ã¿ã€ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã€æ­£è¦åŒ–ã€æ´»æ€§åŒ–é–¢æ•°ãªã©ã®æ¼”ç®—ã‚’æœ€é©åŒ–ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€PyTorchã‚„TensorFlowã®å†…éƒ¨ã§ã‚‚ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™

### AMD GPU ã®å ´åˆï¼ˆROCmï¼‰

**ROCm**ï¼ˆRadeon Open Compute platformï¼‰ã¯ã€AMD GPUå‘ã‘ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è¨ˆç®—ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚

```bash
# ROCm 5.7 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆUbuntu 22.04ä¾‹ï¼‰
wget https://repo.radeon.com/amdgpu-install/5.7/ubuntu/jammy/amdgpu-install_5.7.50700-1_all.deb
sudo apt-get install ./amdgpu-install_5.7.50700-1_all.deb
sudo amdgpu-install --usecase=rocm

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
rocminfo
```

### GPU å‹•ä½œç¢ºèª

#### nvidia-smi ã®èª­ã¿æ–¹

```bash
$ nvidia-smi
```

å‡ºåŠ›ä¾‹:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03   Driver Version: 535.129.03   CUDA Version: 12.2   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA RTX 4090    Off  | 00000000:01:00.0  On |                  Off |
| 30%   45C    P8    20W / 450W |   1024MiB / 24564MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

**é‡è¦ãªé …ç›®**:
- **GPU Name**: GPUå‹ç•ª
- **Memory-Usage**: ç¾åœ¨ã®VRAMä½¿ç”¨é‡ / ç·VRAM
- **GPU-Util**: GPUä½¿ç”¨ç‡ï¼ˆ%ï¼‰
- **Temp**: GPUæ¸©åº¦ï¼ˆâ„ƒï¼‰
- **CUDA Version**: ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ãŒå¯¾å¿œã™ã‚‹CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³

## 0.3 å¿…è¦ãªã‚¯ãƒ¬ãƒ¼ãƒˆã¨ãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³

### Cargo.toml ã®åŸºæœ¬è¨­å®š

Rustãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¾å­˜é–¢ä¿‚ã¯ `Cargo.toml` ã§ç®¡ç†ã—ã¾ã™ã€‚ä»¥ä¸‹ã¯å…¸å‹çš„ãªè¨­å®šä¾‹ã§ã™ï¼š

```toml
[package]
name = "gpu-ml-example"
version = "0.1.0"
edition = "2021"

[dependencies]
# æ•°å€¤è¨ˆç®—
ndarray = "0.15"
num-traits = "0.2"

# CUDA ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
cudarc = { version = "0.10", features = ["cuda-12030"] }

# ç·šå½¢ä»£æ•°
blas-src = { version = "0.10", features = ["openblas"] }
openblas-src = { version = "0.10", features = ["cblas", "system"] }

# ä¸¦åˆ—å‡¦ç†
rayon = "1.8"

# ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

[dev-dependencies]
criterion = "0.5"  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

[profile.release]
opt-level = 3
lto = true  # Link-Time Optimization
codegen-units = 1
```

### ä¸»è¦ã‚¯ãƒ¬ãƒ¼ãƒˆã®èª¬æ˜

#### æ•°å€¤è¨ˆç®—ãƒ»ç·šå½¢ä»£æ•°

| ã‚¯ãƒ¬ãƒ¼ãƒˆ | ç”¨é€” | Python å¯¾å¿œ |
|---------|------|------------|
| `ndarray` | å¤šæ¬¡å…ƒé…åˆ— | NumPy |
| `nalgebra` | ç·šå½¢ä»£æ•°æ¼”ç®— | NumPy/SciPy |
| `blas-src` | BLAS ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ | NumPyï¼ˆå†…éƒ¨ï¼‰ |

#### GPU ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°

| ã‚¯ãƒ¬ãƒ¼ãƒˆ | ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ | ç‰¹å¾´ |
|---------|------------|------|
| `cudarc` | CUDA | Rust-native CUDA ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚° |
| `cust` | CUDA | é«˜ãƒ¬ãƒ™ãƒ«CUDA API |
| `wgpu` | Vulkan/Metal/DX12 | ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  |
| `rust-gpu` | SPIR-V | Rustã§GPUã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã‚’è¨˜è¿° |

#### æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

| ã‚¯ãƒ¬ãƒ¼ãƒˆ | ç‰¹å¾´ | Python å¯¾å¿œ |
|---------|------|------------|
| `burn` | ãƒ¢ãƒ€ãƒ³ãªML ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | PyTorché¢¨ |
| `candle` | è»½é‡MLãƒ©ã‚¤ãƒ–ãƒ©ãƒª | - |
| `tch-rs` | PyTorch ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚° | PyTorch |
| `dfdx` | å‹å®‰å…¨ãªè‡ªå‹•å¾®åˆ† | - |

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ

```bash
# æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
cargo new gpu-ml-example
cd gpu-ml-example

# ãƒ“ãƒ«ãƒ‰ã¨å®Ÿè¡Œ
cargo build --release
cargo run --release

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
cargo test

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
cargo bench
```

### Python ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã®é•ã„

| æ“ä½œ | Python | Rust |
|------|--------|------|
| ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ | `mkdir project` | `cargo new project` |
| ä¾å­˜è¿½åŠ  | `pip install numpy` | `Cargo.toml`ã«è¨˜è¿° |
| å®Ÿè¡Œ | `python main.py` | `cargo run` |
| ãƒ†ã‚¹ãƒˆ | `pytest` | `cargo test` |
| å‹ãƒã‚§ãƒƒã‚¯ | `mypy`ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ | è‡ªå‹•ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ï¼‰ |

## 0.4 Hello World: æœ€åˆã® GPU ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

### CPUç‰ˆã®å®Ÿè£…

ã¾ãšã€CPUã§ã®è¡Œåˆ—ç©ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```rust
// src/main.rs
use ndarray::{Array2, Zip};
use std::time::Instant;

fn matmul_cpu(a: &Array2<f32>, b: &Array2<f32>) -> Array2<f32> {
    let (m, k) = a.dim();
    let (_, n) = b.dim();
    let mut c = Array2::zeros((m, n));
    
    for i in 0..m {
        for j in 0..n {
            let mut sum = 0.0;
            for p in 0..k {
                sum += a[[i, p]] * b[[p, j]];
            }
            c[[i, j]] = sum;
        }
    }
    c
}

fn main() {
    let n = 1024;
    let a = Array2::<f32>::from_elem((n, n), 1.0);
    let b = Array2::<f32>::from_elem((n, n), 2.0);
    
    let start = Instant::now();
    let c = matmul_cpu(&a, &b);
    let duration = start.elapsed();
    
    println!("CPU: {:?}", duration);
    println!("Result sample: c[0,0] = {}", c[[0, 0]]);
}
```

### GPUç‰ˆã®å®Ÿè£…ï¼ˆCUDAï¼‰

æ¬¡ã«ã€CUDAã‚’ä½¿ã£ãŸGPUç‰ˆã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```rust
// Cargo.toml ã«è¿½åŠ 
// cudarc = { version = "0.10", features = ["cuda-12030"] }

use cudarc::driver::*;
use std::sync::Arc;

fn matmul_gpu(a: &[f32], b: &[f32], m: usize, n: usize, k: usize) -> Vec<f32> {
    // GPU ãƒ‡ãƒã‚¤ã‚¹ã®åˆæœŸåŒ–
    let device = CudaDevice::new(0).unwrap();
    
    // ã‚«ãƒ¼ãƒãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆPTXå½¢å¼ï¼‰
    let ptx = compile_ptx(r#"
        extern "C" __global__ void matmul(
            const float* A, const float* B, float* C,
            int M, int N, int K
        ) {
            int row = blockIdx.y * blockDim.y + threadIdx.y;
            int col = blockIdx.x * blockDim.x + threadIdx.x;
            
            if (row < M && col < N) {
                float sum = 0.0f;
                for (int i = 0; i < K; i++) {
                    sum += A[row * K + i] * B[i * N + col];
                }
                C[row * N + col] = sum;
            }
        }
    "#).unwrap();
    
    device.load_ptx(ptx, "matmul_module", &["matmul"]).unwrap();
    
    // ãƒ‡ãƒ¼ã‚¿ã‚’GPUãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼
    let a_gpu = device.htod_copy(a.to_vec()).unwrap();
    let b_gpu = device.htod_copy(b.to_vec()).unwrap();
    let mut c_gpu = device.alloc_zeros::<f32>(m * n).unwrap();
    
    // ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œè¨­å®š
    let block_dim = (16, 16, 1);
    let grid_dim = ((n + 15) / 16, (m + 15) / 16, 1);
    
    // ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
    let f = device.get_func("matmul_module", "matmul").unwrap();
    unsafe {
        f.launch(
            LaunchConfig { grid_dim, block_dim, shared_mem_bytes: 0 },
            (&a_gpu, &b_gpu, &mut c_gpu, m as i32, n as i32, k as i32)
        ).unwrap();
    }
    
    // çµæœã‚’CPUãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼
    device.dtoh_sync_copy(&c_gpu).unwrap()
}

fn main() {
    let n = 1024;
    let a = vec![1.0f32; n * n];
    let b = vec![2.0f32; n * n];
    
    let start = std::time::Instant::now();
    let c = matmul_gpu(&a, &b, n, n, n);
    let duration = start.elapsed();
    
    println!("GPU: {:?}", duration);
    println!("Result sample: c[0] = {}", c[0]);
}
```

### æ€§èƒ½æ¯”è¼ƒ

å…¸å‹çš„ãªå®Ÿè¡Œçµæœï¼ˆ1024Ã—1024è¡Œåˆ—ç©ï¼‰:

| å®Ÿè£… | å®Ÿè¡Œæ™‚é–“ | é«˜é€ŸåŒ–ç‡ |
|------|---------|---------|
| CPUï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ | ~2000 ms | 1x |
| CPUï¼ˆrayonä¸¦åˆ—ï¼‰ | ~50 ms | 40x |
| GPUï¼ˆCUDAï¼‰ | ~1.5 ms | 1333x |

**æ•°å¼ã§è¦‹ã‚‹è¨ˆç®—é‡**:

æ¼”ç®—å›æ•°: \( 2 \times n^3 = 2 \times 1024^3 \approx 2.15 \) GFLOPS

GPUæ€§èƒ½: \( \frac{2.15 \text{ GFLOPS}}{0.0015 \text{ s}} \approx 1433 \) GFLOPS

### Python ã¨ã®æ¯”è¼ƒ

```python
# Python + NumPy
import numpy as np
import time

n = 1024
a = np.ones((n, n), dtype=np.float32)
b = np.ones((n, n), dtype=np.float32) * 2

start = time.time()
c = np.dot(a, b)
print(f"NumPy: {time.time() - start:.4f}s")

# Python + CuPy (GPU)
import cupy as cp

a_gpu = cp.ones((n, n), dtype=cp.float32)
b_gpu = cp.ones((n, n), dtype=cp.float32) * 2

start = time.time()
c_gpu = cp.dot(a_gpu, b_gpu)
cp.cuda.Stream.null.synchronize()
print(f"CuPy: {time.time() - start:.4f}s")
```

## 0.5 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ FAQ

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•

#### 1. `nvcc not found`

**ç—‡çŠ¶**: CUDAã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒè¦‹ã¤ã‹ã‚‰ãªã„

**è§£æ±ºç­–**:
```bash
# ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèª
echo $PATH | grep cuda

# PATHã«è¿½åŠ 
export PATH=/usr/local/cuda/bin:$PATH
```

#### 2. `libcudart.so: cannot open shared object file`

**ç—‡çŠ¶**: CUDA ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„

**è§£æ±ºç­–**:
```bash
# LD_LIBRARY_PATHã«è¿½åŠ 
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# ã¾ãŸã¯ ldconfig ã§ç™»éŒ²
sudo ldconfig /usr/local/cuda/lib64
```

#### 3. `CUDA error: out of memory`

**ç—‡çŠ¶**: GPU VRAMãŒä¸è¶³

**è§£æ±ºç­–**:
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™
- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ç¸®å°
- `nvidia-smi` ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèª
- ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†

```bash
# GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢
nvidia-smi --gpu-reset
```

#### 4. Rustã®ãƒªãƒ³ã‚¯ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `linking with 'cc' failed`

**è§£æ±ºç­–**ï¼ˆLinuxï¼‰:
```bash
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
sudo apt-get install build-essential pkg-config libssl-dev
```

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

| é …ç›® | ç¢ºèªã‚³ãƒãƒ³ãƒ‰ | æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ› |
|------|------------|--------------|
| Rust | `rustc --version` | `rustc 1.75.0+` |
| Cargo | `cargo --version` | `cargo 1.75.0+` |
| CUDA | `nvcc --version` | `release 12.x` |
| GPU Driver | `nvidia-smi` | ãƒ‰ãƒ©ã‚¤ãƒãƒ¼æƒ…å ±è¡¨ç¤º |
| cuDNN | `ls /usr/local/cuda/include/cudnn*` | ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º |

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯

```rust
// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚³ãƒ¼ãƒ‰ä¾‹
#[cfg(test)]
mod benchmarks {
    use super::*;
    use criterion::{black_box, criterion_group, criterion_main, Criterion};
    
    fn bench_matmul(c: &mut Criterion) {
        let n = 1024;
        let a = Array2::<f32>::from_elem((n, n), 1.0);
        let b = Array2::<f32>::from_elem((n, n), 2.0);
        
        c.bench_function("matmul_cpu", |bencher| {
            bencher.iter(|| {
                matmul_cpu(black_box(&a), black_box(&b))
            });
        });
    }
    
    criterion_group!(benches, bench_matmul);
    criterion_main!(benches);
}
```

å®Ÿè¡Œ:
```bash
cargo bench
```

### FAQ

**Q1: CUDAã¨ROCmã¯åŒæ™‚ã«ä½¿ãˆã¾ã™ã‹ï¼Ÿ**

A: åŒã˜ã‚·ã‚¹ãƒ†ãƒ ã«ä¸¡æ–¹ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ãŒã€å®Ÿè¡Œæ™‚ã«ã©ã¡ã‚‰ã‹ã‚’é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‚„ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ãƒ©ã‚°ã§åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

**Q2: WSL2ã§GPUã¯ä½¿ãˆã¾ã™ã‹ï¼Ÿ**

A: ã¯ã„ã€‚Windows 11ã¨WSL2ã§CUDA on WSLãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚Windowså´ã«CUDAãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€WSLå†…ã§CUDA Toolkitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

**Q3: Rustã®å­¦ç¿’ã‚³ã‚¹ãƒˆã¯é«˜ã„ã§ã™ã‹ï¼Ÿ**

A: æ‰€æœ‰æ¨©ã‚·ã‚¹ãƒ†ãƒ ã®ç†è§£ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ãŒã€ä»¥ä¸‹ã®é †åºã§å­¦ç¿’ã™ã‚‹ã¨åŠ¹ç‡çš„ã§ã™ï¼š
1. åŸºæœ¬æ–‡æ³•ï¼ˆ1-2é€±é–“ï¼‰
2. æ‰€æœ‰æ¨©ãƒ»å€Ÿç”¨ï¼ˆ2-3é€±é–“ï¼‰
3. ãƒˆãƒ¬ã‚¤ãƒˆã¨ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ï¼ˆ1-2é€±é–“ï¼‰
4. GPU ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ˆæœ¬æ›¸ã§å­¦ç¿’ï¼‰

**Q4: ã‚¨ãƒ‡ã‚£ã‚¿ã¯ä½•ã‚’ä½¿ãˆã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ**

A: æ¨å¥¨ã‚¨ãƒ‡ã‚£ã‚¿ï¼š
- **VS Code** + rust-analyzerï¼ˆæœ€ã‚‚äººæ°—ï¼‰
- **IntelliJ IDEA** + Rust Plugin
- **Vim** / **Emacs** + rust-analyzer

**Q5: ãƒ‡ãƒãƒƒã‚°æ–¹æ³•ã¯ï¼Ÿ**

A:
```bash
# ãƒ‡ãƒãƒƒã‚°ãƒ“ãƒ«ãƒ‰ï¼ˆæœ€é©åŒ–ãªã—ã€ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚ã‚Šï¼‰
cargo build

# GDBã§ãƒ‡ãƒãƒƒã‚°
rust-gdb target/debug/gpu-ml-example

# cuda-gdbï¼ˆCUDAå°‚ç”¨ï¼‰
cuda-gdb target/debug/gpu-ml-example
```

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ç’°å¢ƒæ§‹ç¯‰ãŒå®Œäº†ã—ãŸã‚‰ã€ç¬¬Iéƒ¨ã«é€²ã‚“ã§åŸºç¤ç†è«–ã‚’å­¦ã³ã¾ã—ã‚‡ã†ã€‚ç‰¹ã«ç¬¬1ç« ã€ŒGPUãƒã‚¤ãƒ†ã‚£ãƒ–æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã‹ã€ã¯å¿…èª­ã§ã™ã€‚

---

**ç’°å¢ƒæ§‹ç¯‰ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼ã“ã‚Œã§GPUæ©Ÿæ¢°å­¦ç¿’ã®æ—…ãŒå§‹ã¾ã‚Šã¾ã™ ğŸ¦€âš¡**

