[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬7ç« ](03-07-Rustã‹ã‚‰GPUã‚’æ“ä½œã™ã‚‹.md) | [â¡ï¸ ç¬¬9ç« ](../04_ç¬¬IVéƒ¨_æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰/04-09-ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ.md)

---

# ç¬¬ 8 ç« ã€€GPU ãƒ¡ãƒ¢ãƒªç®¡ç†ã¨æœ€é©åŒ–

ã“ã®ç« ã§ã¯ã€GPUãƒ¡ãƒ¢ãƒªã®åŠ¹ç‡çš„ãªç®¡ç†ã¨ã€ãƒ‡ãƒ¼ã‚¿è»¢é€ã®æœ€é©åŒ–æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ãŒGPUæ€§èƒ½ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ã€ã“ã®ç« ã®çŸ¥è­˜ã¯æ¥µã‚ã¦é‡è¦ã§ã™ã€‚

**ç›®çš„**: ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æœ€é©åŒ–ã—ã€ãƒ‡ãƒ¼ã‚¿è»¢é€ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’æœ€å°åŒ–ã™ã‚‹å®Ÿè·µçš„ãªæ‰‹æ³•ã‚’ç¿’å¾—ã—ã¾ã™ã€‚

## 8.1 ãƒ›ã‚¹ãƒˆ â‡” ãƒ‡ãƒã‚¤ã‚¹è»¢é€ã‚³ã‚¹ãƒˆã¨æœ€å°åŒ–æˆ¦ç•¥

### è»¢é€ã‚³ã‚¹ãƒˆã®å®Ÿæ¸¬

**PCIeå¸¯åŸŸå¹…ã®ç†è«–å€¤ã¨å®ŸåŠ¹å€¤**:

| PCIeä¸–ä»£ | ç†è«–å¸¯åŸŸå¹… | å®ŸåŠ¹å¸¯åŸŸå¹…ï¼ˆReadï¼‰ | å®ŸåŠ¹å¸¯åŸŸå¹…ï¼ˆWriteï¼‰ | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
|---------|-----------|------------------|-------------------|----------|
| PCIe 3.0 x16 | 16 GB/s | ~12 GB/s | ~12 GB/s | ~10 Î¼s |
| PCIe 4.0 x16 | 32 GB/s | ~25 GB/s | ~25 GB/s | ~8 Î¼s |
| PCIe 5.0 x16 | 64 GB/s | ~50 GB/s | ~50 GB/s | ~6 Î¼s |
| NVLink (V100) | 300 GB/s | ~280 GB/s | ~280 GB/s | ~2 Î¼s |

**è¨ˆç®—ä¾‹**ï¼ˆ1GBã®ãƒ‡ãƒ¼ã‚¿è»¢é€ï¼‰:

| æ¥ç¶š | è»¢é€æ™‚é–“ | GPUè¨ˆç®—æ™‚é–“ï¼ˆ10 TFLOPSï¼‰ | è»¢é€ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ |
|------|---------|----------------------|----------------|
| PCIe 3.0 | 83 ms | 0.1 ms | **è»¢é€ãŒ830å€é…ã„** |
| PCIe 4.0 | 40 ms | 0.1 ms | è»¢é€ãŒ400å€é…ã„ |
| NVLink | 3.6 ms | 0.1 ms | è»¢é€ãŒ36å€é…ã„ |

**æ•™è¨“**: ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ãŒæœ€é‡è¦

### Pythonï¼ˆPyTorchï¼‰ã§ã®æš—é»™çš„è»¢é€

```python
import torch

# CPUãƒ†ãƒ³ã‚½ãƒ«
x_cpu = torch.randn(1000, 1000)

# GPUè»¢é€ï¼ˆæš—é»™çš„ï¼‰
x_gpu = x_cpu.cuda()  # å†…éƒ¨ã§cudaMemcpy

# è¨ˆç®—
y_gpu = x_gpu @ x_gpu

# CPUè»¢é€ï¼ˆæš—é»™çš„ï¼‰
y_cpu = y_gpu.cpu()  # å†…éƒ¨ã§cudaMemcpy
```

### Rustï¼ˆcudarcï¼‰ã§ã®æ˜ç¤ºçš„è»¢é€

```rust
use cudarc::driver::*;
use std::time::Instant;

fn measure_transfer() -> Result<(), CudaError> {
    let device = CudaDevice::new(0)?;
    let size = 1000 * 1000;
    let data: Vec<f32> = vec![1.0; size];
    
    // H2Dï¼ˆãƒ›ã‚¹ãƒˆ â†’ ãƒ‡ãƒã‚¤ã‚¹ï¼‰è¨ˆæ¸¬
    let start = Instant::now();
    let d_data = device.htod_copy(data.clone())?;
    device.synchronize()?;
    let h2d_time = start.elapsed();
    
    println!("H2D: {:.3} ms ({:.2} GB/s)", 
             h2d_time.as_secs_f64() * 1000.0,
             (size * 4) as f64 / h2d_time.as_secs_f64() / 1e9);
    
    // D2Hï¼ˆãƒ‡ãƒã‚¤ã‚¹ â†’ ãƒ›ã‚¹ãƒˆï¼‰è¨ˆæ¸¬
    let start = Instant::now();
    let result: Vec<f32> = device.dtoh_sync_copy(&d_data)?;
    let d2h_time = start.elapsed();
    
    println!("D2H: {:.3} ms ({:.2} GB/s)", 
             d2h_time.as_secs_f64() * 1000.0,
             (size * 4) as f64 / d2h_time.as_secs_f64() / 1e9);
    
    Ok(())
}
```

### è»¢é€æœ€å°åŒ–ã®æˆ¦ç•¥

| æˆ¦ç•¥ | èª¬æ˜ | å‰Šæ¸›ç‡ | å®Ÿè£…ã‚³ã‚¹ãƒˆ |
|------|------|--------|----------|
| **ãƒ‡ãƒ¼ã‚¿ã®GPUå¸¸é§åŒ–** | å¯èƒ½ãªé™ã‚ŠGPUã«ç½®ã | 90%+ | ä½ |
| **ãƒãƒƒãƒå‡¦ç†** | å°ã•ã„è»¢é€ã‚’ã¾ã¨ã‚ã‚‹ | 50-80% | ä½ |
| **éåŒæœŸè»¢é€** | è¨ˆç®—ã¨è»¢é€ã‚’é‡è¤‡ | å®Ÿè³ª0% | ä¸­ |
| **ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒª** | DMAè»¢é€ã‚’é«˜é€ŸåŒ– | 30-50% | ä½ |
| **Unified Memory** | è‡ªå‹•è»¢é€ | å¤‰å‹• | ä½ |

## 8.2 ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒªãƒ»Unified Memoryãƒ»ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼

### ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒªï¼ˆPinned Memoryï¼‰

**ãƒšãƒ¼ã‚¸ãƒ³ã‚°å¯èƒ½ãƒ¡ãƒ¢ãƒª**ï¼ˆPageable Memoryï¼‰ã¯ã€OSãŒã‚¹ãƒ¯ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã§ãã‚‹ãŸã‚ã€GPUè»¢é€æ™‚ã«ã‚³ãƒ”ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ã€‚

**ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒª**ï¼ˆPinned/Page-locked Memoryï¼‰[^1] ã¯ã€ç‰©ç†ãƒ¡ãƒ¢ãƒªã«å›ºå®šã•ã‚Œã€DMAè»¢é€ãŒå¯èƒ½ã§ã™ã€‚

[^1]: CUDA C++ Programming Guide, Pinned Memory: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#page-locked-host-memory

**æ€§èƒ½æ¯”è¼ƒ**:

| ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ— | è»¢é€å¸¯åŸŸå¹…ï¼ˆPCIe 3.0ï¼‰ | ä½¿ç”¨ä¾‹ |
|------------|---------------------|--------|
| Pageable | ~3 GB/s | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
| Pinned | ~12 GB/s | **4å€é«˜é€Ÿ** |

**Pythonï¼ˆCuPyï¼‰ã§ã®ä½¿ç”¨**:

```python
import cupy as cp

# ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒªç¢ºä¿
pinned_mem = cp.cuda.alloc_pinned_memory(1000 * 1000 * 4)  # 4MB
array = cp.ndarray((1000, 1000), dtype=cp.float32, memptr=pinned_mem)

# é€šå¸¸ã®ãƒ¡ãƒ¢ãƒªã¨ã®æ¯”è¼ƒ
import time

# Pageable ãƒ¡ãƒ¢ãƒª
normal_array = cp.asnumpy(cp.random.randn(1000, 1000, dtype=cp.float32))
start = time.time()
cp.asarray(normal_array)
print(f"Pageable: {(time.time() - start) * 1000:.3f} ms")

# Pinned ãƒ¡ãƒ¢ãƒª
pinned_array = cp.cuda.to_cpu(cp.random.randn(1000, 1000, dtype=cp.float32), 
                               stream=cp.cuda.Stream.null)
```

**Rustï¼ˆcudarcï¼‰ã§ã®ä½¿ç”¨**:

```rust
use cudarc::driver::*;

fn pinned_memory_example() -> Result<(), CudaError> {
    let device = CudaDevice::new(0)?;
    let size = 1_000_000;
    
    // é€šå¸¸ã®ãƒ¡ãƒ¢ãƒª
    let normal_data = vec![1.0f32; size];
    
    let start = std::time::Instant::now();
    let gpu1 = device.htod_copy(normal_data.clone())?;
    device.synchronize()?;
    println!("Pageable: {:.3} ms", start.elapsed().as_secs_f64() * 1000.0);
    
    // ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒªï¼ˆcudarc ã¯å†…éƒ¨ã§è‡ªå‹•çš„ã«æœ€é©åŒ–ï¼‰
    // æ‰‹å‹•ã§ãƒ”ãƒ³ç•™ã‚ã™ã‚‹å ´åˆ:
    let pinned = device.alloc_host_pinned(size)?;
    // ... ä½¿ç”¨ ...
    
    Ok(())
}
```

### Unified Memory

**Unified Memory** [^2] ã¯ã€CPUã¨GPUé–“ã§ãƒ¡ãƒ¢ãƒªç©ºé–“ã‚’çµ±ä¸€ã—ã€è‡ªå‹•çš„ã«ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚’è¡Œã„ã¾ã™ã€‚

[^2]: CUDA Unified Memory: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#unified-memory-programming

**ç‰¹å¾´**:

| é …ç›® | æ˜ç¤ºçš„è»¢é€ | Unified Memory |
|------|-----------|---------------|
| ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦ | é«˜ | ä½ |
| æ€§èƒ½ | æœ€é«˜ï¼ˆæ‰‹å‹•æœ€é©åŒ–ï¼‰ | ä¸­ã€œé«˜ï¼ˆè‡ªå‹•æœ€é©åŒ–ï¼‰ |
| ãƒšãƒ¼ã‚¸ãƒ•ã‚©ãƒ«ãƒˆ | ãªã— | ã‚ã‚Šï¼ˆåˆå›ã‚¢ã‚¯ã‚»ã‚¹ï¼‰ |
| ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ | æ‰‹å‹•ç®¡ç† | è‡ªå‹• |

**Pythonï¼ˆPyTorchï¼‰ã¯å†…éƒ¨ã§Unified Memoryã‚’ä½¿ç”¨ã—ã¾ã›ã‚“**ï¼ˆæ˜ç¤ºçš„è»¢é€ã®ã¿ï¼‰

**C++ï¼ˆCUDAï¼‰ã§ã®ä½¿ç”¨**:

```cpp
// Unified Memory ç¢ºä¿
float *data;
cudaMallocManaged(&data, size * sizeof(float));

// CPUã‹ã‚‰æ›¸ãè¾¼ã¿
for (int i = 0; i < size; i++) {
    data[i] = i;
}

// GPUã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆè‡ªå‹•è»¢é€ï¼‰
kernel<<<blocks, threads>>>(data);
cudaDeviceSynchronize();

// CPUã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆè‡ªå‹•è»¢é€ï¼‰
printf("%f\n", data[0]);

cudaFree(data);
```

**Rustã§ã¯ç¾çŠ¶ã€Unified Memoryã®ã‚µãƒãƒ¼ãƒˆã¯é™å®šçš„**ã€‚

### ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ï¼ˆZero-Copyï¼‰

**ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼**ã¯ã€ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒªã‚’ç›´æ¥GPUã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹æŠ€è¡“ã§ã™ [^3]ã€‚

[^3]: ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ãªã—ã§ã€PCIeçµŒç”±ã§ã‚¢ã‚¯ã‚»ã‚¹

**ä½¿ç”¨æ¡ä»¶**:
- å°ã•ã„ãƒ‡ãƒ¼ã‚¿ï¼ˆæ•°KBã€œæ•°MBï¼‰
- èª­ã¿å–ã‚Šå›æ•°ãŒå°‘ãªã„
- è»¢é€ã‚³ã‚¹ãƒˆãŒè¨ˆç®—ã‚³ã‚¹ãƒˆã‚ˆã‚Šå¤§ãã„

**é©ç”¨ä¾‹**:

| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | ã‚³ãƒ”ãƒ¼æ–¹å¼ | ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ | æ¨å¥¨ |
|------------|-----------|-----------|------|
| 1 KB | 0.01 ms | 0.001 ms | ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ |
| 1 MB | 0.1 ms | 0.1 ms | ã©ã¡ã‚‰ã§ã‚‚ |
| 100 MB | 10 ms | 50 ms | ã‚³ãƒ”ãƒ¼ |

**è¨ˆç®—**: å¤§ãã„ãƒ‡ãƒ¼ã‚¿ã¯ä¸€åº¦ã‚³ãƒ”ãƒ¼ã—ãŸæ–¹ãŒã€å¾Œã®ã‚¢ã‚¯ã‚»ã‚¹ãŒé«˜é€Ÿ

## 8.3 ãƒ¡ãƒ¢ãƒªåˆä½“ï¼ˆCoalescingï¼‰ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³

**ãƒ¡ãƒ¢ãƒªåˆä½“**ï¼ˆMemory Coalescingï¼‰ã¯ã€é€£ç¶šã—ãŸãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚’1å›ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã«ã¾ã¨ã‚ã‚‹æœ€é©åŒ–ã§ã™ [^4]ã€‚

[^4]: CUDA C++ Best Practices Guide, Coalesced Access: https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#coalesced-access-to-global-memory

### åˆä½“ã®æ¡ä»¶

ãƒ¯ãƒ¼ãƒ—å†…ã®32ã‚¹ãƒ¬ãƒƒãƒ‰ãŒé€£ç¶šã—ãŸ128ãƒã‚¤ãƒˆé ˜åŸŸï¼ˆ32å€‹ã®floatï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€**1å›ã®ãƒ¡ãƒ¢ãƒªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³**ã§æ¸ˆã¿ã¾ã™ã€‚

**åˆä½“ã‚¢ã‚¯ã‚»ã‚¹ã®ä¾‹**:

```c
// âœ… å®Œå…¨åˆä½“
__global__ void coalesced_read(float* in, float* out, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        out[idx] = in[idx];  // é€£ç¶šã‚¢ã‚¯ã‚»ã‚¹
    }
}
```

**ã‚¹ãƒ¬ãƒƒãƒ‰IDã¨ã‚¢ãƒ‰ãƒ¬ã‚¹ã®å¯¾å¿œ**:

| ã‚¹ãƒ¬ãƒƒãƒ‰ID | ã‚¢ã‚¯ã‚»ã‚¹ã‚¢ãƒ‰ãƒ¬ã‚¹ | ãƒã‚¤ãƒˆ |
|-----------|---------------|--------|
| 0 | `&in[0]` | 0-3 |
| 1 | `&in[1]` | 4-7 |
| ... | ... | ... |
| 31 | `&in[31]` | 124-127 |

â†’ 128ãƒã‚¤ãƒˆãŒ1ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³

**éåˆä½“ã‚¢ã‚¯ã‚»ã‚¹ã®ä¾‹**:

```c
// âŒ éåˆä½“ï¼ˆ32å›ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
__global__ void uncoalesced_read(float* in, float* out, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        out[idx] = in[idx * 32];  // ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰32
    }
}
```

**æ€§èƒ½å·®**ï¼ˆ1å„„è¦ç´ ã®èª­ã¿å–ã‚Šï¼‰:

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | å¸¯åŸŸå¹… | æ™‚é–“ | åŠ¹ç‡ |
|---------|--------|------|------|
| åˆä½“ | 850 GB/s | 0.47 ms | 84% |
| ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰2 | 425 GB/s | 0.94 ms | 42% |
| ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰32 | 27 GB/s | 14.8 ms | 2.7% |

### è¡Œåˆ—è»¢ç½®ã®æœ€é©åŒ–

**å•é¡Œ**: è¡Œåˆ—è»¢ç½®ã¯æœ¬è³ªçš„ã«éåˆä½“ã‚¢ã‚¯ã‚»ã‚¹ã‚’å«ã¿ã¾ã™ã€‚

```c
// âŒ ç´ æœ´ãªè»¢ç½®ï¼ˆæ›¸ãè¾¼ã¿ãŒéåˆä½“ï¼‰
__global__ void transpose_naive(float* in, float* out, int n) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (x < n && y < n) {
        out[x * n + y] = in[y * n + x];  // æ›¸ãè¾¼ã¿ãŒéåˆä½“
    }
}

// âœ… ã‚·ã‚§ã‚¢ãƒ¼ãƒ‰ãƒ¡ãƒ¢ãƒªã‚’ä½¿ã£ãŸæœ€é©åŒ–
__global__ void transpose_optimized(float* in, float* out, int n) {
    __shared__ float tile[32][33];  // +1ã§ãƒãƒ³ã‚¯ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆå›é¿
    
    int x = blockIdx.x * 32 + threadIdx.x;
    int y = blockIdx.y * 32 + threadIdx.y;
    
    // èª­ã¿å–ã‚Šï¼ˆåˆä½“ï¼‰
    if (x < n && y < n) {
        tile[threadIdx.y][threadIdx.x] = in[y * n + x];
    }
    
    __syncthreads();
    
    // è»¢ç½®ã—ã¦æ›¸ãè¾¼ã¿ï¼ˆåˆä½“ï¼‰
    x = blockIdx.y * 32 + threadIdx.x;
    y = blockIdx.x * 32 + threadIdx.y;
    
    if (x < n && y < n) {
        out[y * n + x] = tile[threadIdx.x][threadIdx.y];
    }
}
```

**æ€§èƒ½æ¯”è¼ƒ**ï¼ˆ4096Ã—4096è¡Œåˆ—ï¼‰:

| å®Ÿè£… | å¸¯åŸŸå¹… | æ™‚é–“ |
|------|--------|------|
| ç´ æœ´ãªè»¢ç½® | 45 GB/s | 1.5 ms |
| æœ€é©åŒ–è»¢ç½® | 780 GB/s | 0.09 ms |
| cuBLAS | 850 GB/s | 0.08 ms |

**é«˜é€ŸåŒ–ç‡**: 17å€

### Rust ã§ã®å®Ÿè£…

```rust
use cudarc::driver::*;

const TILE_DIM: usize = 32;

let ptx = compile_ptx(r#"
    extern "C" __global__ void transpose_optimized(
        const float* in, float* out, int n
    ) {
        __shared__ float tile[32][33];
        
        int x = blockIdx.x * 32 + threadIdx.x;
        int y = blockIdx.y * 32 + threadIdx.y;
        
        if (x < n && y < n) {
            tile[threadIdx.y][threadIdx.x] = in[y * n + x];
        }
        
        __syncthreads();
        
        x = blockIdx.y * 32 + threadIdx.x;
        y = blockIdx.x * 32 + threadIdx.y;
        
        if (x < n && y < n) {
            out[y * n + x] = tile[threadIdx.x][threadIdx.y];
        }
    }
"#)?;
```

## 8.4 ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆãƒ»éåŒæœŸå®Ÿè¡Œ

### CUDAã‚¹ãƒˆãƒªãƒ¼ãƒ 

**ã‚¹ãƒˆãƒªãƒ¼ãƒ **ã¯ã€é †åºä»˜ã‘ã‚‰ã‚ŒãŸGPUæ“ä½œã®ã‚­ãƒ¥ãƒ¼ã§ã™ [^5]ã€‚ç•°ãªã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®æ“ä½œã¯ä¸¦è¡Œå®Ÿè¡Œã§ãã¾ã™ã€‚

[^5]: CUDA C++ Programming Guide, Streams: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#streams

**ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ç¨®é¡**:

| ã‚¹ãƒˆãƒªãƒ¼ãƒ  | èª¬æ˜ | ç”¨é€” |
|----------|------|------|
| ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | æš—é»™çš„ã€åŒæœŸçš„ | å˜ç´”ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ  |
| éãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | æ˜ç¤ºçš„ã€éåŒæœŸ | ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŒ– |

**Pythonï¼ˆCuPyï¼‰ã§ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ **:

```python
import cupy as cp

# ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
stream1 = cp.cuda.Stream()
stream2 = cp.cuda.Stream()

with stream1:
    a1 = cp.random.randn(1000, 1000)
    b1 = a1 @ a1

with stream2:
    a2 = cp.random.randn(1000, 1000)
    b2 = a2 @ a2

# ä¸¡æ–¹å®Œäº†ã‚’å¾…ã¤
stream1.synchronize()
stream2.synchronize()
```

**Rustï¼ˆcudarcï¼‰ã§ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ **:

```rust
use cudarc::driver::*;

fn stream_example() -> Result<(), CudaError> {
    let device = CudaDevice::new(0)?;
    
    // ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
    let stream1 = device.fork_default_stream()?;
    let stream2 = device.fork_default_stream()?;
    
    // ãƒ‡ãƒ¼ã‚¿æº–å‚™
    let data1 = vec![1.0f32; 100000];
    let data2 = vec![2.0f32; 100000];
    
    // éåŒæœŸè»¢é€
    let d1 = device.htod_copy_async(data1, &stream1)?;
    let d2 = device.htod_copy_async(data2, &stream2)?;
    
    // ä¸¦è¡Œå®Ÿè¡Œ
    unsafe {
        kernel.launch_on_stream(&stream1, cfg, (&d1,))?;
        kernel.launch_on_stream(&stream2, cfg, (&d2,))?;
    }
    
    // åŒæœŸ
    stream1.synchronize()?;
    stream2.synchronize()?;
    
    Ok(())
}
```

### è¨ˆç®—ã¨è»¢é€ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŒ–

**3æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**:

```mermaid
gantt
    title ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«ã‚ˆã‚‹ä¸¦è¡Œå®Ÿè¡Œ
    dateFormat X
    axisFormat %L
    
    section Stream 0
    H2D_0    :s0h0, 0, 1
    Kernel_0 :s0k0, after s0h0, 1
    D2H_0    :s0d0, after s0k0, 1
    H2D_3    :s0h3, after s0d0, 1
    Kernel_3 :s0k3, after s0h3, 1
    
    section Stream 1
    H2D_1    :s1h1, 1, 1
    Kernel_1 :s1k1, after s1h1, 1
    D2H_1    :s1d1, after s1k1, 1
    H2D_4    :s1h4, after s1d1, 1
    
    section Stream 2
    H2D_2    :s2h2, 2, 1
    Kernel_2 :s2k2, after s2h2, 1
    D2H_2    :s2d2, after s2k2, 1
```

**å‡¡ä¾‹**:
- H2D: Host to Device è»¢é€
- Kernel: GPUè¨ˆç®—
- D2H: Device to Host è»¢é€

**å®Ÿè£…ä¾‹**:

```rust
fn pipelined_processing() -> Result<(), CudaError> {
    let device = CudaDevice::new(0)?;
    let num_streams = 3;
    let batch_size = 10000;
    let num_batches = 30;
    
    // ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
    let streams: Vec<_> = (0..num_streams)
        .map(|_| device.fork_default_stream())
        .collect::<Result<_, _>>()?;
    
    for i in 0..num_batches {
        let stream_idx = i % num_streams;
        let stream = &streams[stream_idx];
        
        // ãƒ‡ãƒ¼ã‚¿æº–å‚™
        let data = vec![i as f32; batch_size];
        
        // H2D
        let d_in = device.htod_copy_async(data, stream)?;
        
        // ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
        unsafe {
            kernel.launch_on_stream(stream, cfg, (&d_in,))?;
        }
        
        // D2H
        let result = device.dtoh_async_copy(&d_in, stream)?;
    }
    
    // å…¨ã‚¹ãƒˆãƒªãƒ¼ãƒ åŒæœŸ
    for stream in streams {
        stream.synchronize()?;
    }
    
    Ok(())
}
```

**æ€§èƒ½æ”¹å–„**:

| å®Ÿè£… | æ™‚é–“ | ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ— |
|------|------|--------------|
| é †æ¬¡å®Ÿè¡Œ | 300 ms | 1x |
| 2ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | 160 ms | 1.9x |
| 3ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | 110 ms | 2.7x |

## 8.5 è¤‡æ•° GPUãƒ»ãƒ‡ãƒã‚¤ã‚¹é¸æŠã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

### ãƒãƒ«ãƒGPU ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°

**PyTorchã§ã®ãƒãƒ«ãƒGPU**:

```python
import torch
import torch.nn as nn

# DataParallelï¼ˆç°¡å˜ã ãŒéåŠ¹ç‡ï¼‰
model = nn.DataParallel(MyModel())
model = model.cuda()

# DistributedDataParallelï¼ˆæ¨å¥¨ï¼‰
model = MyModel().cuda()
model = nn.parallel.DistributedDataParallel(model)
```

**Rustï¼ˆcudarcï¼‰ã§ã®ãƒãƒ«ãƒGPU**:

```rust
use cudarc::driver::*;
use rayon::prelude::*;

fn multi_gpu_processing() -> Result<(), Box<dyn std::error::Error>> {
    let device_count = CudaDevice::count()?;
    println!("Found {} GPUs", device_count);
    
    // å„GPUã§ãƒ‡ãƒã‚¤ã‚¹ä½œæˆ
    let devices: Vec<_> = (0..device_count)
        .map(|i| CudaDevice::new(i))
        .collect::<Result<_, _>>()?;
    
    // ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
    let total_size = 1_000_000;
    let chunk_size = total_size / device_count;
    let data: Vec<f32> = (0..total_size).map(|i| i as f32).collect();
    
    // ä¸¦åˆ—å®Ÿè¡Œï¼ˆrayonï¼‰
    let results: Vec<Vec<f32>> = devices.par_iter()
        .enumerate()
        .map(|(i, device)| {
            let start = i * chunk_size;
            let end = (i + 1) * chunk_size;
            let chunk = &data[start..end];
            
            // GPUå‡¦ç†
            let d_chunk = device.htod_copy(chunk.to_vec()).unwrap();
            // ... ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ ...
            device.dtoh_sync_copy(&d_chunk).unwrap()
        })
        .collect();
    
    // çµæœã‚’ãƒãƒ¼ã‚¸
    let final_result: Vec<f32> = results.into_iter().flatten().collect();
    
    Ok(())
}
```

### P2Pï¼ˆPeer-to-Peerï¼‰è»¢é€

**GPUé–“ç›´æ¥è»¢é€**ï¼ˆNVLinkçµŒç”±ï¼‰:

```rust
fn p2p_transfer() -> Result<(), CudaError> {
    let device0 = CudaDevice::new(0)?;
    let device1 = CudaDevice::new(1)?;
    
    // P2Pã‚¢ã‚¯ã‚»ã‚¹æœ‰åŠ¹åŒ–
    device0.enable_peer_access(&device1)?;
    
    // GPU0ã§ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    let data = vec![1.0f32; 1000000];
    let d0_data = device0.htod_copy(data)?;
    
    // GPU0 â†’ GPU1 ç›´æ¥è»¢é€ï¼ˆNVLinkçµŒç”±ï¼‰
    let d1_data = device1.alloc_zeros::<f32>(1000000)?;
    // cudarc ã§ã¯ p2pè»¢é€ã¯æ‰‹å‹•ã§CUDA APIã‚’å‘¼ã¶å¿…è¦ãŒã‚ã‚‹
    
    Ok(())
}
```

**è»¢é€é€Ÿåº¦æ¯”è¼ƒ**:

| çµŒè·¯ | å¸¯åŸŸå¹… |
|------|--------|
| GPU â†’ CPU â†’ GPU | ~12 GB/sï¼ˆPCIe 3.0ï¼‰ |
| GPU â†’ GPUï¼ˆP2Pã€PCIeï¼‰ | ~12 GB/s |
| GPU â†’ GPUï¼ˆNVLinkï¼‰ | ~300 GB/sï¼ˆ**25å€**ï¼‰ |

## 8.6 ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ãƒ»ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ­ã‚±ãƒ¼ã‚¿

### ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«

é »ç¹ãªãƒ¡ãƒ¢ãƒªç¢ºä¿ãƒ»è§£æ”¾ã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒå¤§ãã„ãŸã‚ã€**ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«**ã§å†åˆ©ç”¨ã—ã¾ã™ã€‚

**PyTorch ã®ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥**:

```python
import torch

# PyTorchã¯å†…éƒ¨ã§ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚’ä½¿ç”¨
for i in range(1000):
    x = torch.randn(1000, 1000).cuda()  # å†åˆ©ç”¨ã•ã‚Œã‚‹
    y = x @ x
    del x, y  # ãƒ¡ãƒ¢ãƒªã¯å³åº§ã«è§£æ”¾ã•ã‚Œãšã€ãƒ—ãƒ¼ãƒ«ã«æˆ»ã‚‹

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
torch.cuda.empty_cache()

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
print(f"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
print(f"Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB")
```

**Rust ã§ã®ç°¡æ˜“ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«**:

```rust
use cudarc::driver::*;
use std::collections::HashMap;

struct GpuMemoryPool {
    device: CudaDevice,
    pool: HashMap<usize, Vec<CudaSlice<f32>>>,
}

impl GpuMemoryPool {
    fn new(device: CudaDevice) -> Self {
        Self {
            device,
            pool: HashMap::new(),
        }
    }
    
    fn alloc(&mut self, size: usize) -> Result<CudaSlice<f32>, CudaError> {
        // ãƒ—ãƒ¼ãƒ«ã‹ã‚‰å–å¾—
        if let Some(buffers) = self.pool.get_mut(&size) {
            if let Some(buffer) = buffers.pop() {
                return Ok(buffer);
            }
        }
        
        // æ–°è¦ç¢ºä¿
        self.device.alloc_zeros(size)
    }
    
    fn free(&mut self, buffer: CudaSlice<f32>) {
        let size = buffer.len();
        self.pool.entry(size).or_insert_with(Vec::new).push(buffer);
    }
}

fn main() {
    let device = CudaDevice::new(0).unwrap();
    let mut pool = GpuMemoryPool::new(device);
    
    for _ in 0..1000 {
        let buf = pool.alloc(1000000).unwrap();
        // ... ä½¿ç”¨ ...
        pool.free(buf);  // ãƒ—ãƒ¼ãƒ«ã«æˆ»ã™
    }
}
```

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–

```rust
use cudarc::driver::*;

fn monitor_memory(device: &CudaDevice) {
    let total = device.total_memory().unwrap();
    let free = device.free_memory().unwrap();
    let used = total - free;
    
    println!("GPU Memory:");
    println!("  Total: {:.2} GB", total as f64 / 1e9);
    println!("  Used:  {:.2} GB ({:.1}%)", 
             used as f64 / 1e9,
             used as f64 / total as f64 * 100.0);
    println!("  Free:  {:.2} GB", free as f64 / 1e9);
}
```

### æœ€é©åŒ–ã®ã¾ã¨ã‚

| æ‰‹æ³• | é©ç”¨å ´é¢ | åŠ¹æœ | å®Ÿè£…é›£åº¦ |
|------|---------|------|---------|
| **ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒª** | é »ç¹ãªè»¢é€ | 4xé«˜é€ŸåŒ– | ä½ |
| **éåŒæœŸè»¢é€** | è¨ˆç®—ã¨è»¢é€ã®é‡è¤‡ | 2-3x | ä¸­ |
| **ãƒ¡ãƒ¢ãƒªåˆä½“** | ã™ã¹ã¦ã®ã‚«ãƒ¼ãƒãƒ« | 10-30x | ä¸­ |
| **ã‚·ã‚§ã‚¢ãƒ¼ãƒ‰ãƒ¡ãƒ¢ãƒª** | ãƒ‡ãƒ¼ã‚¿å†åˆ©ç”¨ | 5-15x | é«˜ |
| **ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«** | é »ç¹ãªç¢ºä¿è§£æ”¾ | 2-5x | ä¸­ |
| **P2Pè»¢é€** | ãƒãƒ«ãƒGPU | 25xï¼ˆNVLinkï¼‰ | ä¸­ |

### Python vs Rust ã®ãƒ¡ãƒ¢ãƒªç®¡ç†

| è¦³ç‚¹ | Python (PyTorch/CuPy) | Rust (cudarc) |
|------|---------------------|--------------|
| è»¢é€ | æš—é»™çš„ | æ˜ç¤ºçš„ |
| ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ« | è‡ªå‹•ï¼ˆå†…è”µï¼‰ | æ‰‹å‹•å®Ÿè£… |
| ã‚¨ãƒ©ãƒ¼å‡¦ç† | ä¾‹å¤– | Resultå‹ |
| ç´°ã‹ã„åˆ¶å¾¡ | é™å®šçš„ | å®Œå…¨ |
| å­¦ç¿’ã‚³ã‚¹ãƒˆ | ä½ | é«˜ |
| æœ€é©åŒ–ã®ä½™åœ° | å° | å¤§ |

**æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:
- **ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—**: Pythonï¼ˆè‡ªå‹•æœ€é©åŒ–ï¼‰
- **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³**: Rustï¼ˆæ‰‹å‹•æœ€é©åŒ–ã§æ¥µé™æ€§èƒ½ï¼‰

æ¬¡ç« ï¼ˆç¬¬IVéƒ¨ï¼‰ã§ã¯ã€ã“ã‚Œã¾ã§ã®çŸ¥è­˜ã‚’çµ±åˆã—ã¦ã€å®Ÿéš›ã®æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

---

## å‚è€ƒæ–‡çŒ®

1. NVIDIA Corporation. "CUDA C++ Programming Guide." https://docs.nvidia.com/cuda/cuda-c-programming-guide/
2. NVIDIA Corporation. "CUDA C++ Best Practices Guide, Chapter 9: Memory Optimizations." https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/
3. Harris, M. (2013). "How to Optimize Data Transfers in CUDA C/C++." NVIDIA Developer Blog.
4. Harris, M. (2012). "How to Overlap Data Transfers in CUDA C/C++." NVIDIA Developer Blog.
5. Ruetsch, G., & Micikevicius, P. (2009). "Optimizing Matrix Transpose in CUDA." NVIDIA SDK.
6. NVIDIA Corporation. "CUDA Unified Memory Programming." https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#unified-memory-programming
7. NVIDIA Corporation. "Multi-GPU Programming." https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#multi-gpu-programming
8. cudarc repository. https://github.com/coreylowman/cudarc
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬7ç« : Rustã‹ã‚‰GPUã‚’æ“ä½œã™ã‚‹](03-07-Rustã‹ã‚‰GPUã‚’æ“ä½œã™ã‚‹.md) | [â¡ï¸ ç¬¬9ç« : ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ](../04_ç¬¬IVéƒ¨_æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰/04-09-ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ.md)