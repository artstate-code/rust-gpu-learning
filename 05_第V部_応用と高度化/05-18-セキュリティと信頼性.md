# 第 15 章　セキュリティと信頼性

この章では、プロダクション環境でのRust機械学習システムのセキュリティと信頼性について学びます。メモリ安全性、FFI境界の監査、テスト戦略、ベンチマーク手法を扱います。

**目的**: 安全で信頼性の高い機械学習システムを構築し、長期間にわたって運用できるようにします。

## 15.1 メモリ安全と GPU クラッシュハンドリング

### GPU クラッシュの原因

| 原因 | 説明 | 検出方法 |
|------|------|---------|
| **Out-of-Bounds Access** | メモリ範囲外アクセス | CUDA Memcheck |
| **Null Pointer Dereference** | nullポインタ参照 | Sanitizers |
| **Race Condition** | データ競合 | cuda-memcheck --tool racecheck |
| **Invalid Memory Access** | 解放済みメモリアクセス | Valgrind |
| **Synchronization Error** | 同期不足 | NSight Compute |

### CUDA エラーハンドリング

**Python（PyTorch）**:

```python
import torch

try:
    # GPU操作
    result = model(input_tensor.cuda())
except RuntimeError as e:
    if "out of memory" in str(e):
        # OOM handling
        torch.cuda.empty_cache()
        print("CUDA out of memory. Clearing cache...")
    elif "CUDA error" in str(e):
        # その他のCUDAエラー
        print(f"CUDA error: {e}")
        torch.cuda.synchronize()  # エラーを同期
```

**Rust（cudarc）**:

```rust
use cudarc::driver::*;
use std::sync::Arc;

#[derive(Debug)]
pub enum GpuError {
    OutOfMemory,
    InvalidDevice,
    LaunchFailed,
    Unknown(String),
}

impl From<DriverError> for GpuError {
    fn from(err: DriverError) -> Self {
        match err {
            DriverError::OutOfMemory => GpuError::OutOfMemory,
            DriverError::InvalidDevice => GpuError::InvalidDevice,
            _ => GpuError::Unknown(err.to_string()),
        }
    }
}

pub struct SafeGpuContext {
    device: Arc<CudaDevice>,
}

impl SafeGpuContext {
    pub fn new(ordinal: usize) -> Result<Self, GpuError> {
        let device = CudaDevice::new(ordinal)
            .map_err(|e| GpuError::from(e))?;
        
        Ok(Self {
            device: Arc::new(device),
        })
    }
    
    pub fn allocate<T: DeviceRepr>(&self, len: usize) -> Result<CudaSlice<T>, GpuError> {
        self.device
            .alloc_zeros::<T>(len)
            .map_err(|e| {
                eprintln!("GPU allocation failed: {:?}", e);
                self.handle_oom();
                GpuError::from(e)
            })
    }
    
    fn handle_oom(&self) {
        // OOM時の対処
        eprintln!("Out of GPU memory. Attempting cleanup...");
        
        // 未使用メモリの解放を試みる
        // Note: cudarc は自動的にDropで解放される
    }
    
    pub fn synchronize(&self) -> Result<(), GpuError> {
        self.device
            .synchronize()
            .map_err(|e| GpuError::from(e))
    }
}

// 使用例
fn safe_gpu_operation() -> Result<(), GpuError> {
    let ctx = SafeGpuContext::new(0)?;
    
    // メモリ割り当て（エラーハンドリング付き）
    let buffer = ctx.allocate::<f32>(1_000_000)?;
    
    // 同期（エラー検出）
    ctx.synchronize()?;
    
    Ok(())
}
```

### Panic Recovery

Rustの`std::panic::catch_unwind`でpanic捕捉:

```rust
use std::panic;

pub fn safe_inference(model: &Model, input: &Tensor) -> Result<Tensor, String> {
    // panicを捕捉
    let result = panic::catch_unwind(panic::AssertUnwindSafe(|| {
        model.forward(input)
    }));
    
    match result {
        Ok(output) => Ok(output),
        Err(e) => {
            // パニック情報をログ
            let err_msg = if let Some(s) = e.downcast_ref::<&str>() {
                s.to_string()
            } else if let Some(s) = e.downcast_ref::<String>() {
                s.clone()
            } else {
                "Unknown panic".to_string()
            };
            
            eprintln!("Model inference panicked: {}", err_msg);
            
            // クリーンアップ処理
            cleanup_gpu_resources();
            
            Err(err_msg)
        }
    }
}

fn cleanup_gpu_resources() {
    // GPU リソースの解放
    // CUDA コンテキストのリセット等
}
```

## 15.2 FFI 境界の監査・unsafe 最小化

### unsafe ブロックの設計原則

**原則**:
1. **最小化**: unsafe ブロックを可能な限り小さく
2. **カプセル化**: unsafe を安全なAPIで包む
3. **文書化**: 安全性の根拠をコメント
4. **検証**: 境界チェック、nullチェック

### 悪い例と良い例

**❌ 悪い例**:

```rust
pub fn matmul_bad(a: &[f32], b: &[f32], c: &mut [f32], m: usize, n: usize, k: usize) {
    unsafe {
        // 大きなunsafeブロック、境界チェックなし
        for i in 0..m {
            for j in 0..n {
                let mut sum = 0.0;
                for p in 0..k {
                    sum += *a.get_unchecked(i * k + p) * *b.get_unchecked(p * n + j);
                }
                *c.get_unchecked_mut(i * n + j) = sum;
            }
        }
    }
}
```

**✅ 良い例**:

```rust
pub fn matmul_safe(a: &[f32], b: &[f32], c: &mut [f32], m: usize, n: usize, k: usize) 
    -> Result<(), String> 
{
    // 境界チェック（safe領域）
    if a.len() != m * k {
        return Err(format!("Invalid shape for a: expected {}, got {}", m * k, a.len()));
    }
    if b.len() != k * n {
        return Err(format!("Invalid shape for b: expected {}, got {}", k * n, b.len()));
    }
    if c.len() != m * n {
        return Err(format!("Invalid shape for c: expected {}, got {}", m * n, c.len()));
    }
    
    // 実装（safe）
    for i in 0..m {
        for j in 0..n {
            let mut sum = 0.0;
            for p in 0..k {
                sum += a[i * k + p] * b[p * n + j];
            }
            c[i * n + j] = sum;
        }
    }
    
    Ok(())
}

// パフォーマンスが必要な場合のみunsafeを使用
pub fn matmul_fast(a: &[f32], b: &[f32], c: &mut [f32], m: usize, n: usize, k: usize) 
    -> Result<(), String> 
{
    // 境界チェック（safe領域）
    if a.len() != m * k || b.len() != k * n || c.len() != m * n {
        return Err("Shape mismatch".to_string());
    }
    
    // unsafeは最小限に
    for i in 0..m {
        for j in 0..n {
            let mut sum = 0.0;
            for p in 0..k {
                // SAFETY: 上の境界チェックにより、インデックスは有効
                unsafe {
                    sum += a.get_unchecked(i * k + p) * b.get_unchecked(p * n + j);
                }
            }
            // SAFETY: 上の境界チェックにより、インデックスは有効
            unsafe {
                *c.get_unchecked_mut(i * n + j) = sum;
            }
        }
    }
    
    Ok(())
}
```

### FFI（Foreign Function Interface）の安全性

**C/CUDA APIのラップ**:

```rust
// CUDA FFI（生のインターフェース）
extern "C" {
    fn cudaMalloc(ptr: *mut *mut std::ffi::c_void, size: usize) -> i32;
    fn cudaFree(ptr: *mut std::ffi::c_void) -> i32;
    fn cudaMemcpy(
        dst: *mut std::ffi::c_void,
        src: *const std::ffi::c_void,
        count: usize,
        kind: i32,
    ) -> i32;
}

// 安全なラッパー
pub struct CudaBuffer<T> {
    ptr: *mut T,
    len: usize,
    _marker: std::marker::PhantomData<T>,
}

impl<T> CudaBuffer<T> {
    pub fn new(len: usize) -> Result<Self, CudaError> {
        let mut ptr: *mut std::ffi::c_void = std::ptr::null_mut();
        let size = len * std::mem::size_of::<T>();
        
        // SAFETY: FFI呼び出し、エラーチェック付き
        let result = unsafe {
            cudaMalloc(&mut ptr as *mut *mut std::ffi::c_void, size)
        };
        
        if result != 0 {
            return Err(CudaError::AllocationFailed(result));
        }
        
        Ok(Self {
            ptr: ptr as *mut T,
            len,
            _marker: std::marker::PhantomData,
        })
    }
    
    pub fn copy_from_host(&mut self, host_data: &[T]) -> Result<(), CudaError> {
        if host_data.len() != self.len {
            return Err(CudaError::SizeMismatch);
        }
        
        let result = unsafe {
            cudaMemcpy(
                self.ptr as *mut std::ffi::c_void,
                host_data.as_ptr() as *const std::ffi::c_void,
                self.len * std::mem::size_of::<T>(),
                1, // cudaMemcpyHostToDevice
            )
        };
        
        if result != 0 {
            return Err(CudaError::CopyFailed(result));
        }
        
        Ok(())
    }
    
    pub fn len(&self) -> usize {
        self.len
    }
}

// RAII: Dropで自動的に解放
impl<T> Drop for CudaBuffer<T> {
    fn drop(&mut self) {
        unsafe {
            let result = cudaFree(self.ptr as *mut std::ffi::c_void);
            if result != 0 {
                eprintln!("cudaFree failed with error code: {}", result);
            }
        }
    }
}

// Sendを実装（スレッド間で転送可能）
unsafe impl<T: Send> Send for CudaBuffer<T> {}

// Syncは実装しない（複数スレッドから同時アクセスは不可）
```

## 15.3 ライブラリ設計における抽象化戦略

### Builder パターン

```rust
pub struct ModelConfig {
    input_dim: usize,
    hidden_dim: usize,
    output_dim: usize,
    dropout: f32,
    activation: Activation,
}

pub struct ModelBuilder {
    input_dim: Option<usize>,
    hidden_dim: Option<usize>,
    output_dim: Option<usize>,
    dropout: f32,
    activation: Activation,
}

impl ModelBuilder {
    pub fn new() -> Self {
        Self {
            input_dim: None,
            hidden_dim: None,
            output_dim: None,
            dropout: 0.0,
            activation: Activation::ReLU,
        }
    }
    
    pub fn input_dim(mut self, dim: usize) -> Self {
        self.input_dim = Some(dim);
        self
    }
    
    pub fn hidden_dim(mut self, dim: usize) -> Self {
        self.hidden_dim = Some(dim);
        self
    }
    
    pub fn output_dim(mut self, dim: usize) -> Self {
        self.output_dim = Some(dim);
        self
    }
    
    pub fn dropout(mut self, rate: f32) -> Self {
        self.dropout = rate.clamp(0.0, 1.0);
        self
    }
    
    pub fn activation(mut self, act: Activation) -> Self {
        self.activation = act;
        self
    }
    
    pub fn build(self) -> Result<Model, String> {
        let input_dim = self.input_dim
            .ok_or("input_dim is required")?;
        let hidden_dim = self.hidden_dim
            .ok_or("hidden_dim is required")?;
        let output_dim = self.output_dim
            .ok_or("output_dim is required")?;
        
        Ok(Model::new(
            input_dim,
            hidden_dim,
            output_dim,
            self.dropout,
            self.activation,
        ))
    }
}

// 使用例
let model = ModelBuilder::new()
    .input_dim(784)
    .hidden_dim(256)
    .output_dim(10)
    .dropout(0.5)
    .activation(Activation::ReLU)
    .build()?;
```

### トレイトによる抽象化

```rust
pub trait Backend: Send + Sync {
    type Tensor;
    type Error;
    
    fn allocate(&self, shape: &[usize]) -> Result<Self::Tensor, Self::Error>;
    fn matmul(&self, a: &Self::Tensor, b: &Self::Tensor) -> Result<Self::Tensor, Self::Error>;
    fn relu(&self, x: &Self::Tensor) -> Result<Self::Tensor, Self::Error>;
}

// CPU バックエンド
pub struct CpuBackend;

impl Backend for CpuBackend {
    type Tensor = Array2<f32>;
    type Error = String;
    
    fn allocate(&self, shape: &[usize]) -> Result<Self::Tensor, Self::Error> {
        if shape.len() != 2 {
            return Err("Only 2D tensors supported".to_string());
        }
        Ok(Array2::zeros((shape[0], shape[1])))
    }
    
    fn matmul(&self, a: &Self::Tensor, b: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        Ok(a.dot(b))
    }
    
    fn relu(&self, x: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        Ok(x.mapv(|v| v.max(0.0)))
    }
}

// GPU バックエンド
pub struct GpuBackend {
    device: Arc<CudaDevice>,
}

impl Backend for GpuBackend {
    type Tensor = CudaSlice<f32>;
    type Error = CudaError;
    
    fn allocate(&self, shape: &[usize]) -> Result<Self::Tensor, Self::Error> {
        let len = shape.iter().product();
        self.device.alloc_zeros(len)
    }
    
    fn matmul(&self, a: &Self::Tensor, b: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        // CUDA GEMM 実装
        todo!()
    }
    
    fn relu(&self, x: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        // CUDA ReLU カーネル
        todo!()
    }
}

// バックエンド非依存のモデル
pub struct Model<B: Backend> {
    backend: B,
    weights: Vec<B::Tensor>,
}

impl<B: Backend> Model<B> {
    pub fn forward(&self, x: &B::Tensor) -> Result<B::Tensor, B::Error> {
        let h = self.backend.matmul(x, &self.weights[0])?;
        let h = self.backend.relu(&h)?;
        let out = self.backend.matmul(&h, &self.weights[1])?;
        Ok(out)
    }
}
```

## 15.4 ベンチマーク・テスト自動化・再現性確保

### Criterion によるベンチマーク

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use ndarray::Array2;

fn matmul_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("matmul");
    
    for size in [64, 128, 256, 512, 1024].iter() {
        group.bench_with_input(
            BenchmarkId::new("naive", size),
            size,
            |b, &size| {
                let a = Array2::<f32>::zeros((size, size));
                let b = Array2::<f32>::zeros((size, size));
                
                b.iter(|| {
                    let _c = black_box(&a).dot(black_box(&b));
                });
            },
        );
        
        group.bench_with_input(
            BenchmarkId::new("blas", size),
            size,
            |b, &size| {
                let a = Array2::<f32>::zeros((size, size));
                let b = Array2::<f32>::zeros((size, size));
                
                b.iter(|| {
                    let _c = black_box(&a).dot(black_box(&b));
                });
            },
        );
    }
    
    group.finish();
}

criterion_group!(benches, matmul_benchmark);
criterion_main!(benches);
```

**実行とレポート**:

```bash
cargo bench

# 出力例:
matmul/naive/64        time:   [12.345 µs 12.456 µs 12.567 µs]
matmul/naive/128       time:   [89.123 µs 89.234 µs 89.345 µs]
matmul/blas/64         time:   [1.234 µs 1.245 µs 1.256 µs]
matmul/blas/128        time:   [8.912 µs 8.923 µs 8.934 µs]
```

### Property-based Testing（Proptest）

```rust
use proptest::prelude::*;
use ndarray::Array2;

proptest! {
    #[test]
    fn test_matmul_associativity(
        m in 1usize..10,
        n in 1usize..10,
        k in 1usize..10,
        p in 1usize..10,
    ) {
        let a = Array2::<f32>::from_shape_fn((m, n), |(i, j)| (i + j) as f32);
        let b = Array2::<f32>::from_shape_fn((n, k), |(i, j)| (i * j) as f32);
        let c = Array2::<f32>::from_shape_fn((k, p), |(i, j)| (i - j) as f32);
        
        // (AB)C = A(BC)
        let ab = a.dot(&b);
        let ab_c = ab.dot(&c);
        
        let bc = b.dot(&c);
        let a_bc = a.dot(&bc);
        
        // 浮動小数点誤差を考慮
        for (x, y) in ab_c.iter().zip(a_bc.iter()) {
            prop_assert!((x - y).abs() < 1e-4);
        }
    }
    
    #[test]
    fn test_relu_properties(x in prop::array::uniform32(-100.0f32..100.0)) {
        let result = relu(&x);
        
        // Property 1: 出力は常に非負
        for &val in result.iter() {
            prop_assert!(val >= 0.0);
        }
        
        // Property 2: 単調性
        for (&input, &output) in x.iter().zip(result.iter()) {
            if input > 0.0 {
                prop_assert_eq!(output, input);
            } else {
                prop_assert_eq!(output, 0.0);
            }
        }
    }
}
```

### 再現性の確保

```rust
use rand::{Rng, SeedableRng};
use rand_chacha::ChaCha8Rng;

pub struct ReproducibleTrainer {
    rng: ChaCha8Rng,
    seed: u64,
}

impl ReproducibleTrainer {
    pub fn new(seed: u64) -> Self {
        Self {
            rng: ChaCha8Rng::seed_from_u64(seed),
            seed,
        }
    }
    
    pub fn initialize_weights(&mut self, shape: (usize, usize)) -> Array2<f32> {
        // 再現可能な初期化
        Array2::from_shape_fn(shape, |_| {
            self.rng.gen_range(-0.1..0.1)
        })
    }
    
    pub fn shuffle_data<T>(&mut self, data: &mut [T]) {
        use rand::seq::SliceRandom;
        data.shuffle(&mut self.rng);
    }
    
    pub fn get_seed(&self) -> u64 {
        self.seed
    }
}

// 使用例
fn reproducible_training() {
    let seed = 42;
    let mut trainer1 = ReproducibleTrainer::new(seed);
    let mut trainer2 = ReproducibleTrainer::new(seed);
    
    // 同じシードなら同じ結果
    let weights1 = trainer1.initialize_weights((10, 10));
    let weights2 = trainer2.initialize_weights((10, 10));
    
    assert_eq!(weights1, weights2);
}
```

## 15.5 Differential Testing と Fuzzing

### Differential Testing

**異なる実装間で結果を比較**:

```rust
#[cfg(test)]
mod differential_tests {
    use super::*;
    
    #[test]
    fn test_matmul_against_numpy() {
        // NumPyの結果をロード
        let numpy_result: Array2<f32> = load_numpy_result("matmul_result.npy");
        
        // Rust実装
        let a = Array2::from_shape_vec((2, 3), vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0]).unwrap();
        let b = Array2::from_shape_vec((3, 2), vec![7.0, 8.0, 9.0, 10.0, 11.0, 12.0]).unwrap();
        let rust_result = a.dot(&b);
        
        // 差分チェック
        for ((r, n), (i, j)) in rust_result.indexed_iter().zip(numpy_result.indexed_iter()) {
            assert!(
                (r - n).abs() < 1e-5,
                "Mismatch at ({}, {}): Rust={}, NumPy={}",
                i,
                j,
                r,
                n
            );
        }
    }
}
```

### Fuzzing（cargo-fuzz）

```rust
// fuzz/fuzz_targets/matmul.rs
#![no_main]
use libfuzzer_sys::fuzz_target;
use ndarray::Array2;

fuzz_target!(|data: &[u8]| {
    // 入力からパラメータを抽出
    if data.len() < 12 {
        return;
    }
    
    let m = (data[0] as usize % 10) + 1;
    let n = (data[1] as usize % 10) + 1;
    let k = (data[2] as usize % 10) + 1;
    
    // ランダムな行列生成
    let a_data: Vec<f32> = data[3..3+m*n]
        .iter()
        .map(|&b| (b as f32) / 255.0)
        .collect();
    
    if a_data.len() != m * n {
        return;
    }
    
    let b_data: Vec<f32> = data[3+m*n..3+m*n+n*k]
        .iter()
        .map(|&b| (b as f32) / 255.0)
        .collect();
    
    if b_data.len() != n * k {
        return;
    }
    
    let a = Array2::from_shape_vec((m, n), a_data).unwrap();
    let b = Array2::from_shape_vec((n, k), b_data).unwrap();
    
    // クラッシュしないことを確認
    let _ = a.dot(&b);
});
```

**実行**:

```bash
cargo install cargo-fuzz
cargo fuzz run matmul
```

---

## まとめ

| 側面 | Python | Rust |
|------|--------|------|
| **メモリ安全性** | GC依存、実行時エラー | コンパイル時保証 |
| **FFI安全性** | ctypes（型チェックなし） | 型安全なFFI |
| **テスト** | pytest, hypothesis | cargo test, proptest |
| **ベンチマーク** | timeit, pytest-benchmark | criterion（統計的） |
| **Fuzzing** | atheris, hypothesis | cargo-fuzz |
| **再現性** | 手動管理 | 型システムで強制可能 |

**Rust の優位性**:
- **コンパイル時安全性**: メモリエラーの大半を事前検出
- **型安全なFFI**: C/CUDAとの境界を型でチェック
- **ゼロコスト**: 安全性チェックのランタイムオーバーヘッドなし

**プロダクション環境での推奨**:
1. **unsafe の最小化**: 必要最小限に留め、境界チェック実装
2. **包括的テスト**: Unit, Integration, Property-based, Differential
3. **CI/CD**: GitHub Actions で自動テスト・ベンチマーク
4. **モニタリング**: Prometheusなどでメトリクス収集
5. **ログ**: 構造化ログ（`tracing` crate）

---

## 参考文献

1. Rust Unsafe Code Guidelines. https://rust-lang.github.io/unsafe-code-guidelines/
2. The Rustonomicon. https://doc.rust-lang.org/nomicon/
3. Proptest Book. https://altsysrq.github.io/proptest-book/
4. Criterion.rs User Guide. https://bheisler.github.io/criterion.rs/book/
5. cargo-fuzz. https://github.com/rust-fuzz/cargo-fuzz
6. Klabnik, S., & Nichols, C. (2019). "The Rust Programming Language." No Starch Press. (Chapter 19: Unsafe Rust)
7. CUDA Runtime API Error Handling. https://docs.nvidia.com/cuda/cuda-runtime-api/
8. Anderson, C. (2020). "Effective Rust." Pragmatic Bookshelf.
9. Gjengset, J. (2021). "Rust for Rustaceans." No Starch Press. (Chapter 9: Unsafe Code)
10. Building Reliable and Scalable Systems in Rust. https://tokio.rs/blog/2021-05-14-inventing-the-service-trait
