[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬17ç« ](05-17-åˆ†æ•£ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿å¯¾å¿œ.md) | [â¡ï¸ ç¬¬19ç« ](../06_ç¬¬VIéƒ¨_ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã¨å®Ÿè·µ/06-19-CNNãƒ»RNNãƒ»Transformerã‚’å®Ÿè£…ã™ã‚‹.md)

---

# ç¬¬ 15 ç« ã€€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ä¿¡é ¼æ€§

ã“ã®ç« ã§ã¯ã€ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®Rustæ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ä¿¡é ¼æ€§ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§ã€FFIå¢ƒç•Œã®ç›£æŸ»ã€ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ‰‹æ³•ã‚’æ‰±ã„ã¾ã™ã€‚

**ç›®çš„**: å®‰å…¨ã§ä¿¡é ¼æ€§ã®é«˜ã„æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€é•·æœŸé–“ã«ã‚ãŸã£ã¦é‹ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

## 15.1 ãƒ¡ãƒ¢ãƒªå®‰å…¨ã¨ GPU ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### GPU ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã®åŸå› 

| åŸå›  | èª¬æ˜ | æ¤œå‡ºæ–¹æ³• |
|------|------|---------|
| **Out-of-Bounds Access** | ãƒ¡ãƒ¢ãƒªç¯„å›²å¤–ã‚¢ã‚¯ã‚»ã‚¹ | CUDA Memcheck |
| **Null Pointer Dereference** | nullãƒã‚¤ãƒ³ã‚¿å‚ç…§ | Sanitizers |
| **Race Condition** | ãƒ‡ãƒ¼ã‚¿ç«¶åˆ | cuda-memcheck --tool racecheck |
| **Invalid Memory Access** | è§£æ”¾æ¸ˆã¿ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ | Valgrind |
| **Synchronization Error** | åŒæœŸä¸è¶³ | NSight Compute |

### CUDA ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**Pythonï¼ˆPyTorchï¼‰**:

```python
import torch

try:
    # GPUæ“ä½œ
    result = model(input_tensor.cuda())
except RuntimeError as e:
    if "out of memory" in str(e):
        # OOM handling
        torch.cuda.empty_cache()
        print("CUDA out of memory. Clearing cache...")
    elif "CUDA error" in str(e):
        # ãã®ä»–ã®CUDAã‚¨ãƒ©ãƒ¼
        print(f"CUDA error: {e}")
        torch.cuda.synchronize()  # ã‚¨ãƒ©ãƒ¼ã‚’åŒæœŸ
```

**Rustï¼ˆcudarcï¼‰**:

```rust
use cudarc::driver::*;
use std::sync::Arc;

#[derive(Debug)]
pub enum GpuError {
    OutOfMemory,
    InvalidDevice,
    LaunchFailed,
    Unknown(String),
}

impl From<DriverError> for GpuError {
    fn from(err: DriverError) -> Self {
        match err {
            DriverError::OutOfMemory => GpuError::OutOfMemory,
            DriverError::InvalidDevice => GpuError::InvalidDevice,
            _ => GpuError::Unknown(err.to_string()),
        }
    }
}

pub struct SafeGpuContext {
    device: Arc<CudaDevice>,
}

impl SafeGpuContext {
    pub fn new(ordinal: usize) -> Result<Self, GpuError> {
        let device = CudaDevice::new(ordinal)
            .map_err(|e| GpuError::from(e))?;
        
        Ok(Self {
            device: Arc::new(device),
        })
    }
    
    pub fn allocate<T: DeviceRepr>(&self, len: usize) -> Result<CudaSlice<T>, GpuError> {
        self.device
            .alloc_zeros::<T>(len)
            .map_err(|e| {
                eprintln!("GPU allocation failed: {:?}", e);
                self.handle_oom();
                GpuError::from(e)
            })
    }
    
    fn handle_oom(&self) {
        // OOMæ™‚ã®å¯¾å‡¦
        eprintln!("Out of GPU memory. Attempting cleanup...");
        
        // æœªä½¿ç”¨ãƒ¡ãƒ¢ãƒªã®è§£æ”¾ã‚’è©¦ã¿ã‚‹
        // Note: cudarc ã¯è‡ªå‹•çš„ã«Dropã§è§£æ”¾ã•ã‚Œã‚‹
    }
    
    pub fn synchronize(&self) -> Result<(), GpuError> {
        self.device
            .synchronize()
            .map_err(|e| GpuError::from(e))
    }
}

// ä½¿ç”¨ä¾‹
fn safe_gpu_operation() -> Result<(), GpuError> {
    let ctx = SafeGpuContext::new(0)?;
    
    // ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
    let buffer = ctx.allocate::<f32>(1_000_000)?;
    
    // åŒæœŸï¼ˆã‚¨ãƒ©ãƒ¼æ¤œå‡ºï¼‰
    ctx.synchronize()?;
    
    Ok(())
}
```

### Panic Recovery

Rustã®`std::panic::catch_unwind`ã§panicæ•æ‰:

```rust
use std::panic;

pub fn safe_inference(model: &Model, input: &Tensor) -> Result<Tensor, String> {
    // panicã‚’æ•æ‰
    let result = panic::catch_unwind(panic::AssertUnwindSafe(|| {
        model.forward(input)
    }));
    
    match result {
        Ok(output) => Ok(output),
        Err(e) => {
            // ãƒ‘ãƒ‹ãƒƒã‚¯æƒ…å ±ã‚’ãƒ­ã‚°
            let err_msg = if let Some(s) = e.downcast_ref::<&str>() {
                s.to_string()
            } else if let Some(s) = e.downcast_ref::<String>() {
                s.clone()
            } else {
                "Unknown panic".to_string()
            };
            
            eprintln!("Model inference panicked: {}", err_msg);
            
            // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
            cleanup_gpu_resources();
            
            Err(err_msg)
        }
    }
}

fn cleanup_gpu_resources() {
    // GPU ãƒªã‚½ãƒ¼ã‚¹ã®è§£æ”¾
    // CUDA ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚»ãƒƒãƒˆç­‰
}
```

## 15.2 FFI å¢ƒç•Œã®ç›£æŸ»ãƒ»unsafe æœ€å°åŒ–

### unsafe ãƒ–ãƒ­ãƒƒã‚¯ã®è¨­è¨ˆåŸå‰‡

**åŸå‰‡**:
1. **æœ€å°åŒ–**: unsafe ãƒ–ãƒ­ãƒƒã‚¯ã‚’å¯èƒ½ãªé™ã‚Šå°ã•ã
2. **ã‚«ãƒ—ã‚»ãƒ«åŒ–**: unsafe ã‚’å®‰å…¨ãªAPIã§åŒ…ã‚€
3. **æ–‡æ›¸åŒ–**: å®‰å…¨æ€§ã®æ ¹æ‹ ã‚’ã‚³ãƒ¡ãƒ³ãƒˆ
4. **æ¤œè¨¼**: å¢ƒç•Œãƒã‚§ãƒƒã‚¯ã€nullãƒã‚§ãƒƒã‚¯

### æ‚ªã„ä¾‹ã¨è‰¯ã„ä¾‹

**âŒ æ‚ªã„ä¾‹**:

```rust
pub fn matmul_bad(a: &[f32], b: &[f32], c: &mut [f32], m: usize, n: usize, k: usize) {
    unsafe {
        // å¤§ããªunsafeãƒ–ãƒ­ãƒƒã‚¯ã€å¢ƒç•Œãƒã‚§ãƒƒã‚¯ãªã—
        for i in 0..m {
            for j in 0..n {
                let mut sum = 0.0;
                for p in 0..k {
                    sum += *a.get_unchecked(i * k + p) * *b.get_unchecked(p * n + j);
                }
                *c.get_unchecked_mut(i * n + j) = sum;
            }
        }
    }
}
```

**âœ… è‰¯ã„ä¾‹**:

```rust
pub fn matmul_safe(a: &[f32], b: &[f32], c: &mut [f32], m: usize, n: usize, k: usize) 
    -> Result<(), String> 
{
    // å¢ƒç•Œãƒã‚§ãƒƒã‚¯ï¼ˆsafeé ˜åŸŸï¼‰
    if a.len() != m * k {
        return Err(format!("Invalid shape for a: expected {}, got {}", m * k, a.len()));
    }
    if b.len() != k * n {
        return Err(format!("Invalid shape for b: expected {}, got {}", k * n, b.len()));
    }
    if c.len() != m * n {
        return Err(format!("Invalid shape for c: expected {}, got {}", m * n, c.len()));
    }
    
    // å®Ÿè£…ï¼ˆsafeï¼‰
    for i in 0..m {
        for j in 0..n {
            let mut sum = 0.0;
            for p in 0..k {
                sum += a[i * k + p] * b[p * n + j];
            }
            c[i * n + j] = sum;
        }
    }
    
    Ok(())
}

// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¿…è¦ãªå ´åˆã®ã¿unsafeã‚’ä½¿ç”¨
pub fn matmul_fast(a: &[f32], b: &[f32], c: &mut [f32], m: usize, n: usize, k: usize) 
    -> Result<(), String> 
{
    // å¢ƒç•Œãƒã‚§ãƒƒã‚¯ï¼ˆsafeé ˜åŸŸï¼‰
    if a.len() != m * k || b.len() != k * n || c.len() != m * n {
        return Err("Shape mismatch".to_string());
    }
    
    // unsafeã¯æœ€å°é™ã«
    for i in 0..m {
        for j in 0..n {
            let mut sum = 0.0;
            for p in 0..k {
                // SAFETY: ä¸Šã®å¢ƒç•Œãƒã‚§ãƒƒã‚¯ã«ã‚ˆã‚Šã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯æœ‰åŠ¹
                unsafe {
                    sum += a.get_unchecked(i * k + p) * b.get_unchecked(p * n + j);
                }
            }
            // SAFETY: ä¸Šã®å¢ƒç•Œãƒã‚§ãƒƒã‚¯ã«ã‚ˆã‚Šã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯æœ‰åŠ¹
            unsafe {
                *c.get_unchecked_mut(i * n + j) = sum;
            }
        }
    }
    
    Ok(())
}
```

### FFIï¼ˆForeign Function Interfaceï¼‰ã®å®‰å…¨æ€§

**C/CUDA APIã®ãƒ©ãƒƒãƒ—**:

```rust
// CUDA FFIï¼ˆç”Ÿã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
extern "C" {
    fn cudaMalloc(ptr: *mut *mut std::ffi::c_void, size: usize) -> i32;
    fn cudaFree(ptr: *mut std::ffi::c_void) -> i32;
    fn cudaMemcpy(
        dst: *mut std::ffi::c_void,
        src: *const std::ffi::c_void,
        count: usize,
        kind: i32,
    ) -> i32;
}

// å®‰å…¨ãªãƒ©ãƒƒãƒ‘ãƒ¼
pub struct CudaBuffer<T> {
    ptr: *mut T,
    len: usize,
    _marker: std::marker::PhantomData<T>,
}

impl<T> CudaBuffer<T> {
    pub fn new(len: usize) -> Result<Self, CudaError> {
        let mut ptr: *mut std::ffi::c_void = std::ptr::null_mut();
        let size = len * std::mem::size_of::<T>();
        
        // SAFETY: FFIå‘¼ã³å‡ºã—ã€ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ä»˜ã
        let result = unsafe {
            cudaMalloc(&mut ptr as *mut *mut std::ffi::c_void, size)
        };
        
        if result != 0 {
            return Err(CudaError::AllocationFailed(result));
        }
        
        Ok(Self {
            ptr: ptr as *mut T,
            len,
            _marker: std::marker::PhantomData,
        })
    }
    
    pub fn copy_from_host(&mut self, host_data: &[T]) -> Result<(), CudaError> {
        if host_data.len() != self.len {
            return Err(CudaError::SizeMismatch);
        }
        
        let result = unsafe {
            cudaMemcpy(
                self.ptr as *mut std::ffi::c_void,
                host_data.as_ptr() as *const std::ffi::c_void,
                self.len * std::mem::size_of::<T>(),
                1, // cudaMemcpyHostToDevice
            )
        };
        
        if result != 0 {
            return Err(CudaError::CopyFailed(result));
        }
        
        Ok(())
    }
    
    pub fn len(&self) -> usize {
        self.len
    }
}

// RAII: Dropã§è‡ªå‹•çš„ã«è§£æ”¾
impl<T> Drop for CudaBuffer<T> {
    fn drop(&mut self) {
        unsafe {
            let result = cudaFree(self.ptr as *mut std::ffi::c_void);
            if result != 0 {
                eprintln!("cudaFree failed with error code: {}", result);
            }
        }
    }
}

// Sendã‚’å®Ÿè£…ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§è»¢é€å¯èƒ½ï¼‰
unsafe impl<T: Send> Send for CudaBuffer<T> {}

// Syncã¯å®Ÿè£…ã—ãªã„ï¼ˆè¤‡æ•°ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ã¯ä¸å¯ï¼‰
```

## 15.3 ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¨­è¨ˆã«ãŠã‘ã‚‹æŠ½è±¡åŒ–æˆ¦ç•¥

### Builder ãƒ‘ã‚¿ãƒ¼ãƒ³

```rust
pub struct ModelConfig {
    input_dim: usize,
    hidden_dim: usize,
    output_dim: usize,
    dropout: f32,
    activation: Activation,
}

pub struct ModelBuilder {
    input_dim: Option<usize>,
    hidden_dim: Option<usize>,
    output_dim: Option<usize>,
    dropout: f32,
    activation: Activation,
}

impl ModelBuilder {
    pub fn new() -> Self {
        Self {
            input_dim: None,
            hidden_dim: None,
            output_dim: None,
            dropout: 0.0,
            activation: Activation::ReLU,
        }
    }
    
    pub fn input_dim(mut self, dim: usize) -> Self {
        self.input_dim = Some(dim);
        self
    }
    
    pub fn hidden_dim(mut self, dim: usize) -> Self {
        self.hidden_dim = Some(dim);
        self
    }
    
    pub fn output_dim(mut self, dim: usize) -> Self {
        self.output_dim = Some(dim);
        self
    }
    
    pub fn dropout(mut self, rate: f32) -> Self {
        self.dropout = rate.clamp(0.0, 1.0);
        self
    }
    
    pub fn activation(mut self, act: Activation) -> Self {
        self.activation = act;
        self
    }
    
    pub fn build(self) -> Result<Model, String> {
        let input_dim = self.input_dim
            .ok_or("input_dim is required")?;
        let hidden_dim = self.hidden_dim
            .ok_or("hidden_dim is required")?;
        let output_dim = self.output_dim
            .ok_or("output_dim is required")?;
        
        Ok(Model::new(
            input_dim,
            hidden_dim,
            output_dim,
            self.dropout,
            self.activation,
        ))
    }
}

// ä½¿ç”¨ä¾‹
let model = ModelBuilder::new()
    .input_dim(784)
    .hidden_dim(256)
    .output_dim(10)
    .dropout(0.5)
    .activation(Activation::ReLU)
    .build()?;
```

### ãƒˆãƒ¬ã‚¤ãƒˆã«ã‚ˆã‚‹æŠ½è±¡åŒ–

```rust
pub trait Backend: Send + Sync {
    type Tensor;
    type Error;
    
    fn allocate(&self, shape: &[usize]) -> Result<Self::Tensor, Self::Error>;
    fn matmul(&self, a: &Self::Tensor, b: &Self::Tensor) -> Result<Self::Tensor, Self::Error>;
    fn relu(&self, x: &Self::Tensor) -> Result<Self::Tensor, Self::Error>;
}

// CPU ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
pub struct CpuBackend;

impl Backend for CpuBackend {
    type Tensor = Array2<f32>;
    type Error = String;
    
    fn allocate(&self, shape: &[usize]) -> Result<Self::Tensor, Self::Error> {
        if shape.len() != 2 {
            return Err("Only 2D tensors supported".to_string());
        }
        Ok(Array2::zeros((shape[0], shape[1])))
    }
    
    fn matmul(&self, a: &Self::Tensor, b: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        Ok(a.dot(b))
    }
    
    fn relu(&self, x: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        Ok(x.mapv(|v| v.max(0.0)))
    }
}

// GPU ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
pub struct GpuBackend {
    device: Arc<CudaDevice>,
}

impl Backend for GpuBackend {
    type Tensor = CudaSlice<f32>;
    type Error = CudaError;
    
    fn allocate(&self, shape: &[usize]) -> Result<Self::Tensor, Self::Error> {
        let len = shape.iter().product();
        self.device.alloc_zeros(len)
    }
    
    fn matmul(&self, a: &Self::Tensor, b: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        // CUDA GEMM å®Ÿè£…
        todo!()
    }
    
    fn relu(&self, x: &Self::Tensor) -> Result<Self::Tensor, Self::Error> {
        // CUDA ReLU ã‚«ãƒ¼ãƒãƒ«
        todo!()
    }
}

// ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰éä¾å­˜ã®ãƒ¢ãƒ‡ãƒ«
pub struct Model<B: Backend> {
    backend: B,
    weights: Vec<B::Tensor>,
}

impl<B: Backend> Model<B> {
    pub fn forward(&self, x: &B::Tensor) -> Result<B::Tensor, B::Error> {
        let h = self.backend.matmul(x, &self.weights[0])?;
        let h = self.backend.relu(&h)?;
        let out = self.backend.matmul(&h, &self.weights[1])?;
        Ok(out)
    }
}
```

## 15.4 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ»ãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–ãƒ»å†ç¾æ€§ç¢ºä¿

### Criterion ã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use ndarray::Array2;

fn matmul_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("matmul");
    
    for size in [64, 128, 256, 512, 1024].iter() {
        group.bench_with_input(
            BenchmarkId::new("naive", size),
            size,
            |b, &size| {
                let a = Array2::<f32>::zeros((size, size));
                let b = Array2::<f32>::zeros((size, size));
                
                b.iter(|| {
                    let _c = black_box(&a).dot(black_box(&b));
                });
            },
        );
        
        group.bench_with_input(
            BenchmarkId::new("blas", size),
            size,
            |b, &size| {
                let a = Array2::<f32>::zeros((size, size));
                let b = Array2::<f32>::zeros((size, size));
                
                b.iter(|| {
                    let _c = black_box(&a).dot(black_box(&b));
                });
            },
        );
    }
    
    group.finish();
}

criterion_group!(benches, matmul_benchmark);
criterion_main!(benches);
```

**å®Ÿè¡Œã¨ãƒ¬ãƒãƒ¼ãƒˆ**:

```bash
cargo bench

# å‡ºåŠ›ä¾‹:
matmul/naive/64        time:   [12.345 Âµs 12.456 Âµs 12.567 Âµs]
matmul/naive/128       time:   [89.123 Âµs 89.234 Âµs 89.345 Âµs]
matmul/blas/64         time:   [1.234 Âµs 1.245 Âµs 1.256 Âµs]
matmul/blas/128        time:   [8.912 Âµs 8.923 Âµs 8.934 Âµs]
```

### Property-based Testingï¼ˆProptestï¼‰

```rust
use proptest::prelude::*;
use ndarray::Array2;

proptest! {
    #[test]
    fn test_matmul_associativity(
        m in 1usize..10,
        n in 1usize..10,
        k in 1usize..10,
        p in 1usize..10,
    ) {
        let a = Array2::<f32>::from_shape_fn((m, n), |(i, j)| (i + j) as f32);
        let b = Array2::<f32>::from_shape_fn((n, k), |(i, j)| (i * j) as f32);
        let c = Array2::<f32>::from_shape_fn((k, p), |(i, j)| (i - j) as f32);
        
        // (AB)C = A(BC)
        let ab = a.dot(&b);
        let ab_c = ab.dot(&c);
        
        let bc = b.dot(&c);
        let a_bc = a.dot(&bc);
        
        // æµ®å‹•å°æ•°ç‚¹èª¤å·®ã‚’è€ƒæ…®
        for (x, y) in ab_c.iter().zip(a_bc.iter()) {
            prop_assert!((x - y).abs() < 1e-4);
        }
    }
    
    #[test]
    fn test_relu_properties(x in prop::array::uniform32(-100.0f32..100.0)) {
        let result = relu(&x);
        
        // Property 1: å‡ºåŠ›ã¯å¸¸ã«éè² 
        for &val in result.iter() {
            prop_assert!(val >= 0.0);
        }
        
        // Property 2: å˜èª¿æ€§
        for (&input, &output) in x.iter().zip(result.iter()) {
            if input > 0.0 {
                prop_assert_eq!(output, input);
            } else {
                prop_assert_eq!(output, 0.0);
            }
        }
    }
}
```

### å†ç¾æ€§ã®ç¢ºä¿

```rust
use rand::{Rng, SeedableRng};
use rand_chacha::ChaCha8Rng;

pub struct ReproducibleTrainer {
    rng: ChaCha8Rng,
    seed: u64,
}

impl ReproducibleTrainer {
    pub fn new(seed: u64) -> Self {
        Self {
            rng: ChaCha8Rng::seed_from_u64(seed),
            seed,
        }
    }
    
    pub fn initialize_weights(&mut self, shape: (usize, usize)) -> Array2<f32> {
        // å†ç¾å¯èƒ½ãªåˆæœŸåŒ–
        Array2::from_shape_fn(shape, |_| {
            self.rng.gen_range(-0.1..0.1)
        })
    }
    
    pub fn shuffle_data<T>(&mut self, data: &mut [T]) {
        use rand::seq::SliceRandom;
        data.shuffle(&mut self.rng);
    }
    
    pub fn get_seed(&self) -> u64 {
        self.seed
    }
}

// ä½¿ç”¨ä¾‹
fn reproducible_training() {
    let seed = 42;
    let mut trainer1 = ReproducibleTrainer::new(seed);
    let mut trainer2 = ReproducibleTrainer::new(seed);
    
    // åŒã˜ã‚·ãƒ¼ãƒ‰ãªã‚‰åŒã˜çµæœ
    let weights1 = trainer1.initialize_weights((10, 10));
    let weights2 = trainer2.initialize_weights((10, 10));
    
    assert_eq!(weights1, weights2);
}
```

## 15.5 Differential Testing ã¨ Fuzzing

### Differential Testing

**ç•°ãªã‚‹å®Ÿè£…é–“ã§çµæœã‚’æ¯”è¼ƒ**:

```rust
#[cfg(test)]
mod differential_tests {
    use super::*;
    
    #[test]
    fn test_matmul_against_numpy() {
        // NumPyã®çµæœã‚’ãƒ­ãƒ¼ãƒ‰
        let numpy_result: Array2<f32> = load_numpy_result("matmul_result.npy");
        
        // Rustå®Ÿè£…
        let a = Array2::from_shape_vec((2, 3), vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0]).unwrap();
        let b = Array2::from_shape_vec((3, 2), vec![7.0, 8.0, 9.0, 10.0, 11.0, 12.0]).unwrap();
        let rust_result = a.dot(&b);
        
        // å·®åˆ†ãƒã‚§ãƒƒã‚¯
        for ((r, n), (i, j)) in rust_result.indexed_iter().zip(numpy_result.indexed_iter()) {
            assert!(
                (r - n).abs() < 1e-5,
                "Mismatch at ({}, {}): Rust={}, NumPy={}",
                i,
                j,
                r,
                n
            );
        }
    }
}
```

### Fuzzingï¼ˆcargo-fuzzï¼‰

```rust
// fuzz/fuzz_targets/matmul.rs
#![no_main]
use libfuzzer_sys::fuzz_target;
use ndarray::Array2;

fuzz_target!(|data: &[u8]| {
    // å…¥åŠ›ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    if data.len() < 12 {
        return;
    }
    
    let m = (data[0] as usize % 10) + 1;
    let n = (data[1] as usize % 10) + 1;
    let k = (data[2] as usize % 10) + 1;
    
    // ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œåˆ—ç”Ÿæˆ
    let a_data: Vec<f32> = data[3..3+m*n]
        .iter()
        .map(|&b| (b as f32) / 255.0)
        .collect();
    
    if a_data.len() != m * n {
        return;
    }
    
    let b_data: Vec<f32> = data[3+m*n..3+m*n+n*k]
        .iter()
        .map(|&b| (b as f32) / 255.0)
        .collect();
    
    if b_data.len() != n * k {
        return;
    }
    
    let a = Array2::from_shape_vec((m, n), a_data).unwrap();
    let b = Array2::from_shape_vec((n, k), b_data).unwrap();
    
    // ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãªã„ã“ã¨ã‚’ç¢ºèª
    let _ = a.dot(&b);
});
```

**å®Ÿè¡Œ**:

```bash
cargo install cargo-fuzz
cargo fuzz run matmul
```

---

## ã¾ã¨ã‚

| å´é¢ | Python | Rust |
|------|--------|------|
| **ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§** | GCä¾å­˜ã€å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ | ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ä¿è¨¼ |
| **FFIå®‰å…¨æ€§** | ctypesï¼ˆå‹ãƒã‚§ãƒƒã‚¯ãªã—ï¼‰ | å‹å®‰å…¨ãªFFI |
| **ãƒ†ã‚¹ãƒˆ** | pytest, hypothesis | cargo test, proptest |
| **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯** | timeit, pytest-benchmark | criterionï¼ˆçµ±è¨ˆçš„ï¼‰ |
| **Fuzzing** | atheris, hypothesis | cargo-fuzz |
| **å†ç¾æ€§** | æ‰‹å‹•ç®¡ç† | å‹ã‚·ã‚¹ãƒ†ãƒ ã§å¼·åˆ¶å¯èƒ½ |

**Rust ã®å„ªä½æ€§**:
- **ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚å®‰å…¨æ€§**: ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã®å¤§åŠã‚’äº‹å‰æ¤œå‡º
- **å‹å®‰å…¨ãªFFI**: C/CUDAã¨ã®å¢ƒç•Œã‚’å‹ã§ãƒã‚§ãƒƒã‚¯
- **ã‚¼ãƒ­ã‚³ã‚¹ãƒˆ**: å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã—

**ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®æ¨å¥¨**:
1. **unsafe ã®æœ€å°åŒ–**: å¿…è¦æœ€å°é™ã«ç•™ã‚ã€å¢ƒç•Œãƒã‚§ãƒƒã‚¯å®Ÿè£…
2. **åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ**: Unit, Integration, Property-based, Differential
3. **CI/CD**: GitHub Actions ã§è‡ªå‹•ãƒ†ã‚¹ãƒˆãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
4. **ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**: Prometheusãªã©ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
5. **ãƒ­ã‚°**: æ§‹é€ åŒ–ãƒ­ã‚°ï¼ˆ`tracing` crateï¼‰

---

## å‚è€ƒæ–‡çŒ®

1. Rust Unsafe Code Guidelines. https://rust-lang.github.io/unsafe-code-guidelines/
2. The Rustonomicon. https://doc.rust-lang.org/nomicon/
3. Proptest Book. https://altsysrq.github.io/proptest-book/
4. Criterion.rs User Guide. https://bheisler.github.io/criterion.rs/book/
5. cargo-fuzz. https://github.com/rust-fuzz/cargo-fuzz
6. Klabnik, S., & Nichols, C. (2019). "The Rust Programming Language." No Starch Press. (Chapter 19: Unsafe Rust)
7. CUDA Runtime API Error Handling. https://docs.nvidia.com/cuda/cuda-runtime-api/
8. Anderson, C. (2020). "Effective Rust." Pragmatic Bookshelf.
9. Gjengset, J. (2021). "Rust for Rustaceans." No Starch Press. (Chapter 9: Unsafe Code)
10. Building Reliable and Scalable Systems in Rust. https://tokio.rs/blog/2021-05-14-inventing-the-service-trait
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬17ç« : åˆ†æ•£ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿å¯¾å¿œ](05-17-åˆ†æ•£ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿å¯¾å¿œ.md) | [â¡ï¸ ç¬¬19ç« : CNNãƒ»RNNãƒ»Transformerã‚’å®Ÿè£…ã™ã‚‹](../06_ç¬¬VIéƒ¨_ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã¨å®Ÿè·µ/06-19-CNNãƒ»RNNãƒ»Transformerã‚’å®Ÿè£…ã™ã‚‹.md)