# 第 12 章：データローディングとバッチ処理

本章では、機械学習の学習・推論パイプラインにおいて、データの読み込み、前処理、バッチ化、GPU への転送を効率的に行う方法を Rust で実装します。データローディングのボトルネックは、GPU の計算能力を十分に活用できない主要な原因の一つであり、適切な並列化と非同期処理が重要です。

Python（PyTorch/TensorFlow）との比較を通じて、Rust での高効率なデータパイプラインの構築手法を学びます。

---

## 12.1 データセットとデータローダーの設計

### 12.1.1 Dataset トレイトの定義

Dataset は、個々のサンプルにアクセスするためのインターフェースを提供します。

**Python（PyTorch）の Dataset**：

```python
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class CustomDataset(Dataset):
    def __init__(self, data, labels):
        self.data = data
        self.labels = labels
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# 使用例
data = np.random.randn(1000, 3, 32, 32).astype(np.float32)
labels = np.random.randint(0, 10, 1000)

dataset = CustomDataset(data, labels)
dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,
    pin_memory=True,
)

for batch_data, batch_labels in dataloader:
    # 学習処理
    pass
```

**Rust でのトレイト定義**：

```rust
use ndarray::{ArrayD, Array4, Array1};
use std::error::Error;

/// Dataset トレイト: 個々のサンプルへのアクセスを提供
pub trait Dataset {
    type Item;
    type Error: Error;

    /// データセットのサイズを返す
    fn len(&self) -> usize;

    /// データセットが空かどうか
    fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// インデックスでサンプルを取得
    fn get(&self, index: usize) -> Result<Self::Item, Self::Error>;
}

/// 画像分類用のデータセット例
pub struct ImageDataset {
    images: Vec<Array4<f32>>,  // (C, H, W)
    labels: Vec<usize>,
}

impl ImageDataset {
    pub fn new(images: Vec<Array4<f32>>, labels: Vec<usize>) -> Self {
        assert_eq!(images.len(), labels.len());
        Self { images, labels }
    }

    pub fn from_arrays(
        data: Array4<f32>,  // (N, C, H, W)
        labels: Array1<usize>,
    ) -> Self {
        let n = data.shape()[0];
        let mut images = Vec::with_capacity(n);
        
        for i in 0..n {
            let image = data.slice(s![i, .., .., ..]).to_owned();
            images.push(image);
        }
        
        let labels = labels.to_vec();
        Self { images, labels }
    }
}

#[derive(Debug)]
pub enum DatasetError {
    IndexOutOfBounds,
}

impl std::fmt::Display for DatasetError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            DatasetError::IndexOutOfBounds => write!(f, "Index out of bounds"),
        }
    }
}

impl Error for DatasetError {}

impl Dataset for ImageDataset {
    type Item = (Array4<f32>, usize);
    type Error = DatasetError;

    fn len(&self) -> usize {
        self.images.len()
    }

    fn get(&self, index: usize) -> Result<Self::Item, Self::Error> {
        if index >= self.len() {
            return Err(DatasetError::IndexOutOfBounds);
        }
        
        Ok((self.images[index].clone(), self.labels[index]))
    }
}
```

### 12.1.2 バッチサンプラーの実装

バッチサンプラーは、データセットからバッチ単位でインデックスを生成します。

**Python（PyTorch）のサンプラー**：

```python
from torch.utils.data import Sampler
import random

class RandomSampler(Sampler):
    def __init__(self, data_source, shuffle=True):
        self.data_source = data_source
        self.shuffle = shuffle
    
    def __iter__(self):
        indices = list(range(len(self.data_source)))
        if self.shuffle:
            random.shuffle(indices)
        return iter(indices)
    
    def __len__(self):
        return len(self.data_source)
```

**Rust 実装**：

```rust
use rand::seq::SliceRandom;
use rand::thread_rng;

pub trait Sampler {
    fn sample(&mut self, num_samples: usize) -> Vec<usize>;
    fn len(&self) -> usize;
}

pub struct RandomSampler {
    num_samples: usize,
    shuffle: bool,
}

impl RandomSampler {
    pub fn new(num_samples: usize, shuffle: bool) -> Self {
        Self { num_samples, shuffle }
    }
}

impl Sampler for RandomSampler {
    fn sample(&mut self, _num_samples: usize) -> Vec<usize> {
        let mut indices: Vec<usize> = (0..self.num_samples).collect();
        
        if self.shuffle {
            let mut rng = thread_rng();
            indices.shuffle(&mut rng);
        }
        
        indices
    }

    fn len(&self) -> usize {
        self.num_samples
    }
}

pub struct BatchSampler<S: Sampler> {
    sampler: S,
    batch_size: usize,
    drop_last: bool,
}

impl<S: Sampler> BatchSampler<S> {
    pub fn new(sampler: S, batch_size: usize, drop_last: bool) -> Self {
        Self {
            sampler,
            batch_size,
            drop_last,
        }
    }

    pub fn batches(&mut self) -> Vec<Vec<usize>> {
        let indices = self.sampler.sample(self.sampler.len());
        let mut batches = Vec::new();
        
        for chunk in indices.chunks(self.batch_size) {
            if chunk.len() == self.batch_size || !self.drop_last {
                batches.push(chunk.to_vec());
            }
        }
        
        batches
    }
}
```

### 12.1.3 DataLoader の実装

DataLoader は、データセットからバッチを生成し、並列処理を管理します。

**Rust での基本的な DataLoader**：

```rust
use std::sync::Arc;
use rayon::prelude::*;

pub struct DataLoader<D: Dataset> {
    dataset: Arc<D>,
    batch_size: usize,
    shuffle: bool,
    num_workers: usize,
    drop_last: bool,
}

impl<D: Dataset> DataLoader<D>
where
    D: Send + Sync + 'static,
    D::Item: Send,
{
    pub fn new(
        dataset: D,
        batch_size: usize,
        shuffle: bool,
        num_workers: usize,
        drop_last: bool,
    ) -> Self {
        Self {
            dataset: Arc::new(dataset),
            batch_size,
            shuffle,
            num_workers,
            drop_last,
        }
    }

    pub fn iter(&self) -> DataLoaderIterator<D> {
        let mut sampler = RandomSampler::new(self.dataset.len(), self.shuffle);
        let batch_sampler = BatchSampler::new(sampler, self.batch_size, self.drop_last);
        let batches = batch_sampler.batches();
        
        DataLoaderIterator {
            dataset: Arc::clone(&self.dataset),
            batches,
            current_batch: 0,
            num_workers: self.num_workers,
        }
    }
}

pub struct DataLoaderIterator<D: Dataset> {
    dataset: Arc<D>,
    batches: Vec<Vec<usize>>,
    current_batch: usize,
    num_workers: usize,
}

impl<D: Dataset> Iterator for DataLoaderIterator<D>
where
    D: Send + Sync + 'static,
    D::Item: Send,
{
    type Item = Vec<D::Item>;

    fn next(&mut self) -> Option<Self::Item> {
        if self.current_batch >= self.batches.len() {
            return None;
        }

        let indices = &self.batches[self.current_batch];
        self.current_batch += 1;

        // 並列にデータを読み込む
        let batch: Vec<_> = if self.num_workers > 1 {
            indices
                .par_iter()
                .filter_map(|&idx| self.dataset.get(idx).ok())
                .collect()
        } else {
            indices
                .iter()
                .filter_map(|&idx| self.dataset.get(idx).ok())
                .collect()
        };

        Some(batch)
    }
}
```

---

## 12.2 データの前処理とデータ拡張

### 12.2.1 変換（Transform）の設計

**Python（torchvision）の Transform**：

```python
import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                       std=[0.229, 0.224, 0.225]),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomCrop(32, padding=4),
])
```

**Rust での Transform トレイト**：

```rust
use ndarray::{Array3, Array4};
use rand::Rng;

pub trait Transform {
    fn apply(&self, image: Array3<f32>) -> Array3<f32>;
}

/// 正規化変換
pub struct Normalize {
    mean: [f32; 3],
    std: [f32; 3],
}

impl Normalize {
    pub fn new(mean: [f32; 3], std: [f32; 3]) -> Self {
        Self { mean, std }
    }
}

impl Transform for Normalize {
    fn apply(&self, image: Array3<f32>) -> Array3<f32> {
        let (c, h, w) = image.dim();
        let mut normalized = image.clone();
        
        for ch in 0..c {
            for y in 0..h {
                for x in 0..w {
                    normalized[[ch, y, x]] = 
                        (normalized[[ch, y, x]] - self.mean[ch]) / self.std[ch];
                }
            }
        }
        
        normalized
    }
}

/// ランダム水平反転
pub struct RandomHorizontalFlip {
    p: f32,
}

impl RandomHorizontalFlip {
    pub fn new(p: f32) -> Self {
        assert!(p >= 0.0 && p <= 1.0);
        Self { p }
    }
}

impl Transform for RandomHorizontalFlip {
    fn apply(&self, image: Array3<f32>) -> Array3<f32> {
        let mut rng = rand::thread_rng();
        
        if rng.gen::<f32>() < self.p {
            // 水平反転
            let (c, h, w) = image.dim();
            let mut flipped = Array3::zeros((c, h, w));
            
            for ch in 0..c {
                for y in 0..h {
                    for x in 0..w {
                        flipped[[ch, y, x]] = image[[ch, y, w - 1 - x]];
                    }
                }
            }
            
            flipped
        } else {
            image
        }
    }
}

/// ランダムクロップ
pub struct RandomCrop {
    size: usize,
    padding: usize,
}

impl RandomCrop {
    pub fn new(size: usize, padding: usize) -> Self {
        Self { size, padding }
    }
    
    fn pad_image(&self, image: &Array3<f32>) -> Array3<f32> {
        let (c, h, w) = image.dim();
        let new_h = h + 2 * self.padding;
        let new_w = w + 2 * self.padding;
        
        let mut padded = Array3::zeros((c, new_h, new_w));
        
        for ch in 0..c {
            for y in 0..h {
                for x in 0..w {
                    padded[[ch, y + self.padding, x + self.padding]] = image[[ch, y, x]];
                }
            }
        }
        
        padded
    }
}

impl Transform for RandomCrop {
    fn apply(&self, image: Array3<f32>) -> Array3<f32> {
        let padded = self.pad_image(&image);
        let (c, h, w) = padded.dim();
        
        let mut rng = rand::thread_rng();
        let y_start = rng.gen_range(0..=(h - self.size));
        let x_start = rng.gen_range(0..=(w - self.size));
        
        let mut cropped = Array3::zeros((c, self.size, self.size));
        
        for ch in 0..c {
            for y in 0..self.size {
                for x in 0..self.size {
                    cropped[[ch, y, x]] = padded[[ch, y_start + y, x_start + x]];
                }
            }
        }
        
        cropped
    }
}

/// 複数の変換を順番に適用
pub struct Compose {
    transforms: Vec<Box<dyn Transform + Send + Sync>>,
}

impl Compose {
    pub fn new(transforms: Vec<Box<dyn Transform + Send + Sync>>) -> Self {
        Self { transforms }
    }
}

impl Transform for Compose {
    fn apply(&self, mut image: Array3<f32>) -> Array3<f32> {
        for transform in &self.transforms {
            image = transform.apply(image);
        }
        image
    }
}
```

### 12.2.2 GPU でのデータ拡張

画像の前処理をCPUで行うと、GPUの計算を待たせてしまう可能性があります。簡単な変換はGPUカーネルで実装することで、効率を向上できます。

**CUDA カーネルでの正規化**：

```cuda
__global__ void normalize_kernel(
    const float* input,
    float* output,
    const float* mean,
    const float* std,
    int batch_size,
    int channels,
    int height,
    int width
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total = batch_size * channels * height * width;
    
    if (idx < total) {
        int w = idx % width;
        int h = (idx / width) % height;
        int c = (idx / (width * height)) % channels;
        int n = idx / (width * height * channels);
        
        output[idx] = (input[idx] - mean[c]) / std[c];
    }
}

__global__ void random_horizontal_flip_kernel(
    const float* input,
    float* output,
    const bool* flip_flags,
    int batch_size,
    int channels,
    int height,
    int width
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total = batch_size * channels * height * width;
    
    if (idx < total) {
        int w = idx % width;
        int h = (idx / width) % height;
        int c = (idx / (width * height)) % channels;
        int n = idx / (width * height * channels);
        
        if (flip_flags[n]) {
            int flipped_w = width - 1 - w;
            int src_idx = ((n * channels + c) * height + h) * width + flipped_w;
            output[idx] = input[src_idx];
        } else {
            output[idx] = input[idx];
        }
    }
}
```

---

## 12.3 効率的な GPU メモリ転送

### 12.3.1 ピン留めメモリ（Pinned Memory）

ピン留めメモリを使うと、CPU から GPU へのデータ転送が高速化されます。

**Python（PyTorch）での pin_memory**：

```python
import torch

# ピン留めメモリを有効にする
dataloader = DataLoader(
    dataset,
    batch_size=32,
    pin_memory=True,  # ← 重要
)

for data, labels in dataloader:
    # non_blocking=True で非同期転送
    data = data.cuda(non_blocking=True)
    labels = labels.cuda(non_blocking=True)
    
    # 計算処理
    output = model(data)
```

**CUDA でのピン留めメモリ確保**：

```c
// ホスト側でピン留めメモリを確保
float* h_data_pinned;
cudaMallocHost(&h_data_pinned, size * sizeof(float));

// 通常のメモリ転送より高速
cudaMemcpy(d_data, h_data_pinned, size * sizeof(float), cudaMemcpyHostToDevice);

// 解放
cudaFreeHost(h_data_pinned);
```

**Rust（cudarc）での実装**：

```rust
use cudarc::driver::*;
use std::sync::Arc;

pub struct PinnedMemoryAllocator {
    device: Arc<CudaDevice>,
}

impl PinnedMemoryAllocator {
    pub fn new(device: Arc<CudaDevice>) -> Self {
        Self { device }
    }

    pub fn alloc_pinned(&self, size: usize) -> Result<HostBuffer<f32>, CudaError> {
        // ピン留めメモリの確保
        self.device.alloc_host(size)
    }

    pub fn copy_to_device_async(
        &self,
        host_data: &HostBuffer<f32>,
        stream: &CudaStream,
    ) -> Result<CudaSlice<f32>, CudaError> {
        let device_buffer = self.device.alloc_zeros::<f32>(host_data.len())?;
        
        // 非同期でデバイスにコピー
        self.device.htod_copy_into_async(host_data, &device_buffer, stream)?;
        
        Ok(device_buffer)
    }
}
```

### 12.3.2 ストリームを使った並列転送と計算

CUDA ストリームを使うと、データ転送と計算を並列化できます。

**パイプライン処理のパターン**：

```
Batch 0: [Transfer] → [Compute] → [Transfer Result]
Batch 1:               [Transfer] → [Compute] → [Transfer Result]
Batch 2:                             [Transfer] → [Compute] → ...
```

**Python（PyTorch）での実装**：

```python
import torch

# 複数のストリームを作成
stream1 = torch.cuda.Stream()
stream2 = torch.cuda.Stream()

for i, (data, labels) in enumerate(dataloader):
    # ストリームを交互に使う
    stream = stream1 if i % 2 == 0 else stream2
    
    with torch.cuda.stream(stream):
        data = data.cuda(non_blocking=True)
        labels = labels.cuda(non_blocking=True)
        
        output = model(data)
        loss = criterion(output, labels)
        loss.backward()
```

**Rust（cudarc）での実装**：

```rust
use cudarc::driver::*;
use std::sync::Arc;

pub struct PipelinedDataLoader {
    device: Arc<CudaDevice>,
    streams: Vec<CudaStream>,
    num_streams: usize,
}

impl PipelinedDataLoader {
    pub fn new(device: Arc<CudaDevice>, num_streams: usize) -> Result<Self, CudaError> {
        let mut streams = Vec::new();
        for _ in 0..num_streams {
            streams.push(device.fork_default_stream()?);
        }
        
        Ok(Self {
            device,
            streams,
            num_streams,
        })
    }

    pub fn load_batch_async(
        &self,
        batch_idx: usize,
        host_data: &HostBuffer<f32>,
    ) -> Result<CudaSlice<f32>, CudaError> {
        let stream_idx = batch_idx % self.num_streams;
        let stream = &self.streams[stream_idx];
        
        // 非同期転送
        let device_buffer = self.device.alloc_zeros::<f32>(host_data.len())?;
        self.device.htod_copy_into_async(host_data, &device_buffer, stream)?;
        
        Ok(device_buffer)
    }

    pub fn synchronize(&self, batch_idx: usize) -> Result<(), CudaError> {
        let stream_idx = batch_idx % self.num_streams;
        self.streams[stream_idx].synchronize()
    }
}
```

---

## 12.4 メモリ効率的なバッチ処理

### 12.4.1 動的バッチサイズの調整

GPU メモリが限られている場合、バッチサイズを動的に調整することで、Out of Memory エラーを回避できます。

**Python 実装**：

```python
import torch

def find_max_batch_size(model, input_shape, device):
    """最大バッチサイズを二分探索で見つける"""
    low, high = 1, 1024
    max_batch_size = 1
    
    while low <= high:
        mid = (low + high) // 2
        try:
            # テスト用のダミーデータ
            dummy_input = torch.randn(mid, *input_shape).to(device)
            dummy_target = torch.randint(0, 10, (mid,)).to(device)
            
            # Forward pass
            output = model(dummy_input)
            loss = F.cross_entropy(output, dummy_target)
            
            # Backward pass
            loss.backward()
            
            # 成功したらバッチサイズを増やす
            max_batch_size = mid
            low = mid + 1
            
            # メモリをクリア
            del dummy_input, dummy_target, output, loss
            torch.cuda.empty_cache()
            
        except RuntimeError as e:
            if 'out of memory' in str(e):
                # OOM なのでバッチサイズを減らす
                high = mid - 1
                torch.cuda.empty_cache()
            else:
                raise e
    
    return max_batch_size

# 使用例
max_bs = find_max_batch_size(model, (3, 224, 224), 'cuda:0')
print(f"Max batch size: {max_bs}")
```

### 12.4.2 勾配累積（Gradient Accumulation）

メモリが足りない場合、小さなバッチで複数回 forward/backward を行い、勾配を累積してから optimizer を更新します。

**Python 実装**：

```python
accumulation_steps = 4  # 4 バッチ分の勾配を累積

optimizer.zero_grad()

for i, (data, labels) in enumerate(dataloader):
    data, labels = data.cuda(), labels.cuda()
    
    # Forward pass
    output = model(data)
    loss = criterion(output, labels)
    
    # 勾配を累積するため、損失を accumulation_steps で割る
    loss = loss / accumulation_steps
    
    # Backward pass
    loss.backward()
    
    # accumulation_steps ごとに optimizer を更新
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**Rust での概念的な実装**：

```rust
pub struct GradientAccumulator {
    accumulation_steps: usize,
    current_step: usize,
}

impl GradientAccumulator {
    pub fn new(accumulation_steps: usize) -> Self {
        Self {
            accumulation_steps,
            current_step: 0,
        }
    }

    pub fn should_update(&mut self) -> bool {
        self.current_step += 1;
        if self.current_step >= self.accumulation_steps {
            self.current_step = 0;
            true
        } else {
            false
        }
    }

    pub fn scale_loss(&self, loss: f32) -> f32 {
        loss / self.accumulation_steps as f32
    }
}

// 使用例（疑似コード）
let mut accumulator = GradientAccumulator::new(4);

for (data, labels) in dataloader.iter() {
    let output = model.forward(&data);
    let mut loss = criterion.compute(&output, &labels);
    
    // 勾配累積のためにスケール
    loss = accumulator.scale_loss(loss);
    
    model.backward(loss);
    
    if accumulator.should_update() {
        optimizer.step();
        optimizer.zero_grad();
    }
}
```

---

## 12.5 並列データローディングとプリフェッチ

### 12.5.1 マルチスレッドでのデータ読み込み

複数のワーカースレッドを使ってデータを並列に読み込みます。

**Rust での実装（rayon と crossbeam を使用）**：

```rust
use crossbeam::channel::{bounded, Sender, Receiver};
use std::thread;
use std::sync::Arc;

pub struct ParallelDataLoader<D: Dataset> {
    dataset: Arc<D>,
    batch_size: usize,
    num_workers: usize,
    prefetch_factor: usize,
}

impl<D: Dataset> ParallelDataLoader<D>
where
    D: Send + Sync + 'static,
    D::Item: Send + 'static,
{
    pub fn new(
        dataset: D,
        batch_size: usize,
        num_workers: usize,
        prefetch_factor: usize,
    ) -> Self {
        Self {
            dataset: Arc::new(dataset),
            batch_size,
            num_workers,
            prefetch_factor,
        }
    }

    pub fn iter(&self) -> ParallelDataLoaderIterator<D> {
        let (sender, receiver) = bounded(self.prefetch_factor);
        
        let dataset = Arc::clone(&self.dataset);
        let batch_size = self.batch_size;
        let num_workers = self.num_workers;
        let num_batches = (dataset.len() + batch_size - 1) / batch_size;
        
        // ワーカースレッドを起動
        thread::spawn(move || {
            for batch_idx in 0..num_batches {
                let start_idx = batch_idx * batch_size;
                let end_idx = (start_idx + batch_size).min(dataset.len());
                let indices: Vec<usize> = (start_idx..end_idx).collect();
                
                // 並列にバッチを読み込む
                let batch: Vec<_> = indices
                    .into_par_iter()
                    .filter_map(|idx| dataset.get(idx).ok())
                    .collect();
                
                if sender.send(batch).is_err() {
                    break;
                }
            }
        });
        
        ParallelDataLoaderIterator { receiver }
    }
}

pub struct ParallelDataLoaderIterator<D: Dataset> {
    receiver: Receiver<Vec<D::Item>>,
}

impl<D: Dataset> Iterator for ParallelDataLoaderIterator<D> {
    type Item = Vec<D::Item>;

    fn next(&mut self) -> Option<Self::Item> {
        self.receiver.recv().ok()
    }
}
```

### 12.5.2 プリフェッチパターン

次のバッチを事前に GPU に転送しておくことで、計算と転送のオーバーラップを最大化します。

**ダブルバッファリングパターン**：

```rust
use std::collections::VecDeque;

pub struct PrefetchBuffer<T> {
    buffer: VecDeque<T>,
    capacity: usize,
}

impl<T> PrefetchBuffer<T> {
    pub fn new(capacity: usize) -> Self {
        Self {
            buffer: VecDeque::with_capacity(capacity),
            capacity,
        }
    }

    pub fn push(&mut self, item: T) -> bool {
        if self.buffer.len() < self.capacity {
            self.buffer.push_back(item);
            true
        } else {
            false
        }
    }

    pub fn pop(&mut self) -> Option<T> {
        self.buffer.pop_front()
    }

    pub fn is_full(&self) -> bool {
        self.buffer.len() >= self.capacity
    }

    pub fn len(&self) -> usize {
        self.buffer.len()
    }
}

// 使用例
pub struct PrefetchingDataLoader<D: Dataset> {
    dataloader: ParallelDataLoader<D>,
    prefetch_buffer: PrefetchBuffer<Vec<D::Item>>,
}

impl<D: Dataset> PrefetchingDataLoader<D>
where
    D: Send + Sync + 'static,
    D::Item: Send + 'static,
{
    pub fn new(dataloader: ParallelDataLoader<D>, prefetch_size: usize) -> Self {
        Self {
            dataloader,
            prefetch_buffer: PrefetchBuffer::new(prefetch_size),
        }
    }

    pub fn next_batch(&mut self) -> Option<Vec<D::Item>> {
        // バッファから取り出す
        let batch = self.prefetch_buffer.pop();
        
        // バッファを補充
        for batch in self.dataloader.iter() {
            if !self.prefetch_buffer.push(batch) {
                break;
            }
        }
        
        batch
    }
}
```

---

## 12.6 まとめ

本章では、効率的なデータローディングとバッチ処理パイプラインを Rust で実装しました。

**主要なポイント**：

1. **Dataset と DataLoader**: トレイトを使った抽象化と並列データ読み込み
2. **データ拡張**: CPU/GPU での画像変換の実装
3. **メモリ転送最適化**: ピン留めメモリ、ストリーム、非同期転送
4. **メモリ効率化**: 勾配累積、動的バッチサイズ調整
5. **並列処理**: マルチスレッドローディングとプリフェッチ

**パフォーマンスのベストプラクティス**：

- `num_workers` を適切に設定（通常 4-8）
- `prefetch_factor` でバッファサイズを調整（通常 2-4）
- ピン留めメモリで転送を高速化
- ストリームで転送と計算をオーバーラップ

**次章への接続**：

次の第 13 章（旧第 10 章）では、学習ループと最適化手法の実装について詳しく解説し、本章で構築したデータパイプラインを使った実際の学習プロセスを学びます。

---

## 参考文献

- PyTorch Data Loading Tutorial: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html
- CUDA Best Practices Guide - Memory Optimization: https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/
- NVIDIA DALI (Data Loading Library): https://github.com/NVIDIA/DALI

