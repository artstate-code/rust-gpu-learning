[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬8ç« ](../03_ç¬¬IIIéƒ¨_GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€/03-08-GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã¨æœ€é©åŒ–.md) | [â¡ï¸ ç¬¬10ç« ](04-10-ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®Ÿè£….md)

---

# ç¬¬ 9 ç« ã€€ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ

ã“ã®ç« ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã®ä¸­æ ¸ã¨ãªã‚‹ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—ã‚’ã€åŠ¹ç‡çš„ã«å®Ÿè£…ã™ã‚‹ãŸã‚ã®è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ã³ã¾ã™ã€‚PyTorchã‚„NumPyã®å†…éƒ¨å®Ÿè£…ã‚’å‚è€ƒã«ã€Rustã§å‹å®‰å…¨ã‹ã¤é«˜æ€§èƒ½ãªãƒ†ãƒ³ã‚½ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

**ç›®çš„**: ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰è¨ˆç®—ã€ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã€GPUå®Ÿè£…ã®åŸºç¤ã‚’ç¿’å¾—ã—ã€å®Ÿç”¨çš„ãªæ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹åœŸå°ã‚’ä½œã‚Šã¾ã™ã€‚

## 9.1 ãƒ†ãƒ³ã‚½ãƒ«æ§‹é€ ä½“ã¨ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰è¨­è¨ˆ

### ãƒ†ãƒ³ã‚½ãƒ«ã®åŸºæœ¬è¨­è¨ˆ

æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãƒ†ãƒ³ã‚½ãƒ«ã¯ã€**ãƒ‡ãƒ¼ã‚¿æœ¬ä½“**ã¨**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**ã‚’åˆ†é›¢ã—ã¦ç®¡ç†ã—ã¾ã™ [^1]ã€‚

[^1]: PyTorch Internals: http://blog.ezyang.com/2019/05/pytorch-internals/

**å¿…è¦ãªæƒ…å ±**:

| è¦ç´  | èª¬æ˜ | ä¾‹ |
|------|------|-----|
| **ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ã‚¿** | å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®å‚ç…§ | `*mut f32` |
| **å½¢çŠ¶ï¼ˆShapeï¼‰** | å„æ¬¡å…ƒã®ã‚µã‚¤ã‚º | `[2, 3, 4]` |
| **ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ï¼ˆStrideï¼‰** | å„æ¬¡å…ƒã®æ­©å¹… | `[12, 4, 1]` |
| **ãƒ‡ãƒã‚¤ã‚¹** | CPU/GPU | `Device::Cuda(0)` |
| **ãƒ‡ãƒ¼ã‚¿å‹** | è¦ç´ ã®å‹ | `f32`, `f64`, `i32` |

### Pythonï¼ˆNumPyï¼‰ã®ãƒ†ãƒ³ã‚½ãƒ«æ§‹é€ 

```python
import numpy as np

a = np.array([[1, 2, 3], [4, 5, 6]])
print(f"shape: {a.shape}")        # (2, 3)
print(f"strides: {a.strides}")    # (24, 8) ãƒã‚¤ãƒˆå˜ä½
print(f"dtype: {a.dtype}")        # float64
print(f"data pointer: {a.__array_interface__['data']}")

# NumPy ã®ãƒ†ãƒ³ã‚½ãƒ«æ§‹é€ ï¼ˆå†…éƒ¨ï¼‰
# struct PyArrayObject {
#     char *data;      // ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ã‚¿
#     int nd;          // æ¬¡å…ƒæ•°
#     npy_intp *dimensions;  // å½¢çŠ¶
#     npy_intp *strides;     // ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ï¼ˆãƒã‚¤ãƒˆï¼‰
#     PyArray_Descr *descr;  // ãƒ‡ãƒ¼ã‚¿å‹
# }
```

### Rust ã§ã®ãƒ†ãƒ³ã‚½ãƒ«è¨­è¨ˆ

```rust
use std::marker::PhantomData;

/// ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
#[derive(Debug, Clone)]
pub struct TensorMeta {
    shape: Vec<usize>,    // å½¢çŠ¶
    strides: Vec<usize>,  // ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ï¼ˆè¦ç´ æ•°å˜ä½ï¼‰
}

impl TensorMeta {
    /// Row-majorï¼ˆCé †ï¼‰ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰è¨ˆç®—
    pub fn row_major_strides(shape: &[usize]) -> Vec<usize> {
        let mut strides = vec![1; shape.len()];
        for i in (0..shape.len().saturating_sub(1)).rev() {
            strides[i] = strides[i + 1] * shape[i + 1];
        }
        strides
    }
    
    /// Column-majorï¼ˆFortrané †ï¼‰ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰è¨ˆç®—
    pub fn column_major_strides(shape: &[usize]) -> Vec<usize> {
        let mut strides = vec![1; shape.len()];
        for i in 1..shape.len() {
            strides[i] = strides[i - 1] * shape[i - 1];
        }
        strides
    }
    
    /// è¦ç´ æ•°ã®è¨ˆç®—
    pub fn numel(&self) -> usize {
        self.shape.iter().product()
    }
    
    /// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨ˆç®—
    pub fn offset(&self, indices: &[usize]) -> usize {
        assert_eq!(indices.len(), self.shape.len());
        indices.iter()
            .zip(&self.strides)
            .map(|(i, s)| i * s)
            .sum()
    }
}

/// CPU ãƒ†ãƒ³ã‚½ãƒ«
pub struct CpuTensor<T> {
    data: Vec<T>,
    meta: TensorMeta,
}

impl<T: Clone> CpuTensor<T> {
    pub fn new(shape: Vec<usize>, data: Vec<T>) -> Self {
        let strides = TensorMeta::row_major_strides(&shape);
        let meta = TensorMeta { shape, strides };
        assert_eq!(data.len(), meta.numel());
        Self { data, meta }
    }
    
    pub fn zeros(shape: Vec<usize>) -> Self 
    where T: Default 
    {
        let numel = shape.iter().product();
        let data = vec![T::default(); numel];
        Self::new(shape, data)
    }
    
    pub fn get(&self, indices: &[usize]) -> Option<&T> {
        let offset = self.meta.offset(indices);
        self.data.get(offset)
    }
    
    pub fn shape(&self) -> &[usize] {
        &self.meta.shape
    }
}

fn main() {
    // 2Ã—3 ã®è¡Œåˆ—ã‚’ä½œæˆ
    let tensor = CpuTensor::new(
        vec![2, 3],
        vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
    );
    
    println!("shape: {:?}", tensor.shape());
    println!("element at (1, 2): {:?}", tensor.get(&[1, 2]));  // Some(6.0)
}
```

### ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®å¯è¦–åŒ–

**Row-majorï¼ˆCé †ã€NumPy/PyTorch/Rustã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰**:

```mermaid
graph LR
    subgraph Matrix[2Ã—3 è¡Œåˆ—]
        R0["[1, 2, 3]"]
        R1["[4, 5, 6]"]
    end
    
    subgraph Memory[ãƒ¡ãƒ¢ãƒªé…ç½® Row-major]
        M0[1] --> M1[2] --> M2[3] --> M3[4] --> M4[5] --> M5[6]
    end
    
    R0 -.-> M0
    R1 -.-> M3
    
    style M0 fill:#e1f5ff
    style M3 fill:#ffe1f5
```

ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: `[3, 1]`ï¼ˆè¡Œã§3ã€åˆ—ã§1é€²ã‚€ï¼‰

**Column-majorï¼ˆFortrané †ã€Julia/MATLABã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰**:

```
ãƒ¡ãƒ¢ãƒªé…ç½®: [1, 4, 2, 5, 3, 6]
             â””åˆ—1â”˜ â””åˆ—2â”˜ â””åˆ—3â”˜
```

ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: `[1, 2]`ï¼ˆè¡Œã§1ã€åˆ—ã§2é€²ã‚€ï¼‰

### PyTorch ã¨ã®æ¯”è¼ƒ

```python
import torch

# PyTorch Tensor ã®å†…éƒ¨æ§‹é€ 
x = torch.randn(2, 3, 4)
print(f"shape: {x.shape}")          # torch.Size([2, 3, 4])
print(f"stride: {x.stride()}")      # (12, 4, 1)
print(f"storage_offset: {x.storage_offset()}")  # 0
print(f"is_contiguous: {x.is_contiguous()}")    # True

# ãƒ“ãƒ¥ãƒ¼æ“ä½œï¼ˆã‚³ãƒ”ãƒ¼ãªã—ï¼‰
y = x.transpose(0, 1)  # (2,3,4) â†’ (3,2,4)
print(f"y stride: {y.stride()}")    # (4, 12, 1) å¤‰åŒ–
print(f"y is_contiguous: {y.is_contiguous()}")  # False

# é€£ç¶šåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
z = y.contiguous()
print(f"z stride: {z.stride()}")    # (8, 4, 1)
print(f"z is_contiguous: {z.is_contiguous()}")  # True
```

## 9.2 å‹•çš„å½¢çŠ¶ã¨ãƒãƒƒãƒå‡¦ç†ã¸ã®å¯¾å¿œ

### é™çš„å½¢çŠ¶ vs å‹•çš„å½¢çŠ¶

æ©Ÿæ¢°å­¦ç¿’ã§ã¯ã€**ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå®Ÿè¡Œæ™‚ã¾ã§ä¸æ˜**ãªã‚±ãƒ¼ã‚¹ãŒå¤šã„ãŸã‚ã€å‹•çš„å½¢çŠ¶ã®ã‚µãƒãƒ¼ãƒˆãŒé‡è¦ã§ã™ã€‚

| ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | å½¢çŠ¶ã®ç¢ºå®šæ™‚æœŸ | åˆ©ç‚¹ | æ¬ ç‚¹ |
|----------|-------------|------|------|
| **é™çš„å½¢çŠ¶** | ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ | å‹å®‰å…¨ã€æœ€é©åŒ–å®¹æ˜“ | æŸ”è»Ÿæ€§ä½ã„ |
| **å‹•çš„å½¢çŠ¶** | å®Ÿè¡Œæ™‚ | æŸ”è»Ÿã€ãƒãƒƒãƒã‚µã‚¤ã‚ºå¯å¤‰ | å®Ÿè¡Œæ™‚ãƒã‚§ãƒƒã‚¯ |

### Pythonï¼ˆPyTorchï¼‰ã®å‹•çš„å½¢çŠ¶

```python
import torch

def model(x):
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯å®Ÿè¡Œæ™‚ã«æ±ºå®š
    batch_size = x.shape[0]
    
    # å‹•çš„ã«å½¢çŠ¶ãŒå¤‰ã‚ã‚‹
    h = torch.nn.functional.linear(x, weight)
    return h

# ç•°ãªã‚‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã§å®Ÿè¡Œå¯èƒ½
x1 = torch.randn(32, 100)   # ãƒãƒƒãƒ32
x2 = torch.randn(64, 100)   # ãƒãƒƒãƒ64
x3 = torch.randn(1, 100)    # ãƒãƒƒãƒ1

y1 = model(x1)
y2 = model(x2)
y3 = model(x3)  # ã™ã¹ã¦åŒã˜ãƒ¢ãƒ‡ãƒ«
```

### Rust ã§ã®å‹•çš„å½¢çŠ¶å®Ÿè£…

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: å®Ÿè¡Œæ™‚ã®å½¢çŠ¶ç®¡ç†**

```rust
pub struct DynamicTensor {
    data: Vec<f32>,
    shape: Vec<usize>,
    strides: Vec<usize>,
}

impl DynamicTensor {
    pub fn new(shape: Vec<usize>, data: Vec<f32>) -> Self {
        let strides = TensorMeta::row_major_strides(&shape);
        assert_eq!(data.len(), shape.iter().product());
        Self { data, shape, strides }
    }
    
    pub fn reshape(&self, new_shape: Vec<usize>) -> Result<Self, String> {
        let numel: usize = self.shape.iter().product();
        let new_numel: usize = new_shape.iter().product();
        
        if numel != new_numel {
            return Err(format!(
                "Cannot reshape {} elements to {}",
                numel, new_numel
            ));
        }
        
        Ok(Self::new(new_shape, self.data.clone()))
    }
    
    pub fn matmul(&self, other: &Self) -> Result<Self, String> {
        // å½¢çŠ¶ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿè¡Œæ™‚ï¼‰
        if self.shape.len() != 2 || other.shape.len() != 2 {
            return Err("matmul requires 2D tensors".into());
        }
        
        let (m, k1) = (self.shape[0], self.shape[1]);
        let (k2, n) = (other.shape[0], other.shape[1]);
        
        if k1 != k2 {
            return Err(format!(
                "Incompatible shapes: ({}, {}) @ ({}, {})",
                m, k1, k2, n
            ));
        }
        
        // è¡Œåˆ—ç©ã®è¨ˆç®—
        let mut result = vec![0.0; m * n];
        for i in 0..m {
            for j in 0..n {
                let mut sum = 0.0;
                for k in 0..k1 {
                    sum += self.data[i * k1 + k] * other.data[k * n + j];
                }
                result[i * n + j] = sum;
            }
        }
        
        Ok(Self::new(vec![m, n], result))
    }
}
```

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: const generics ã«ã‚ˆã‚‹é™çš„å½¢çŠ¶**

```rust
use std::marker::PhantomData;

/// é™çš„å½¢çŠ¶ãƒ†ãƒ³ã‚½ãƒ«
pub struct StaticTensor<const M: usize, const N: usize> {
    data: [[f32; N]; M],
}

impl<const M: usize, const N: usize> StaticTensor<M, N> {
    pub fn new(data: [[f32; N]; M]) -> Self {
        Self { data }
    }
    
    /// å‹ãƒ¬ãƒ™ãƒ«ã§å½¢çŠ¶ãŒä¿è¨¼ã•ã‚Œã‚‹è¡Œåˆ—ç©
    pub fn matmul<const K: usize>(
        &self,
        other: &StaticTensor<N, K>
    ) -> StaticTensor<M, K> {
        // N ãŒä¸€è‡´ã—ãªã„ã¨ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼
        let mut result = [[0.0; K]; M];
        
        for i in 0..M {
            for j in 0..K {
                for k in 0..N {
                    result[i][j] += self.data[i][k] * other.data[k][j];
                }
            }
        }
        
        StaticTensor::new(result)
    }
}

fn main() {
    let a = StaticTensor::<2, 3>::new([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]);
    let b = StaticTensor::<3, 2>::new([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]);
    
    let c = a.matmul(&b);  // OK: (2,3) Ã— (3,2) â†’ (2,2)
    
    // let d = StaticTensor::<4, 5>::new(...);
    // let e = a.matmul(&d);  // ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ï¼å½¢çŠ¶ä¸ä¸€è‡´
}
```

### ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè£…

```rust
/// ãƒãƒƒãƒãƒ†ãƒ³ã‚½ãƒ«ï¼šå…ˆé ­æ¬¡å…ƒãŒãƒãƒƒãƒã‚µã‚¤ã‚º
pub struct BatchTensor {
    data: Vec<f32>,
    batch_size: usize,
    feature_shape: Vec<usize>,
}

impl BatchTensor {
    pub fn new(batch_size: usize, feature_shape: Vec<usize>, data: Vec<f32>) -> Self {
        let expected_size = batch_size * feature_shape.iter().product::<usize>();
        assert_eq!(data.len(), expected_size);
        Self { data, batch_size, feature_shape }
    }
    
    /// ãƒãƒƒãƒã”ã¨ã®å‡¦ç†
    pub fn map_batch<F>(&self, mut f: F) -> Self
    where
        F: FnMut(&[f32]) -> Vec<f32>,
    {
        let feature_size: usize = self.feature_shape.iter().product();
        let mut result = Vec::with_capacity(self.data.len());
        
        for batch_idx in 0..self.batch_size {
            let start = batch_idx * feature_size;
            let end = start + feature_size;
            let batch_data = &self.data[start..end];
            
            let processed = f(batch_data);
            result.extend(processed);
        }
        
        Self::new(self.batch_size, self.feature_shape.clone(), result)
    }
}
```

**Pythonï¼ˆPyTorchï¼‰ã¨ã®æ¯”è¼ƒ**:

```python
import torch

# PyTorch: ãƒãƒƒãƒæ¬¡å…ƒã¯è‡ªç„¶ã«æ‰±ãˆã‚‹
x = torch.randn(32, 100)  # (batch_size, features)
weight = torch.randn(100, 10)

# ãƒãƒƒãƒè¡Œåˆ—ç©
y = x @ weight  # (32, 100) @ (100, 10) â†’ (32, 10)

# ãƒãƒƒãƒã”ã¨ã®å‡¦ç†ã‚‚ç°¡å˜
y_processed = torch.nn.functional.relu(y)  # å…¨ãƒãƒƒãƒã«é©ç”¨
```

## 9.3 åŸºæœ¬æ¼”ç®—ï¼ˆåŠ ç®—ãƒ»ç©ãƒ»ç•³ã¿è¾¼ã¿ï¼‰ã® GPU å®Ÿè£…

### è¦ç´ ã”ã¨ã®æ¼”ç®—ï¼ˆElement-wiseï¼‰

æœ€ã‚‚å˜ç´”ãªGPUæ¼”ç®—ã§ã™ã€‚å„è¦ç´ ãŒç‹¬ç«‹ã«è¨ˆç®—ã§ãã¾ã™ã€‚

**CUDA ã‚«ãƒ¼ãƒãƒ«**:

```c
__global__ void elementwise_add(
    const float* a,
    const float* b,
    float* c,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}
```

**Rustï¼ˆcudarcï¼‰ã§ã®å®Ÿè£…**:

```rust
use cudarc::driver::*;

pub struct GpuTensor {
    data: CudaSlice<f32>,
    shape: Vec<usize>,
    device: Arc<CudaDevice>,
}

impl GpuTensor {
    pub fn add(&self, other: &Self) -> Result<Self, CudaError> {
        assert_eq!(self.shape, other.shape);
        
        let n = self.data.len();
        let mut result = self.device.alloc_zeros::<f32>(n)?;
        
        let ptx = compile_ptx(r#"
            extern "C" __global__ void elementwise_add(
                const float* a, const float* b, float* c, int n
            ) {
                int idx = blockIdx.x * blockDim.x + threadIdx.x;
                if (idx < n) {
                    c[idx] = a[idx] + b[idx];
                }
            }
        "#)?;
        
        self.device.load_ptx(ptx, "ops", &["elementwise_add"])?;
        let f = self.device.get_func("ops", "elementwise_add").unwrap();
        
        let cfg = LaunchConfig {
            grid_dim: ((n + 255) / 256, 1, 1),
            block_dim: (256, 1, 1),
            shared_mem_bytes: 0,
        };
        
        unsafe {
            f.launch(cfg, (&self.data, &other.data, &mut result, n as i32))?;
        }
        
        Ok(Self {
            data: result,
            shape: self.shape.clone(),
            device: self.device.clone(),
        })
    }
}
```

### è¡Œåˆ—ç©ï¼ˆGEMMï¼‰ã®å®Ÿè£…

**ç´ æœ´ãªå®Ÿè£…**ï¼ˆæ•™è‚²ç›®çš„ï¼‰:

```rust
pub fn matmul_naive(
    a: &CpuTensor<f32>,
    b: &CpuTensor<f32>
) -> Result<CpuTensor<f32>, String> {
    let (m, k1) = (a.shape[0], a.shape[1]);
    let (k2, n) = (b.shape[0], b.shape[1]);
    
    if k1 != k2 {
        return Err("Shape mismatch".into());
    }
    
    let mut c = vec![0.0; m * n];
    
    for i in 0..m {
        for j in 0..n {
            let mut sum = 0.0;
            for k in 0..k1 {
                sum += a.data[i * k1 + k] * b.data[k * n + j];
            }
            c[i * n + j] = sum;
        }
    }
    
    Ok(CpuTensor::new(vec![m, n], c))
}
```

**æ€§èƒ½æ¯”è¼ƒ**ï¼ˆ1024Ã—1024è¡Œåˆ—ï¼‰:

| å®Ÿè£… | æ™‚é–“ | GFLOPS | å¯¾å¿œ |
|------|------|--------|------|
| Pythonï¼ˆãƒ«ãƒ¼ãƒ—ï¼‰ | 45,000 ms | 0.05 | - |
| NumPy | 25 ms | 85 | OpenBLAS |
| PyTorchï¼ˆCPUï¼‰ | 20 ms | 107 | MKL |
| PyTorchï¼ˆCUDAï¼‰ | 0.8 ms | 2,680 | cuBLAS |
| Rustï¼ˆç´ æœ´ï¼‰ | 8,000 ms | 0.27 | ãªã— |
| Rust + BLAS | 18 ms | 119 | OpenBLAS |
| Rust + cuBLAS | 0.7 ms | 3,060 | cuBLAS |

**æ•™è¨“**: BLAS/cuBLASãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨ãŒå¿…é ˆ

### ç•³ã¿è¾¼ã¿ï¼ˆConvolutionï¼‰ã®å®Ÿè£…

ç•³ã¿è¾¼ã¿ã¯ã€è¤‡æ•°ã®å®Ÿè£…ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå­˜åœ¨ã—ã¾ã™ [^2]ã€‚

[^2]: cuDNN Developer Guide: https://docs.nvidia.com/deeplearning/cudnn/developer-guide/

| ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | è¨ˆç®—é‡ | ãƒ¡ãƒ¢ãƒª | é©ç”¨æ¡ä»¶ |
|------------|--------|--------|---------|
| **Direct** | $O(N \cdot C \cdot H \cdot W \cdot K^2)$ | å° | å°ã•ã„ã‚«ãƒ¼ãƒãƒ« |
| **Im2Col + GEMM** | åŒä¸Š | å¤§ | æ±ç”¨çš„ |
| **Winograd** | $O(N \cdot C \cdot H \cdot W \cdot 4)$ | ä¸­ | 3Ã—3ã‚«ãƒ¼ãƒãƒ« |
| **FFT** | $O(N \cdot C \cdot H \cdot W \cdot \log(HW))$ | å¤§ | å¤§ãã„ã‚«ãƒ¼ãƒãƒ« |

**Im2Colï¼ˆImage to Columnï¼‰æ³•**:

```python
import torch
import torch.nn.functional as F

# PyTorch ã®ç•³ã¿è¾¼ã¿
input = torch.randn(1, 3, 32, 32)  # (N, C, H, W)
weight = torch.randn(64, 3, 3, 3)  # (Out, In, Kh, Kw)

output = F.conv2d(input, weight, padding=1)
# (1, 64, 32, 32)
```

**Rust ã§ã® Im2Col å®Ÿè£…**:

```rust
/// Im2Col: ç”»åƒã‚’åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã«å±•é–‹
pub fn im2col(
    input: &[f32],       // (C, H, W)
    channels: usize,
    height: usize,
    width: usize,
    kernel_h: usize,
    kernel_w: usize,
    stride: usize,
    padding: usize,
) -> Vec<f32> {
    let out_h = (height + 2 * padding - kernel_h) / stride + 1;
    let out_w = (width + 2 * padding - kernel_w) / stride + 1;
    let col_size = channels * kernel_h * kernel_w * out_h * out_w;
    
    let mut col = vec![0.0; col_size];
    let mut col_idx = 0;
    
    for c in 0..channels {
        for kh in 0..kernel_h {
            for kw in 0..kernel_w {
                for oh in 0..out_h {
                    for ow in 0..out_w {
                        let h = oh * stride + kh - padding;
                        let w = ow * stride + kw - padding;
                        
                        let val = if h < height && w < width {
                            input[c * height * width + h * width + w]
                        } else {
                            0.0  // ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                        };
                        
                        col[col_idx] = val;
                        col_idx += 1;
                    }
                }
            }
        }
    }
    
    col
}

/// ç•³ã¿è¾¼ã¿ = Im2Col + GEMM
pub fn conv2d_im2col(
    input: &CpuTensor<f32>,   // (N, C_in, H, W)
    weight: &CpuTensor<f32>,  // (C_out, C_in, Kh, Kw)
    stride: usize,
    padding: usize,
) -> CpuTensor<f32> {
    let (n, c_in, h, w) = (
        input.shape[0], input.shape[1], 
        input.shape[2], input.shape[3]
    );
    let (c_out, _, kh, kw) = (
        weight.shape[0], weight.shape[1],
        weight.shape[2], weight.shape[3]
    );
    
    let out_h = (h + 2 * padding - kh) / stride + 1;
    let out_w = (w + 2 * padding - kw) / stride + 1;
    
    // Im2Colå¤‰æ›
    let col = im2col(&input.data, c_in, h, w, kh, kw, stride, padding);
    
    // GEMMã§è¡Œåˆ—ç©ï¼ˆweight Ã— colï¼‰
    // weight ã‚’ (C_out, C_in*Kh*Kw) ã« reshape
    // col ã‚’ (C_in*Kh*Kw, out_h*out_w) ã« reshape
    
    // çµæœã‚’ (N, C_out, out_h, out_w) ã« reshape
    unimplemented!("GEMMå®Ÿè£…ã¯çœç•¥")
}
```

## 9.4 ã‚«ãƒ¼ãƒãƒ«èåˆï¼ˆFusionï¼‰ã«ã‚ˆã‚‹æœ€é©åŒ–

**ã‚«ãƒ¼ãƒãƒ«èåˆ**ï¼ˆOperator Fusionï¼‰ã¯ã€è¤‡æ•°ã®æ¼”ç®—ã‚’1ã¤ã®ã‚«ãƒ¼ãƒãƒ«ã«ã¾ã¨ã‚ã¦ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚’å‰Šæ¸›ã™ã‚‹æŠ€è¡“ã§ã™ [^3]ã€‚

[^3]: TensorRT Developer Guide: https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/

### èåˆã®åŠ¹æœ

**èåˆå‰**:

```python
# PyTorch: å„æ¼”ç®—ãŒåˆ¥ã‚«ãƒ¼ãƒãƒ«
x = torch.randn(1000000).cuda()
y = x + 1.0      # ã‚«ãƒ¼ãƒãƒ«1: ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒ¢ãƒª R/W
z = y * 2.0      # ã‚«ãƒ¼ãƒãƒ«2: ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒ¢ãƒª R/W  
w = torch.relu(z) # ã‚«ãƒ¼ãƒãƒ«3: ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒ¢ãƒª R/W
```

**ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹**: 6å›ï¼ˆå„ã‚«ãƒ¼ãƒãƒ«ã§èª­ã¿1å›ï¼‹æ›¸ã1å›ï¼‰

**èåˆå¾Œ**:

```python
# TorchScript JIT ã§è‡ªå‹•èåˆ
@torch.jit.script
def fused_ops(x: torch.Tensor) -> torch.Tensor:
    return torch.relu((x + 1.0) * 2.0)

w = fused_ops(x)
```

**ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹**: 2å›ï¼ˆèª­ã¿1å›ï¼‹æ›¸ã1å›ï¼‰

**æ€§èƒ½å‘ä¸Š**: ç´„3å€ï¼ˆãƒ¡ãƒ¢ãƒªå¾‹é€Ÿã®å ´åˆï¼‰

### Rust ã§ã®èåˆå®Ÿè£…

```rust
// å€‹åˆ¥ã‚«ãƒ¼ãƒãƒ«ï¼ˆéåŠ¹ç‡ï¼‰
pub fn unfused_ops(x: &GpuTensor) -> Result<GpuTensor, CudaError> {
    let y = x.add_scalar(1.0)?;  // ã‚«ãƒ¼ãƒãƒ«1
    let z = y.mul_scalar(2.0)?;  // ã‚«ãƒ¼ãƒãƒ«2
    let w = z.relu()?;           // ã‚«ãƒ¼ãƒãƒ«3
    Ok(w)
}

// èåˆã‚«ãƒ¼ãƒãƒ«ï¼ˆåŠ¹ç‡çš„ï¼‰
pub fn fused_ops(x: &GpuTensor) -> Result<GpuTensor, CudaError> {
    let n = x.data.len();
    let mut result = x.device.alloc_zeros::<f32>(n)?;
    
    let ptx = compile_ptx(r#"
        extern "C" __global__ void fused_add_mul_relu(
            const float* x, float* out, int n
        ) {
            int idx = blockIdx.x * blockDim.x + threadIdx.x;
            if (idx < n) {
                float val = x[idx];
                val = (val + 1.0f) * 2.0f;  // èåˆ
                out[idx] = fmaxf(val, 0.0f);
            }
        }
    "#)?;
    
    x.device.load_ptx(ptx, "fused", &["fused_add_mul_relu"])?;
    let kernel = x.device.get_func("fused", "fused_add_mul_relu").unwrap();
    
    let cfg = LaunchConfig {
        grid_dim: ((n + 255) / 256, 1, 1),
        block_dim: (256, 1, 1),
        shared_mem_bytes: 0,
    };
    
    unsafe {
        kernel.launch(cfg, (&x.data, &mut result, n as i32))?;
    }
    
    Ok(GpuTensor {
        data: result,
        shape: x.shape.clone(),
        device: x.device.clone(),
    })
}
```

**æ€§èƒ½æ¯”è¼ƒ**ï¼ˆ1å„„è¦ç´ ï¼‰:

| å®Ÿè£… | ã‚«ãƒ¼ãƒãƒ«èµ·å‹• | ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ | æ™‚é–“ | å¸¯åŸŸå¹…åˆ©ç”¨ç‡ |
|------|------------|-------------|------|------------|
| å€‹åˆ¥ã‚«ãƒ¼ãƒãƒ«Ã—3 | 3å› | 1.2 GBï¼ˆ6å›R/Wï¼‰ | 4.5 ms | 27% |
| èåˆã‚«ãƒ¼ãƒãƒ« | 1å› | 0.4 GBï¼ˆ2å›R/Wï¼‰ | 1.6 ms | 25% |
| ç†è«–æœ€é© | 1å› | 0.4 GB | 0.4 ms | 100% |

### è‡ªå‹•èåˆã®è¨­è¨ˆ

```rust
/// æ¼”ç®—ã‚°ãƒ©ãƒ•
#[derive(Debug, Clone)]
pub enum Op {
    Add(Box<Op>, Box<Op>),
    Mul(Box<Op>, Box<Op>),
    ReLU(Box<Op>),
    Input(usize),  // å…¥åŠ›ID
}

impl Op {
    /// ã‚°ãƒ©ãƒ•ã‚’æœ€é©åŒ–ï¼ˆèåˆå¯èƒ½ãªæ¼”ç®—ã‚’ç‰¹å®šï¼‰
    pub fn optimize(&self) -> Self {
        match self {
            // ReLU(Mul(Add(x, c1), c2)) â†’ èåˆå¯èƒ½
            Op::ReLU(inner) => {
                match &**inner {
                    Op::Mul(a, b) => {
                        // ã•ã‚‰ã«å†…å´ã‚’ãƒã‚§ãƒƒã‚¯
                        Op::ReLU(inner.clone())
                    }
                    _ => self.clone()
                }
            }
            _ => self.clone()
        }
    }
    
    /// èåˆã‚«ãƒ¼ãƒãƒ«ã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    pub fn generate_fused_kernel(&self) -> String {
        // ã‚°ãƒ©ãƒ•ã‚’èµ°æŸ»ã—ã¦CUDAã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        unimplemented!()
    }
}
```

## 9.5 å‹¾é…è¨ˆç®—ã¨é€†ä¼æ’­å®Ÿè£…

### é€†ä¼æ’­ã®æ•°å­¦çš„å®šå¼åŒ–

å„æ¼”ç®—ã«å¯¾ã—ã¦ã€**forward pass**ã¨**backward pass**ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**åŠ ç®—ã®å¾®åˆ†**:

Forward: $z = x + y$  
Backward: $\frac{\partial L}{\partial x} = \frac{\partial L}{\partial z}$, $\frac{\partial L}{\partial y} = \frac{\partial L}{\partial z}$

**ä¹—ç®—ã®å¾®åˆ†**:

Forward: $z = x \times y$  
Backward: $\frac{\partial L}{\partial x} = \frac{\partial L}{\partial z} \times y$, $\frac{\partial L}{\partial y} = \frac{\partial L}{\partial z} \times x$

**ReLUã®å¾®åˆ†**:

Forward: $z = \max(0, x)$  
Backward: $\frac{\partial L}{\partial x} = \frac{\partial L}{\partial z} \times \begin{cases} 1 & \text{if } x > 0 \\ 0 & \text{otherwise} \end{cases}$

### Pythonï¼ˆPyTorchï¼‰ã®è‡ªå‹•å¾®åˆ†

```python
import torch

# Forward pass
x = torch.tensor([1.0, -2.0, 3.0], requires_grad=True)
z = torch.relu(x * 2.0 + 1.0)
loss = z.sum()

# Backward pass
loss.backward()

print(f"x.grad = {x.grad}")
# tensor([2., 0., 2.])  # -2ã®ä½ç½®ã¯0ï¼ˆReLUã§å‹¾é…ãŒæ¶ˆå¤±ï¼‰
```

### Rust ã§ã®å®Ÿè£…

```rust
pub trait Differentiable {
    fn forward(&self, input: &Tensor) -> Tensor;
    fn backward(&self, grad_output: &Tensor) -> Tensor;
}

pub struct ReLU {
    // Forwardæ™‚ã®ãƒã‚¹ã‚¯ã‚’ä¿å­˜
    mask: Option<Vec<bool>>,
}

impl Differentiable for ReLU {
    fn forward(&self, input: &Tensor) -> Tensor {
        let mut output = input.clone();
        let mut mask = vec![false; input.len()];
        
        for (i, val) in output.data.iter_mut().enumerate() {
            if *val > 0.0 {
                mask[i] = true;
            } else {
                *val = 0.0;
                mask[i] = false;
            }
        }
        
        // ãƒã‚¹ã‚¯ã‚’ä¿å­˜ï¼ˆBackward ã§ä½¿ç”¨ï¼‰
        self.mask = Some(mask);
        output
    }
    
    fn backward(&self, grad_output: &Tensor) -> Tensor {
        let mask = self.mask.as_ref().expect("forward not called");
        let mut grad_input = grad_output.clone();
        
        for (i, grad) in grad_input.data.iter_mut().enumerate() {
            if !mask[i] {
                *grad = 0.0;
            }
        }
        
        grad_input
    }
}
```

## 9.6 ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã¨ãƒ“ãƒ¥ãƒ¼æ“ä½œ

### ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°è¦å‰‡

NumPyã®ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°è¦å‰‡ [^4]ï¼š

[^4]: NumPy Broadcasting: https://numpy.org/doc/stable/user/basics.broadcasting.html

1. æ¬¡å…ƒæ•°ãŒç•°ãªã‚‹å ´åˆã€å°ã•ã„æ–¹ã®å…ˆé ­ã«1ã‚’è¿½åŠ 
2. å„è»¸ã§ã€ã‚µã‚¤ã‚ºãŒ1 or ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
3. ã‚µã‚¤ã‚º1ã®è»¸ã¯ã€ã‚‚ã†ä¸€æ–¹ã®ã‚µã‚¤ã‚ºã«æ‹¡å¼µ

**ä¾‹**:

```python
import numpy as np

a = np.array([[1, 2, 3],
              [4, 5, 6]])     # (2, 3)
b = np.array([10, 20, 30])   # (3,)

c = a + b  # (2, 3) + (3,) â†’ (2, 3)
# [[11, 22, 33],
#  [14, 25, 36]]
```

**ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¯è¦–åŒ–**:

```mermaid
graph LR
    subgraph Input
        A["a: (2, 3)<br/>[[1,2,3],<br/>[4,5,6]]"]
        B["b: (3,)<br/>[10,20,30]"]
    end
    
    subgraph Broadcast["ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ"]
        B2["b': (2, 3)<br/>[[10,20,30],<br/>[10,20,30]]"]
    end
    
    subgraph Output
        C["c: (2, 3)<br/>[[11,22,33],<br/>[14,25,36]]"]
    end
    
    A --> C
    B --> B2 --> C
    
    style B2 fill:#fff4e1
```

### Rust ã§ã®ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°å®Ÿè£…

```rust
/// ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¾Œã®å½¢çŠ¶ã‚’è¨ˆç®—
pub fn broadcast_shapes(
    shape1: &[usize],
    shape2: &[usize]
) -> Result<Vec<usize>, String> {
    let max_ndim = shape1.len().max(shape2.len());
    let mut result = vec![0; max_ndim];
    
    for i in 0..max_ndim {
        let dim1 = if i < shape1.len() { 
            shape1[shape1.len() - 1 - i] 
        } else { 
            1 
        };
        let dim2 = if i < shape2.len() { 
            shape2[shape2.len() - 1 - i] 
        } else { 
            1 
        };
        
        if dim1 == dim2 {
            result[max_ndim - 1 - i] = dim1;
        } else if dim1 == 1 {
            result[max_ndim - 1 - i] = dim2;
        } else if dim2 == 1 {
            result[max_ndim - 1 - i] = dim1;
        } else {
            return Err(format!(
                "Incompatible shapes for broadcasting: {:?} and {:?}",
                shape1, shape2
            ));
        }
    }
    
    Ok(result)
}

/// ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸåŠ ç®—
pub fn broadcast_add(
    a: &CpuTensor<f32>,
    b: &CpuTensor<f32>
) -> Result<CpuTensor<f32>, String> {
    let result_shape = broadcast_shapes(&a.shape, &b.shape)?;
    let numel: usize = result_shape.iter().product();
    let mut result_data = vec![0.0; numel];
    
    // å„è¦ç´ ã‚’è¨ˆç®—
    for i in 0..numel {
        let a_idx = compute_broadcast_index(i, &result_shape, &a.shape);
        let b_idx = compute_broadcast_index(i, &result_shape, &b.shape);
        result_data[i] = a.data[a_idx] + b.data[b_idx];
    }
    
    Ok(CpuTensor::new(result_shape, result_data))
}

fn compute_broadcast_index(
    flat_idx: usize,
    result_shape: &[usize],
    original_shape: &[usize]
) -> usize {
    // ãƒ•ãƒ©ãƒƒãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å¤šæ¬¡å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
    // ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆè¦å‰‡ã‚’é©ç”¨ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°
    unimplemented!("å®Ÿè£…ã¯ç·´ç¿’å•é¡Œ")
}
```

### ã¾ã¨ã‚

| è¨­è¨ˆè¦ç´  | Pythonï¼ˆNumPy/PyTorchï¼‰ | Rust | ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ• |
|---------|----------------------|------|------------|
| **å½¢çŠ¶ç®¡ç†** | å®Ÿè¡Œæ™‚ãƒã‚§ãƒƒã‚¯ | é™çš„ or å‹•çš„ï¼ˆé¸æŠå¯ï¼‰ | å®‰å…¨æ€§ vs æŸ”è»Ÿæ€§ |
| **ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰** | è‡ªå‹•è¨ˆç®— | æ˜ç¤ºçš„ç®¡ç† | ç°¡ä¾¿æ€§ vs åˆ¶å¾¡ |
| **ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ** | æš—é»™çš„ | æ˜ç¤ºçš„å®Ÿè£… | ä½¿ã„ã‚„ã™ã• vs ç†è§£ |
| **ã‚«ãƒ¼ãƒãƒ«èåˆ** | JITï¼ˆTorchScriptï¼‰ | æ‰‹å‹• or ãƒã‚¯ãƒ­ | è‡ªå‹• vs æœ€é©åŒ–å¹… |
| **å‹¾é…è¨ˆç®—** | autograd | æ‰‹å‹•å®Ÿè£… | å­¦ç¿’ã‚³ã‚¹ãƒˆ |

**Rustã®å¼·ã¿**:
- å‹ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹å½¢çŠ¶ã‚¨ãƒ©ãƒ¼ã®æ—©æœŸç™ºè¦‹
- æ‰€æœ‰æ¨©ã«ã‚ˆã‚‹å®‰å…¨ãªãƒ¡ãƒ¢ãƒªç®¡ç†
- ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–

**Pythonã®å¼·ã¿**:
- ç°¡æ½”ãªè¨˜è¿°
- è±Šå¯Œãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆcuDNNç­‰ï¼‰
- è‡ªå‹•æœ€é©åŒ–ï¼ˆJITï¼‰

æ¬¡ç« ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—ã‚’ä½¿ã£ã¦ã€å®Ÿéš›ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã¨æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

---

## å‚è€ƒæ–‡çŒ®

1. Paszke, A., et al. (2019). "PyTorch: An Imperative Style, High-Performance Deep Learning Library." NeurIPS.
2. Harris, C. R., et al. (2020). "Array programming with NumPy." Nature, 585(7825), 357-362.
3. NVIDIA Corporation. "cuDNN Developer Guide." https://docs.nvidia.com/deeplearning/cudnn/developer-guide/
4. NVIDIA Corporation. "TensorRT Developer Guide." https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/
5. NumPy Documentation. "Broadcasting." https://numpy.org/doc/stable/user/basics.broadcasting.html
6. PyTorch Documentation. "Tensor Views." https://pytorch.org/docs/stable/tensor_view.html
7. Chellapilla, K., Puri, S., & Simard, P. (2006). "High Performance Convolutional Neural Networks for Document Processing." IEEE.
8. Chetlur, S., et al. (2014). "cuDNN: Efficient Primitives for Deep Learning." arXiv:1410.0759
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬8ç« : GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã¨æœ€é©åŒ–](../03_ç¬¬IIIéƒ¨_GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€/03-08-GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã¨æœ€é©åŒ–.md) | [â¡ï¸ ç¬¬10ç« : ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®Ÿè£…](04-10-ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®Ÿè£….md)