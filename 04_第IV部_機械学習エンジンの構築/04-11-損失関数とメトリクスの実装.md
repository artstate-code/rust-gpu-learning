# 第 11 章：損失関数とメトリクスの実装

本章では、機械学習モデルの学習に不可欠な損失関数（Loss Function）と、モデル性能を評価するメトリクス（Metrics）を Rust で実装します。損失関数は学習の目的関数であり、その数値安定な実装と効率的な勾配計算が、モデルの学習成功の鍵となります。

Python（PyTorch/NumPy）との比較を通じて、Rust での型安全な実装と GPU 最適化の手法を学びます。

---

## 11.1 回帰タスクの損失関数

回帰タスクでは、連続値の予測誤差を最小化することが目標です。代表的な損失関数として、平均二乗誤差（MSE）、平均絶対誤差（MAE）、Huber Loss などがあります。

### 11.1.1 平均二乗誤差（Mean Squared Error, MSE）

MSE は最も基本的な回帰損失関数で、予測値と真値の二乗誤差の平均を計算します。

**数式定義**：
$$
\mathcal{L}_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
$$

**勾配**（$\hat{y}$ に関する）：
$$
\frac{\partial \mathcal{L}_{\text{MSE}}}{\partial \hat{y}_i} = \frac{2}{N} (\hat{y}_i - y_i)
$$

**Python（NumPy）実装**：

```python
import numpy as np

def mse_loss(y_pred, y_true):
    """Mean Squared Error loss"""
    return np.mean((y_pred - y_true) ** 2)

def mse_loss_backward(y_pred, y_true):
    """MSE loss gradient"""
    n = y_pred.shape[0]
    return 2.0 * (y_pred - y_true) / n

# 使用例
y_true = np.array([1.0, 2.0, 3.0, 4.0])
y_pred = np.array([1.1, 2.2, 2.8, 4.3])

loss = mse_loss(y_pred, y_true)  # 0.0425
grad = mse_loss_backward(y_pred, y_true)
```

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

criterion = nn.MSELoss()

y_true = torch.tensor([1.0, 2.0, 3.0, 4.0])
y_pred = torch.tensor([1.1, 2.2, 2.8, 4.3], requires_grad=True)

loss = criterion(y_pred, y_true)
loss.backward()

print(f"Loss: {loss.item()}")
print(f"Gradient: {y_pred.grad}")
```

**Rust（ndarray）実装**：

```rust
use ndarray::{ArrayD, Array1, Zip};

pub fn mse_loss(y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> f32 {
    assert_eq!(y_pred.shape(), y_true.shape(), "Shape mismatch");
    
    let diff = y_pred - y_true;
    let squared = &diff * &diff;
    squared.mean().unwrap()
}

pub fn mse_loss_backward(y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> ArrayD<f32> {
    let n = y_pred.len() as f32;
    2.0 * (y_pred - y_true) / n
}

#[cfg(test)]
mod tests {
    use super::*;
    use ndarray::arr1;

    #[test]
    fn test_mse_loss() {
        let y_true = arr1(&[1.0, 2.0, 3.0, 4.0]).into_dyn();
        let y_pred = arr1(&[1.1, 2.2, 2.8, 4.3]).into_dyn();
        
        let loss = mse_loss(&y_pred, &y_true);
        assert!((loss - 0.0425).abs() < 1e-5);
    }
}
```

**GPU カーネル実装（CUDA）**：

```cuda
// MSE loss forward kernel
__global__ void mse_loss_forward_kernel(
    const float* y_pred,
    const float* y_true,
    float* output,
    int n
) {
    __shared__ float shared_sum[256];
    
    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    float sum = 0.0f;
    if (idx < n) {
        float diff = y_pred[idx] - y_true[idx];
        sum = diff * diff;
    }
    
    shared_sum[tid] = sum;
    __syncthreads();
    
    // Reduction
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            shared_sum[tid] += shared_sum[tid + s];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        atomicAdd(output, shared_sum[0]);
    }
}

// MSE loss backward kernel
__global__ void mse_loss_backward_kernel(
    const float* y_pred,
    const float* y_true,
    float* grad_output,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        grad_output[idx] = 2.0f * (y_pred[idx] - y_true[idx]) / n;
    }
}
```

### 11.1.2 平均絶対誤差（Mean Absolute Error, MAE）

MAE は、予測値と真値の絶対誤差の平均で、外れ値に対して MSE よりロバストです。

**数式定義**：
$$
\mathcal{L}_{\text{MAE}} = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|
$$

**勾配**：
$$
\frac{\partial \mathcal{L}_{\text{MAE}}}{\partial \hat{y}_i} = \frac{1}{N} \cdot \text{sign}(\hat{y}_i - y_i)
$$

**Python 実装**：

```python
import numpy as np

def mae_loss(y_pred, y_true):
    return np.mean(np.abs(y_pred - y_true))

def mae_loss_backward(y_pred, y_true):
    n = y_pred.shape[0]
    return np.sign(y_pred - y_true) / n
```

**Rust 実装**：

```rust
use ndarray::ArrayD;

pub fn mae_loss(y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> f32 {
    let diff = y_pred - y_true;
    diff.mapv(|x| x.abs()).mean().unwrap()
}

pub fn mae_loss_backward(y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> ArrayD<f32> {
    let n = y_pred.len() as f32;
    let diff = y_pred - y_true;
    diff.mapv(|x| x.signum()) / n
}
```

### 11.1.3 Huber Loss（滑らかな MAE）

Huber Loss は、MSE と MAE の利点を組み合わせた損失関数で、小さな誤差には MSE、大きな誤差には MAE を適用します。

**数式定義**：
$$
\mathcal{L}_{\text{Huber}} = \begin{cases}
\frac{1}{2}(y - \hat{y})^2 & \text{if } |y - \hat{y}| \leq \delta \\
\delta \cdot (|y - \hat{y}| - \frac{1}{2}\delta) & \text{otherwise}
\end{cases}
$$

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

huber_loss = nn.HuberLoss(delta=1.0)

y_true = torch.tensor([1.0, 2.0, 3.0, 4.0])
y_pred = torch.tensor([1.1, 2.5, 2.8, 6.0])

loss = huber_loss(y_pred, y_true)
```

**Rust 実装**：

```rust
use ndarray::{ArrayD, Zip};

pub struct HuberLoss {
    delta: f32,
}

impl HuberLoss {
    pub fn new(delta: f32) -> Self {
        Self { delta }
    }

    pub fn forward(&self, y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> f32 {
        let mut sum = 0.0f32;
        
        Zip::from(y_pred)
            .and(y_true)
            .for_each(|&pred, &true_val| {
                let diff = (pred - true_val).abs();
                if diff <= self.delta {
                    sum += 0.5 * diff * diff;
                } else {
                    sum += self.delta * (diff - 0.5 * self.delta);
                }
            });
        
        sum / y_pred.len() as f32
    }

    pub fn backward(&self, y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> ArrayD<f32> {
        let n = y_pred.len() as f32;
        let mut grad = ArrayD::zeros(y_pred.raw_dim());
        
        Zip::from(&mut grad)
            .and(y_pred)
            .and(y_true)
            .for_each(|g, &pred, &true_val| {
                let diff = pred - true_val;
                let abs_diff = diff.abs();
                
                *g = if abs_diff <= self.delta {
                    diff
                } else {
                    self.delta * diff.signum()
                } / n;
            });
        
        grad
    }
}
```

---

## 11.2 分類タスクの損失関数

分類タスクでは、離散的なクラスラベルの予測を目標とします。代表的な損失関数として、交差エントロピー損失（Cross Entropy Loss）があります。

### 11.2.1 二値交差エントロピー（Binary Cross Entropy, BCE）

二値分類（2クラス）のための損失関数です。

**数式定義**：
$$
\mathcal{L}_{\text{BCE}} = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]
$$

ここで、$y_i \in \{0, 1\}$ は真のラベル、$\hat{y}_i \in (0, 1)$ は予測確率です。

**勾配**：
$$
\frac{\partial \mathcal{L}_{\text{BCE}}}{\partial \hat{y}_i} = -\frac{1}{N} \left(\frac{y_i}{\hat{y}_i} - \frac{1 - y_i}{1 - \hat{y}_i}\right)
$$

**数値安定性の問題**：

$\hat{y}_i$ が 0 や 1 に近い場合、`log(0)` や除算によって数値的に不安定になります。

**安定版の実装**（logits から直接計算）：
$$
\mathcal{L}_{\text{BCE}} = -\frac{1}{N} \sum_{i=1}^{N} [y_i \cdot z_i - \log(1 + e^{z_i})]
$$

ここで、$z_i$ は sigmoid を通す前の logits（$\hat{y}_i = \sigma(z_i)$）です。

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

# 確率値からの BCE
bce_loss = nn.BCELoss()

y_true = torch.tensor([1.0, 0.0, 1.0, 0.0])
y_pred = torch.tensor([0.9, 0.1, 0.8, 0.2])

loss = bce_loss(y_pred, y_true)

# logits からの BCE（数値安定）
bce_with_logits = nn.BCEWithLogitsLoss()

logits = torch.tensor([2.0, -2.0, 1.5, -1.5])
loss_stable = bce_with_logits(logits, y_true)
```

**Rust 実装**：

```rust
use ndarray::{ArrayD, Zip};

pub fn bce_loss(y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> f32 {
    let eps = 1e-7;  // 数値安定性のための小さな値
    let mut sum = 0.0f32;
    
    Zip::from(y_pred)
        .and(y_true)
        .for_each(|&pred, &true_val| {
            // clip to [eps, 1-eps] for numerical stability
            let pred_clipped = pred.max(eps).min(1.0 - eps);
            sum -= true_val * pred_clipped.ln() 
                 + (1.0 - true_val) * (1.0 - pred_clipped).ln();
        });
    
    sum / y_pred.len() as f32
}

pub fn bce_loss_backward(y_pred: &ArrayD<f32>, y_true: &ArrayD<f32>) -> ArrayD<f32> {
    let eps = 1e-7;
    let n = y_pred.len() as f32;
    let mut grad = ArrayD::zeros(y_pred.raw_dim());
    
    Zip::from(&mut grad)
        .and(y_pred)
        .and(y_true)
        .for_each(|g, &pred, &true_val| {
            let pred_clipped = pred.max(eps).min(1.0 - eps);
            *g = -(true_val / pred_clipped - (1.0 - true_val) / (1.0 - pred_clipped)) / n;
        });
    
    grad
}

// logits からの安定版実装
pub fn bce_with_logits_loss(logits: &ArrayD<f32>, y_true: &ArrayD<f32>) -> f32 {
    let mut sum = 0.0f32;
    
    Zip::from(logits)
        .and(y_true)
        .for_each(|&z, &y| {
            // log(1 + exp(z)) を安定的に計算
            let max_val = z.max(0.0);
            let loss = y * z - max_val - ((-max_val).exp() + (z - max_val).exp()).ln();
            sum -= loss;
        });
    
    sum / logits.len() as f32
}

pub fn bce_with_logits_backward(logits: &ArrayD<f32>, y_true: &ArrayD<f32>) -> ArrayD<f32> {
    let n = logits.len() as f32;
    let mut grad = ArrayD::zeros(logits.raw_dim());
    
    Zip::from(&mut grad)
        .and(logits)
        .and(y_true)
        .for_each(|g, &z, &y| {
            // sigmoid(z) - y
            let sigmoid = 1.0 / (1.0 + (-z).exp());
            *g = (sigmoid - y) / n;
        });
    
    grad
}
```

### 11.2.2 多クラス交差エントロピー（Categorical Cross Entropy）

多クラス分類（K クラス）のための損失関数です。

**数式定義**：
$$
\mathcal{L}_{\text{CE}} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i,k} \log(\hat{y}_{i,k})
$$

ここで、$y_{i,k}$ は one-hot エンコードされたラベル、$\hat{y}_{i,k}$ は softmax 後の予測確率です。

**Softmax 関数**：
$$
\hat{y}_{i,k} = \frac{e^{z_{i,k}}}{\sum_{j=1}^{K} e^{z_{i,j}}}
$$

**数値安定な Softmax**：
$$
\hat{y}_{i,k} = \frac{e^{z_{i,k} - \max_j z_{i,j}}}{\sum_{j=1}^{K} e^{z_{i,j} - \max_j z_{i,j}}}
$$

**勾配**（softmax + cross entropy の合成）：
$$
\frac{\partial \mathcal{L}_{\text{CE}}}{\partial z_{i,k}} = \frac{1}{N} (\hat{y}_{i,k} - y_{i,k})
$$

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

# 確率値からの CE
ce_loss = nn.CrossEntropyLoss()

# logits: (batch_size, num_classes)
logits = torch.randn(32, 10)
# labels: class indices (not one-hot)
labels = torch.randint(0, 10, (32,))

loss = ce_loss(logits, labels)

# 手動実装
def softmax(logits):
    # 数値安定版
    max_logits = logits.max(dim=1, keepdim=True)[0]
    exp_logits = torch.exp(logits - max_logits)
    return exp_logits / exp_logits.sum(dim=1, keepdim=True)

def cross_entropy_loss(logits, labels):
    # logits: (N, K), labels: (N,) with class indices
    probs = softmax(logits)
    log_probs = torch.log(probs + 1e-7)
    
    # labels を one-hot に変換
    one_hot = torch.zeros_like(logits)
    one_hot.scatter_(1, labels.unsqueeze(1), 1)
    
    loss = -(one_hot * log_probs).sum(dim=1).mean()
    return loss

def cross_entropy_backward(logits, labels):
    probs = softmax(logits)
    
    # labels を one-hot に変換
    one_hot = torch.zeros_like(logits)
    one_hot.scatter_(1, labels.unsqueeze(1), 1)
    
    grad = (probs - one_hot) / logits.shape[0]
    return grad
```

**Rust 実装**：

```rust
use ndarray::{Array2, Array1, Axis, s};

pub fn softmax(logits: &Array2<f32>) -> Array2<f32> {
    let mut result = Array2::zeros(logits.dim());
    
    for (i, row) in logits.axis_iter(Axis(0)).enumerate() {
        // 数値安定性のため最大値を引く
        let max_val = row.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
        
        let exp_values: Array1<f32> = row.mapv(|x| (x - max_val).exp());
        let sum = exp_values.sum();
        
        result.row_mut(i).assign(&(&exp_values / sum));
    }
    
    result
}

pub fn cross_entropy_loss(logits: &Array2<f32>, labels: &Array1<usize>) -> f32 {
    let n = logits.nrows();
    let probs = softmax(logits);
    let eps = 1e-7;
    
    let mut sum = 0.0f32;
    for (i, &label) in labels.iter().enumerate() {
        sum -= (probs[[i, label]] + eps).ln();
    }
    
    sum / n as f32
}

pub fn cross_entropy_backward(logits: &Array2<f32>, labels: &Array1<usize>) -> Array2<f32> {
    let n = logits.nrows();
    let probs = softmax(logits);
    let mut grad = probs.clone();
    
    // grad = (probs - one_hot) / n
    for (i, &label) in labels.iter().enumerate() {
        grad[[i, label]] -= 1.0;
    }
    
    grad / n as f32
}

#[cfg(test)]
mod tests {
    use super::*;
    use ndarray::arr2;

    #[test]
    fn test_cross_entropy() {
        let logits = arr2(&[[2.0, 1.0, 0.1], [0.5, 2.5, 0.2]]);
        let labels = Array1::from(vec![0, 1]);
        
        let loss = cross_entropy_loss(&logits, &labels);
        assert!(loss > 0.0);
        
        let grad = cross_entropy_backward(&logits, &labels);
        assert_eq!(grad.shape(), logits.shape());
    }
}
```

**GPU カーネル実装（CUDA）**：

```cuda
// Softmax kernel (行ごとに計算)
__global__ void softmax_kernel(
    const float* logits,
    float* output,
    int batch_size,
    int num_classes
) {
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < batch_size) {
        const float* logits_row = logits + row * num_classes;
        float* output_row = output + row * num_classes;
        
        // 最大値を見つける
        float max_val = -INFINITY;
        for (int i = 0; i < num_classes; i++) {
            max_val = fmaxf(max_val, logits_row[i]);
        }
        
        // exp の合計を計算
        float sum = 0.0f;
        for (int i = 0; i < num_classes; i++) {
            output_row[i] = expf(logits_row[i] - max_val);
            sum += output_row[i];
        }
        
        // 正規化
        for (int i = 0; i < num_classes; i++) {
            output_row[i] /= sum;
        }
    }
}

// Cross Entropy loss kernel
__global__ void cross_entropy_loss_kernel(
    const float* probs,
    const int* labels,
    float* output,
    int batch_size,
    int num_classes
) {
    __shared__ float shared_sum[256];
    
    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    float sum = 0.0f;
    if (idx < batch_size) {
        int label = labels[idx];
        float prob = probs[idx * num_classes + label];
        sum = -logf(prob + 1e-7f);
    }
    
    shared_sum[tid] = sum;
    __syncthreads();
    
    // Reduction
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            shared_sum[tid] += shared_sum[tid + s];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        atomicAdd(output, shared_sum[0]);
    }
}
```

### 11.2.3 Focal Loss（不均衡データ向け）

Focal Loss は、クラス不均衡問題に対処するため、簡単な例の重みを下げる損失関数です。

**数式定義**：
$$
\mathcal{L}_{\text{Focal}} = -\frac{1}{N} \sum_{i=1}^{N} (1 - \hat{y}_i)^\gamma \log(\hat{y}_i)
$$

ここで、$\gamma$ は focusing parameter（通常 2）です。

**Python 実装**：

```python
import torch
import torch.nn.functional as F

def focal_loss(logits, labels, gamma=2.0, alpha=0.25):
    ce_loss = F.cross_entropy(logits, labels, reduction='none')
    probs = F.softmax(logits, dim=1)
    
    # 正解クラスの確率を取得
    pt = probs.gather(1, labels.unsqueeze(1)).squeeze(1)
    
    focal_weight = (1 - pt) ** gamma
    loss = alpha * focal_weight * ce_loss
    
    return loss.mean()
```

**Rust 実装**：

```rust
pub fn focal_loss(
    logits: &Array2<f32>,
    labels: &Array1<usize>,
    gamma: f32,
    alpha: f32,
) -> f32 {
    let probs = softmax(logits);
    let n = logits.nrows();
    let eps = 1e-7;
    
    let mut sum = 0.0f32;
    for (i, &label) in labels.iter().enumerate() {
        let pt = probs[[i, label]].max(eps);
        let focal_weight = (1.0 - pt).powf(gamma);
        sum -= alpha * focal_weight * pt.ln();
    }
    
    sum / n as f32
}
```

---

## 11.3 カスタム損失関数の設計パターン

実用的な機械学習タスクでは、標準的な損失関数だけでなく、タスク固有のカスタム損失関数が必要になる場合があります。

### 11.3.1 複合損失関数（Multi-task Loss）

複数のタスクを同時に学習する場合、各タスクの損失を重み付けして合計します。

**数式定義**：
$$
\mathcal{L}_{\text{total}} = \sum_{i=1}^{T} \lambda_i \mathcal{L}_i
$$

**Python 実装**：

```python
import torch
import torch.nn as nn

class MultiTaskLoss(nn.Module):
    def __init__(self, task_weights):
        super().__init__()
        self.task_weights = task_weights
        
    def forward(self, predictions, targets):
        # predictions: dict of task_name -> prediction
        # targets: dict of task_name -> target
        total_loss = 0.0
        
        for task_name, weight in self.task_weights.items():
            if task_name == 'classification':
                loss = F.cross_entropy(predictions[task_name], targets[task_name])
            elif task_name == 'regression':
                loss = F.mse_loss(predictions[task_name], targets[task_name])
            
            total_loss += weight * loss
        
        return total_loss

# 使用例
multi_loss = MultiTaskLoss({
    'classification': 1.0,
    'regression': 0.5,
})
```

**Rust 実装**：

```rust
use std::collections::HashMap;

pub struct MultiTaskLoss {
    task_weights: HashMap<String, f32>,
}

impl MultiTaskLoss {
    pub fn new(task_weights: HashMap<String, f32>) -> Self {
        Self { task_weights }
    }

    pub fn compute(
        &self,
        predictions: &HashMap<String, ArrayD<f32>>,
        targets: &HashMap<String, ArrayD<f32>>,
    ) -> f32 {
        let mut total_loss = 0.0;

        for (task_name, &weight) in &self.task_weights {
            if let (Some(pred), Some(target)) = (
                predictions.get(task_name),
                targets.get(task_name),
            ) {
                // タスクに応じて適切な損失関数を選択
                let loss = match task_name.as_str() {
                    "classification" => {
                        // 交差エントロピー損失を計算
                        // （実装省略）
                        0.0
                    }
                    "regression" => mse_loss(pred, target),
                    _ => 0.0,
                };

                total_loss += weight * loss;
            }
        }

        total_loss
    }
}
```

### 11.3.2 正則化項を含む損失関数

過学習を防ぐため、重みの L1/L2 正則化を損失関数に追加します。

**L2 正則化（Weight Decay）**：
$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \lambda \sum_i w_i^2
$$

**L1 正則化（Lasso）**：
$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \lambda \sum_i |w_i|
$$

**Python 実装**：

```python
def l2_regularization(model, lambda_reg):
    l2_loss = 0.0
    for param in model.parameters():
        l2_loss += torch.sum(param ** 2)
    return lambda_reg * l2_loss

# 使用例
task_loss = criterion(outputs, targets)
reg_loss = l2_regularization(model, lambda_reg=0.01)
total_loss = task_loss + reg_loss
```

**Rust 実装**：

```rust
pub fn l2_regularization(weights: &[ArrayD<f32>], lambda: f32) -> f32 {
    let mut sum = 0.0;
    for w in weights {
        sum += w.mapv(|x| x * x).sum();
    }
    lambda * sum
}

pub fn l1_regularization(weights: &[ArrayD<f32>], lambda: f32) -> f32 {
    let mut sum = 0.0;
    for w in weights {
        sum += w.mapv(|x| x.abs()).sum();
    }
    lambda * sum
}
```

### 11.3.3 Contrastive Loss（対照学習）

対照学習では、類似したサンプルを近づけ、異なるサンプルを遠ざける損失関数を使います。

**Triplet Loss**：
$$
\mathcal{L}_{\text{triplet}} = \max(0, \|f(a) - f(p)\|^2 - \|f(a) - f(n)\|^2 + \alpha)
$$

ここで、$a$ はアンカー、$p$ は正例、$n$ は負例、$\alpha$ はマージンです。

**Python 実装**：

```python
import torch
import torch.nn as nn

triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)

anchor = torch.randn(32, 128)
positive = torch.randn(32, 128)
negative = torch.randn(32, 128)

loss = triplet_loss(anchor, positive, negative)
```

---

## 11.4 評価メトリクスの実装

損失関数とは別に、モデルの性能を人間が理解しやすい形で評価するメトリクスが重要です。

### 11.4.1 分類タスクのメトリクス

**Accuracy（正解率）**：
$$
\text{Accuracy} = \frac{\text{正解数}}{\text{全サンプル数}}
$$

**Precision（適合率）**：
$$
\text{Precision} = \frac{TP}{TP + FP}
$$

**Recall（再現率）**：
$$
\text{Recall} = \frac{TP}{TP + FN}
$$

**F1 Score**：
$$
\text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

**Python 実装**：

```python
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_true = np.array([0, 1, 2, 0, 1, 2])
y_pred = np.array([0, 2, 1, 0, 1, 2])

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='macro')
recall = recall_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')

# 手動実装
def accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)

def confusion_matrix(y_true, y_pred, num_classes):
    cm = np.zeros((num_classes, num_classes), dtype=int)
    for true_label, pred_label in zip(y_true, y_pred):
        cm[true_label, pred_label] += 1
    return cm
```

**Rust 実装**：

```rust
use ndarray::{Array1, Array2};

pub fn accuracy(y_true: &Array1<usize>, y_pred: &Array1<usize>) -> f32 {
    let correct = y_true.iter()
        .zip(y_pred.iter())
        .filter(|(&t, &p)| t == p)
        .count();
    
    correct as f32 / y_true.len() as f32
}

pub fn confusion_matrix(
    y_true: &Array1<usize>,
    y_pred: &Array1<usize>,
    num_classes: usize,
) -> Array2<usize> {
    let mut cm = Array2::zeros((num_classes, num_classes));
    
    for (&true_label, &pred_label) in y_true.iter().zip(y_pred.iter()) {
        cm[[true_label, pred_label]] += 1;
    }
    
    cm
}

pub struct ClassificationMetrics {
    pub accuracy: f32,
    pub precision: Vec<f32>,
    pub recall: Vec<f32>,
    pub f1: Vec<f32>,
}

pub fn compute_metrics(
    y_true: &Array1<usize>,
    y_pred: &Array1<usize>,
    num_classes: usize,
) -> ClassificationMetrics {
    let cm = confusion_matrix(y_true, y_pred, num_classes);
    let acc = accuracy(y_true, y_pred);
    
    let mut precision = Vec::new();
    let mut recall = Vec::new();
    let mut f1 = Vec::new();
    
    for class in 0..num_classes {
        let tp = cm[[class, class]] as f32;
        let fp = cm.column(class).sum() as f32 - tp;
        let fn_val = cm.row(class).sum() as f32 - tp;
        
        let prec = if tp + fp > 0.0 { tp / (tp + fp) } else { 0.0 };
        let rec = if tp + fn_val > 0.0 { tp / (tp + fn_val) } else { 0.0 };
        let f1_val = if prec + rec > 0.0 {
            2.0 * prec * rec / (prec + rec)
        } else {
            0.0
        };
        
        precision.push(prec);
        recall.push(rec);
        f1.push(f1_val);
    }
    
    ClassificationMetrics {
        accuracy: acc,
        precision,
        recall,
        f1,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_metrics() {
        let y_true = Array1::from(vec![0, 1, 2, 0, 1, 2]);
        let y_pred = Array1::from(vec![0, 2, 1, 0, 1, 2]);
        
        let acc = accuracy(&y_true, &y_pred);
        assert!((acc - 0.5).abs() < 1e-5);
        
        let metrics = compute_metrics(&y_true, &y_pred, 3);
        assert_eq!(metrics.precision.len(), 3);
    }
}
```

### 11.4.2 回帰タスクのメトリクス

**R² Score（決定係数）**：
$$
R^2 = 1 - \frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i (y_i - \bar{y})^2}
$$

**Python 実装**：

```python
from sklearn.metrics import r2_score, mean_absolute_error

y_true = np.array([3.0, -0.5, 2.0, 7.0])
y_pred = np.array([2.5, 0.0, 2.0, 8.0])

r2 = r2_score(y_true, y_pred)
mae = mean_absolute_error(y_true, y_pred)
```

**Rust 実装**：

```rust
pub fn r2_score(y_true: &Array1<f32>, y_pred: &Array1<f32>) -> f32 {
    let mean_true = y_true.mean().unwrap();
    
    let ss_res: f32 = y_true.iter()
        .zip(y_pred.iter())
        .map(|(&t, &p)| (t - p).powi(2))
        .sum();
    
    let ss_tot: f32 = y_true.iter()
        .map(|&t| (t - mean_true).powi(2))
        .sum();
    
    1.0 - ss_res / ss_tot
}
```

---

## 11.5 まとめ

本章では、機械学習の学習と評価に必要な損失関数とメトリクスを、Python と Rust の両方で実装しました。

**主要なポイント**：

1. **回帰損失関数**: MSE、MAE、Huber Loss の実装と特性
2. **分類損失関数**: BCE、交差エントロピー、Focal Loss の数値安定な実装
3. **カスタム損失**: マルチタスク学習、正則化、対照学習の損失関数
4. **評価メトリクス**: Accuracy、Precision、Recall、F1 Score、R² Score の実装

**数値安定性の重要性**：

- Softmax: 最大値を引いてオーバーフローを防ぐ
- Log-Softmax: log-sum-exp トリックを使う
- BCE: logits から直接計算して精度を向上

**次章への接続**：

次の第 12 章では、データローディングとバッチ処理パイプラインの実装について詳しく解説し、効率的なデータ供給の仕組みを学びます。

---

## 参考文献

- Lin, T. Y., et al. (2017). Focal Loss for Dense Object Detection. ICCV.
- Schroff, F., Kalenichenko, D., & Philbin, J. (2015). FaceNet: A Unified Embedding for Face Recognition and Clustering. CVPR.
- Huber, P. J. (1964). Robust Estimation of a Location Parameter. The Annals of Mathematical Statistics.

