[ğŸ“š ç›®æ¬¡](../README.md) | [â¬…ï¸ ç¬¬9ç« ](04-09-ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ.md) | [â¡ï¸ ç¬¬11ç« ](04-11-æå¤±é–¢æ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®Ÿè£….md)

---

# ç¬¬ 10 ç« ï¼šãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®Ÿè£…

æœ¬ç« ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹æˆã™ã‚‹åŸºæœ¬çš„ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆæ´»æ€§åŒ–é–¢æ•°ã€æ­£è¦åŒ–å±¤ã€ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼‰ã‚’ Rust ã§å®Ÿè£…ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ã€ã©ã®ã‚ˆã†ãªæ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚‚å…±é€šã—ã¦ä½¿ã‚ã‚Œã‚‹åŸºç¤çš„ãªæ§‹æˆè¦ç´ ã§ã‚ã‚Šã€GPU ä¸Šã§åŠ¹ç‡çš„ã«å®Ÿè£…ã™ã‚‹ã“ã¨ãŒå­¦ç¿’ãƒ»æ¨è«–æ€§èƒ½ã«ç›´çµã—ã¾ã™ã€‚

Pythonï¼ˆPyTorch/NumPyï¼‰ã¨ã®æ¯”è¼ƒã‚’é€šã˜ã¦ã€Rust ã§ã®å‹å®‰å…¨ãªå®Ÿè£…ã¨ GPU æœ€é©åŒ–ã®æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

---

## 10.1 æ´»æ€§åŒ–é–¢æ•°ã®å®Ÿè£…ã¨ GPU æœ€é©åŒ–

æ´»æ€§åŒ–é–¢æ•°ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«éç·šå½¢æ€§ã‚’å°å…¥ã™ã‚‹é‡è¦ãªè¦ç´ ã§ã™ã€‚æœ¬ç¯€ã§ã¯ã€ä»£è¡¨çš„ãªæ´»æ€§åŒ–é–¢æ•°ï¼ˆReLUã€Sigmoidã€Tanhã€GELUã€Swishï¼‰ã‚’å®Ÿè£…ã—ã€ãã®å‹¾é…è¨ˆç®—ã¨ GPU æœ€é©åŒ–ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

### 10.1.1 ReLUï¼ˆRectified Linear Unitï¼‰

ReLU ã¯æœ€ã‚‚åºƒãä½¿ã‚ã‚Œã‚‹æ´»æ€§åŒ–é–¢æ•°ã§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒä½ãã€å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã—ã¾ã™ã€‚

**æ•°å¼å®šç¾©**ï¼š
$$
\text{ReLU}(x) = \max(0, x)
$$

**å‹¾é…**ï¼š
$$
\frac{\partial \text{ReLU}(x)}{\partial x} = \begin{cases}
1 & \text{if } x > 0 \\
0 & \text{otherwise}
\end{cases}
$$

**Pythonï¼ˆNumPyï¼‰å®Ÿè£…**ï¼š

```python
import numpy as np

def relu_forward(x):
    """ReLU forward pass"""
    return np.maximum(0, x)

def relu_backward(x, grad_output):
    """ReLU backward pass"""
    grad_input = grad_output * (x > 0)
    return grad_input

# ä½¿ç”¨ä¾‹
x = np.array([[-1.0, 2.0], [3.0, -4.0]])
y = relu_forward(x)  # [[0., 2.], [3., 0.]]

grad_output = np.ones_like(y)
grad_input = relu_backward(x, grad_output)  # [[0., 1.], [1., 0.]]
```

**Rustï¼ˆndarrayï¼‰å®Ÿè£…**ï¼š

```rust
use ndarray::{Array, ArrayD, Zip};

pub fn relu_forward(x: &ArrayD<f32>) -> ArrayD<f32> {
    x.mapv(|v| v.max(0.0))
}

pub fn relu_backward(x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    let mut grad_input = Array::zeros(x.raw_dim());
    Zip::from(&mut grad_input)
        .and(x)
        .and(grad_output)
        .for_each(|grad_in, &x_val, &grad_out| {
            *grad_in = if x_val > 0.0 { grad_out } else { 0.0 };
        });
    grad_input
}
```

**GPU ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…ï¼ˆCUDAï¼‰**ï¼š

ReLU ã¯è¦ç´ ã”ã¨ã®æ¼”ç®—ï¼ˆelement-wise operationï¼‰ãªã®ã§ã€GPU ã§ä¸¦åˆ—åŒ–ã—ã‚„ã™ã„æ¼”ç®—ã§ã™ã€‚

```cuda
// ReLU forward kernel
__global__ void relu_forward_kernel(const float* x, float* y, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        y[idx] = fmaxf(0.0f, x[idx]);
    }
}

// ReLU backward kernel
__global__ void relu_backward_kernel(
    const float* x,
    const float* grad_output,
    float* grad_input,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        grad_input[idx] = (x[idx] > 0.0f) ? grad_output[idx] : 0.0f;
    }
}
```

**Rust ã‹ã‚‰ CUDA ã‚«ãƒ¼ãƒãƒ«ã‚’å‘¼ã³å‡ºã™ï¼ˆcudarc ä½¿ç”¨ï¼‰**ï¼š

```rust
use cudarc::driver::*;
use std::sync::Arc;

pub struct ReLULayer {
    device: Arc<CudaDevice>,
}

impl ReLULayer {
    pub fn new(device: Arc<CudaDevice>) -> Result<Self, CudaError> {
        Ok(Self { device })
    }

    pub fn forward(&self, x: &CudaSlice<f32>) -> Result<CudaSlice<f32>, CudaError> {
        let n = x.len();
        let mut y = self.device.alloc_zeros::<f32>(n)?;

        // ã‚«ãƒ¼ãƒãƒ«èµ·å‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        let threads = 256;
        let blocks = (n + threads - 1) / threads;

        // PTXã¾ãŸã¯CUDAã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚«ãƒ¼ãƒãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆäº‹å‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã¨ä»®å®šï¼‰
        let kernel = self.device.get_func("relu_module", "relu_forward_kernel")?;
        
        unsafe {
            kernel.launch(
                LaunchConfig {
                    grid_dim: (blocks as u32, 1, 1),
                    block_dim: (threads as u32, 1, 1),
                    shared_mem_bytes: 0,
                },
                (&x, &mut y, n as i32),
            )?;
        }

        Ok(y)
    }

    pub fn backward(
        &self,
        x: &CudaSlice<f32>,
        grad_output: &CudaSlice<f32>,
    ) -> Result<CudaSlice<f32>, CudaError> {
        let n = x.len();
        let mut grad_input = self.device.alloc_zeros::<f32>(n)?;

        let threads = 256;
        let blocks = (n + threads - 1) / threads;

        let kernel = self.device.get_func("relu_module", "relu_backward_kernel")?;
        
        unsafe {
            kernel.launch(
                LaunchConfig {
                    grid_dim: (blocks as u32, 1, 1),
                    block_dim: (threads as u32, 1, 1),
                    shared_mem_bytes: 0,
                },
                (&x, &grad_output, &mut grad_input, n as i32),
            )?;
        }

        Ok(grad_input)
    }
}
```

### 10.1.2 Leaky ReLU ã¨ PReLU

ReLU ã®å¤‰ç¨®ã¨ã—ã¦ã€è² ã®å€¤ã«å¯¾ã—ã¦ã‚‚å°ã•ãªå‹¾é…ã‚’æŒãŸã›ã‚‹ Leaky ReLU ã¨ã€è² ã®å‚¾ãã‚’å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã™ã‚‹ PReLU ãŒã‚ã‚Šã¾ã™ã€‚

**Leaky ReLU**ï¼š
$$
\text{LeakyReLU}(x) = \begin{cases}
x & \text{if } x > 0 \\
\alpha x & \text{otherwise}
\end{cases}
$$

é€šå¸¸ã€$\alpha = 0.01$ ãŒä½¿ã‚ã‚Œã¾ã™ã€‚

**PReLUï¼ˆParametric ReLUï¼‰**ï¼š
$$
\text{PReLU}(x) = \begin{cases}
x & \text{if } x > 0 \\
\alpha x & \text{otherwise}
\end{cases}
$$

$\alpha$ ã¯å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™ã€‚

**Pythonï¼ˆPyTorchï¼‰å®Ÿè£…**ï¼š

```python
import torch
import torch.nn as nn

# Leaky ReLU
class LeakyReLU(nn.Module):
    def __init__(self, alpha=0.01):
        super().__init__()
        self.alpha = alpha
    
    def forward(self, x):
        return torch.where(x > 0, x, self.alpha * x)

# PReLU
prelu = nn.PReLU(num_parameters=1, init=0.25)
x = torch.randn(2, 3)
y = prelu(x)
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{Array, ArrayD, Zip};

pub struct LeakyReLU {
    alpha: f32,
}

impl LeakyReLU {
    pub fn new(alpha: f32) -> Self {
        Self { alpha }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> ArrayD<f32> {
        x.mapv(|v| if v > 0.0 { v } else { self.alpha * v })
    }

    pub fn backward(&self, x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
        let mut grad_input = Array::zeros(x.raw_dim());
        Zip::from(&mut grad_input)
            .and(x)
            .and(grad_output)
            .for_each(|grad_in, &x_val, &grad_out| {
                *grad_in = if x_val > 0.0 { grad_out } else { self.alpha * grad_out };
            });
        grad_input
    }
}

pub struct PReLU {
    alpha: ArrayD<f32>,  // å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
}

impl PReLU {
    pub fn new(num_parameters: usize, init: f32) -> Self {
        let alpha = Array::from_elem(vec![num_parameters], init);
        Self { alpha }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> ArrayD<f32> {
        // ãƒãƒ£ãƒãƒ«ã”ã¨ã«ç•°ãªã‚‹alphaã‚’é©ç”¨ã™ã‚‹å®Ÿè£…ãŒå¿…è¦
        // ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚å˜ä¸€ã®alphaã‚’ä»®å®š
        let alpha_val = self.alpha[[0]];
        x.mapv(|v| if v > 0.0 { v } else { alpha_val * v })
    }

    pub fn backward(
        &self,
        x: &ArrayD<f32>,
        grad_output: &ArrayD<f32>,
    ) -> (ArrayD<f32>, ArrayD<f32>) {
        // grad_input ã¨ grad_alpha ã‚’è¨ˆç®—
        let alpha_val = self.alpha[[0]];
        let mut grad_input = Array::zeros(x.raw_dim());
        let mut grad_alpha_sum = 0.0f32;

        Zip::from(&mut grad_input)
            .and(x)
            .and(grad_output)
            .for_each(|grad_in, &x_val, &grad_out| {
                if x_val > 0.0 {
                    *grad_in = grad_out;
                } else {
                    *grad_in = alpha_val * grad_out;
                    grad_alpha_sum += x_val * grad_out;
                }
            });

        let mut grad_alpha = Array::zeros(self.alpha.raw_dim());
        grad_alpha[[0]] = grad_alpha_sum;

        (grad_input, grad_alpha)
    }
}
```

### 10.1.3 Sigmoid ã¨ Tanh

Sigmoid ã¨ Tanh ã¯å¤å…¸çš„ãªæ´»æ€§åŒ–é–¢æ•°ã§ã€å‡ºåŠ›ç¯„å›²ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚

**Sigmoid**ï¼š
$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$

**å‹¾é…**ï¼š
$$
\frac{\partial \sigma(x)}{\partial x} = \sigma(x) \cdot (1 - \sigma(x))
$$

**Tanh**ï¼š
$$
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
$$

**å‹¾é…**ï¼š
$$
\frac{\partial \tanh(x)}{\partial x} = 1 - \tanh^2(x)
$$

**Python å®Ÿè£…**ï¼š

```python
import numpy as np

def sigmoid_forward(x):
    return 1.0 / (1.0 + np.exp(-x))

def sigmoid_backward(y, grad_output):
    # y ã¯ forward ã®å‡ºåŠ›ã‚’å†åˆ©ç”¨ï¼ˆè¨ˆç®—åŠ¹ç‡åŒ–ï¼‰
    grad_input = grad_output * y * (1.0 - y)
    return grad_input

def tanh_forward(x):
    return np.tanh(x)

def tanh_backward(y, grad_output):
    # y ã¯ forward ã®å‡ºåŠ›ã‚’å†åˆ©ç”¨
    grad_input = grad_output * (1.0 - y ** 2)
    return grad_input
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{Array, ArrayD, Zip};

pub fn sigmoid_forward(x: &ArrayD<f32>) -> ArrayD<f32> {
    x.mapv(|v| 1.0 / (1.0 + (-v).exp()))
}

pub fn sigmoid_backward(y: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    // y ã¯ forward ã®å‡ºåŠ›
    let mut grad_input = Array::zeros(y.raw_dim());
    Zip::from(&mut grad_input)
        .and(y)
        .and(grad_output)
        .for_each(|grad_in, &y_val, &grad_out| {
            *grad_in = grad_out * y_val * (1.0 - y_val);
        });
    grad_input
}

pub fn tanh_forward(x: &ArrayD<f32>) -> ArrayD<f32> {
    x.mapv(|v| v.tanh())
}

pub fn tanh_backward(y: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    let mut grad_input = Array::zeros(y.raw_dim());
    Zip::from(&mut grad_input)
        .and(y)
        .and(grad_output)
        .for_each(|grad_in, &y_val, &grad_out| {
            *grad_in = grad_out * (1.0 - y_val * y_val);
        });
    grad_input
}
```

**æ•°å€¤å®‰å®šæ€§ã®æ³¨æ„**ï¼š

Sigmoid ã§ã¯ã€$x$ ãŒéå¸¸ã«å¤§ãã„ï¼ˆã¾ãŸã¯å°ã•ã„ï¼‰å ´åˆã€`exp(-x)` ãŒã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ï¼ˆã¾ãŸã¯ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ï¼‰ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å®‰å®šç‰ˆã®å®Ÿè£…ï¼š

```rust
pub fn sigmoid_stable(x: f32) -> f32 {
    if x >= 0.0 {
        1.0 / (1.0 + (-x).exp())
    } else {
        let exp_x = x.exp();
        exp_x / (1.0 + exp_x)
    }
}
```

### 10.1.4 GELUï¼ˆGaussian Error Linear Unitï¼‰

GELU ã¯ã€Transformer ãªã©ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã§åºƒãä½¿ã‚ã‚Œã‚‹æ´»æ€§åŒ–é–¢æ•°ã§ã™ã€‚

**æ•°å¼å®šç¾©**ï¼š
$$
\text{GELU}(x) = x \cdot \Phi(x)
$$

ã“ã“ã§ã€$\Phi(x)$ ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã®ç´¯ç©åˆ†å¸ƒé–¢æ•°ï¼ˆCDFï¼‰ã§ã™ã€‚

**è¿‘ä¼¼ç‰ˆ**ï¼ˆè¨ˆç®—åŠ¹ç‡åŒ–ï¼‰ï¼š
$$
\text{GELU}(x) \approx 0.5 x \left(1 + \tanh\left(\sqrt{\frac{2}{\pi}} \left(x + 0.044715 x^3\right)\right)\right)
$$

**å‹¾é…**ï¼ˆè¿‘ä¼¼ç‰ˆï¼‰ï¼š

è¤‡é›‘ãªå°å‡ºã¯çœç•¥ã—ã¾ã™ãŒã€è‡ªå‹•å¾®åˆ†ã‚’ä½¿ã†ã®ãŒå®Ÿç”¨çš„ã§ã™ã€‚

**Pythonï¼ˆPyTorchï¼‰å®Ÿè£…**ï¼š

```python
import torch
import torch.nn as nn

gelu = nn.GELU()
x = torch.randn(2, 3)
y = gelu(x)

# è¿‘ä¼¼ç‰ˆã®æ‰‹å‹•å®Ÿè£…
def gelu_approx(x):
    return 0.5 * x * (1.0 + torch.tanh(
        torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * x ** 3)
    ))
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::ArrayD;
use std::f32::consts::PI;

pub fn gelu_approx(x: &ArrayD<f32>) -> ArrayD<f32> {
    let sqrt_2_pi = (2.0 / PI).sqrt();
    x.mapv(|v| {
        let inner = sqrt_2_pi * (v + 0.044715 * v.powi(3));
        0.5 * v * (1.0 + inner.tanh())
    })
}

pub fn gelu_backward(x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    // æ•°å€¤å¾®åˆ†ã¾ãŸã¯è‡ªå‹•å¾®åˆ†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®åˆ©ç”¨ã‚’æ¨å¥¨
    // ã“ã“ã§ã¯æ¦‚å¿µçš„ãªå®Ÿè£…
    let sqrt_2_pi = (2.0 / PI).sqrt();
    let mut grad_input = ArrayD::zeros(x.raw_dim());
    
    for (i, &x_val) in x.iter().enumerate() {
        let inner = sqrt_2_pi * (x_val + 0.044715 * x_val.powi(3));
        let tanh_val = inner.tanh();
        let sech2 = 1.0 - tanh_val.powi(2);
        
        let d_inner = sqrt_2_pi * (1.0 + 3.0 * 0.044715 * x_val.powi(2));
        let grad = 0.5 * (1.0 + tanh_val) + 0.5 * x_val * sech2 * d_inner;
        
        grad_input[[i]] = grad * grad_output[[i]];
    }
    
    grad_input
}
```

### 10.1.5 Swishï¼ˆSiLUï¼‰

Swish ã¯ Google ãŒææ¡ˆã—ãŸæ´»æ€§åŒ–é–¢æ•°ã§ã€ReLU ã‚ˆã‚Šã‚‚æ»‘ã‚‰ã‹ãªç‰¹æ€§ã‚’æŒã¡ã¾ã™ã€‚

**æ•°å¼å®šç¾©**ï¼š
$$
\text{Swish}(x) = x \cdot \sigma(\beta x)
$$

$\beta = 1$ ã®å ´åˆã¯ SiLUï¼ˆSigmoid Linear Unitï¼‰ã¨å‘¼ã°ã‚Œã¾ã™ã€‚

**å‹¾é…**ï¼š
$$
\frac{\partial \text{Swish}(x)}{\partial x} = \sigma(\beta x) + \beta x \cdot \sigma(\beta x) \cdot (1 - \sigma(\beta x))
$$

**Python å®Ÿè£…**ï¼š

```python
import torch

def swish(x, beta=1.0):
    return x * torch.sigmoid(beta * x)

def swish_backward(x, grad_output, beta=1.0):
    sigmoid_val = torch.sigmoid(beta * x)
    grad = sigmoid_val + beta * x * sigmoid_val * (1 - sigmoid_val)
    return grad_output * grad
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{Array, ArrayD, Zip};

pub struct Swish {
    beta: f32,
}

impl Swish {
    pub fn new(beta: f32) -> Self {
        Self { beta }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> ArrayD<f32> {
        x.mapv(|v| {
            let sigmoid = 1.0 / (1.0 + (-self.beta * v).exp());
            v * sigmoid
        })
    }

    pub fn backward(&self, x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
        let mut grad_input = Array::zeros(x.raw_dim());
        Zip::from(&mut grad_input)
            .and(x)
            .and(grad_output)
            .for_each(|grad_in, &x_val, &grad_out| {
                let sigmoid = 1.0 / (1.0 + (-self.beta * x_val).exp());
                let grad = sigmoid + self.beta * x_val * sigmoid * (1.0 - sigmoid);
                *grad_in = grad_out * grad;
            });
        grad_input
    }
}
```

### 10.1.6 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| æ´»æ€§åŒ–é–¢æ•° | è¨ˆç®—è¤‡é›‘åº¦ | ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ | ä¸»ãªç”¨é€” |
|-----------|----------|--------------|---------|
| **ReLU** | éå¸¸ã«ä½ã„ï¼ˆæ¯”è¼ƒã®ã¿ï¼‰ | 1 read, 1 write | CNN, æ±ç”¨ |
| **Leaky ReLU** | ä½ã„ï¼ˆä¹—ç®—1å›ï¼‰ | 1 read, 1 write | CNN, æ±ç”¨ |
| **Sigmoid** | ä¸­ï¼ˆexp 1å›ï¼‰ | 1 read, 1 write | å‡ºåŠ›å±¤ï¼ˆ2å€¤åˆ†é¡ï¼‰ |
| **Tanh** | ä¸­ï¼ˆexp 2å›ï¼‰ | 1 read, 1 write | RNN, æ­£è¦åŒ– |
| **GELU** | é«˜ï¼ˆtanh, ç´¯ä¹—ï¼‰ | 1 read, 1 write | Transformer |
| **Swish** | ä¸­ï¼ˆsigmoidï¼‰ | 1 read, 1 write | CNN, EfficientNet |

**GPU æœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ**ï¼š

1. **ã‚«ãƒ¼ãƒãƒ«èåˆ**: æ´»æ€§åŒ–é–¢æ•°ã¯é€šå¸¸ã€ç•³ã¿è¾¼ã¿ã‚„è¡Œåˆ—ç©ã®ç›´å¾Œã«é©ç”¨ã•ã‚Œã‚‹ãŸã‚ã€ã“ã‚Œã‚‰ã®æ¼”ç®—ã¨èåˆã™ã‚‹ã“ã¨ã§ã€ä¸­é–“çµæœã® GPU ãƒ¡ãƒ¢ãƒªã¸ã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿è¾¼ã¿ã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚
2. **ãƒ™ã‚¯ãƒˆãƒ«åŒ–**: CUDA ã§ã¯ `float4` ãªã©ã®ãƒ™ã‚¯ãƒˆãƒ«å‹ã‚’ä½¿ã„ã€è¤‡æ•°ã®è¦ç´ ã‚’ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªå¸¯åŸŸã‚’åŠ¹ç‡çš„ã«åˆ©ç”¨ã§ãã¾ã™ã€‚
3. **æ•°å€¤å®‰å®šæ€§**: Sigmoid ã‚„ Tanh ã§ã¯ã€å…¥åŠ›å€¤ã®ç¯„å›²ã«å¿œã˜ã¦è¨ˆç®—æ–¹æ³•ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã§ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼/ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ãã¾ã™ã€‚

---

## 10.2 æ­£è¦åŒ–å±¤ã®å®Ÿè£…ï¼ˆBatchNorm, LayerNormï¼‰

æ­£è¦åŒ–å±¤ã¯ã€æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’ã‚’å®‰å®šåŒ–ã•ã›ã€åæŸã‚’é«˜é€ŸåŒ–ã™ã‚‹é‡è¦ãªæŠ€è¡“ã§ã™ã€‚æœ¬ç¯€ã§ã¯ã€Batch Normalization ã¨ Layer Normalization ã®å®Ÿè£…ã¨ GPU æœ€é©åŒ–ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚

### 10.2.1 Batch Normalizationï¼ˆãƒãƒƒãƒæ­£è¦åŒ–ï¼‰

Batch Normalizationï¼ˆBatchNormï¼‰ã¯ã€ãƒŸãƒ‹ãƒãƒƒãƒå†…ã®çµ±è¨ˆé‡ã‚’ä½¿ã£ã¦ã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å…¥åŠ›ã‚’æ­£è¦åŒ–ã—ã¾ã™ã€‚

**æ•°å¼å®šç¾©ï¼ˆå­¦ç¿’æ™‚ï¼‰**ï¼š

1. ãƒŸãƒ‹ãƒãƒƒãƒã®å¹³å‡ã¨åˆ†æ•£ã‚’è¨ˆç®—ï¼š
$$
\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i
$$
$$
\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2
$$

2. æ­£è¦åŒ–ï¼š
$$
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
$$

3. ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚·ãƒ•ãƒˆï¼ˆå­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\gamma, \beta$ï¼‰ï¼š
$$
y_i = \gamma \hat{x}_i + \beta
$$

**æ•°å¼å®šç¾©ï¼ˆæ¨è«–æ™‚ï¼‰**ï¼š

æ¨è«–æ™‚ã¯ã€å­¦ç¿’ä¸­ã«è¨ˆç®—ã—ãŸç§»å‹•å¹³å‡ï¼ˆrunning mean, running varianceï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

**Pythonï¼ˆPyTorchï¼‰å®Ÿè£…**ï¼š

```python
import torch
import torch.nn as nn

# 2Dç•³ã¿è¾¼ã¿ç”¨ã®BatchNorm
bn = nn.BatchNorm2d(num_features=64, eps=1e-5, momentum=0.1)

x = torch.randn(32, 64, 28, 28)  # (batch, channels, height, width)
y = bn(x)

# æ‰‹å‹•å®Ÿè£…ï¼ˆå­¦ç¿’æ™‚ï¼‰
def batch_norm_2d_forward(x, gamma, beta, eps=1e-5):
    # x: (N, C, H, W)
    N, C, H, W = x.shape
    
    # ãƒãƒ£ãƒãƒ«ã”ã¨ã«çµ±è¨ˆé‡ã‚’è¨ˆç®—
    mean = x.mean(dim=(0, 2, 3), keepdim=True)  # (1, C, 1, 1)
    var = x.var(dim=(0, 2, 3), keepdim=True, unbiased=False)
    
    # æ­£è¦åŒ–
    x_normalized = (x - mean) / torch.sqrt(var + eps)
    
    # ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚·ãƒ•ãƒˆ
    y = gamma.view(1, C, 1, 1) * x_normalized + beta.view(1, C, 1, 1)
    
    return y, mean, var
```

**Rustï¼ˆndarrayï¼‰å®Ÿè£…**ï¼š

```rust
use ndarray::{Array, Array1, Array4, Axis, Zip, s};

pub struct BatchNorm2d {
    num_features: usize,
    gamma: Array1<f32>,  // ã‚¹ã‚±ãƒ¼ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    beta: Array1<f32>,   // ã‚·ãƒ•ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    running_mean: Array1<f32>,
    running_var: Array1<f32>,
    momentum: f32,
    eps: f32,
    training: bool,
}

impl BatchNorm2d {
    pub fn new(num_features: usize, eps: f32, momentum: f32) -> Self {
        Self {
            num_features,
            gamma: Array1::ones(num_features),
            beta: Array1::zeros(num_features),
            running_mean: Array1::zeros(num_features),
            running_var: Array1::ones(num_features),
            momentum,
            eps,
            training: true,
        }
    }

    pub fn forward(&mut self, x: &Array4<f32>) -> (Array4<f32>, Option<(Array1<f32>, Array1<f32>)>) {
        let (n, c, h, w) = x.dim();
        assert_eq!(c, self.num_features);

        if self.training {
            // å­¦ç¿’æ™‚: ãƒŸãƒ‹ãƒãƒƒãƒçµ±è¨ˆé‡ã‚’è¨ˆç®—
            let mut mean = Array1::zeros(c);
            let mut var = Array1::zeros(c);

            // ãƒãƒ£ãƒãƒ«ã”ã¨ã«å¹³å‡ã¨åˆ†æ•£ã‚’è¨ˆç®—
            for ch in 0..c {
                let channel_data = x.slice(s![.., ch, .., ..]);
                let m = channel_data.mean().unwrap();
                let v = channel_data.var(0.0);
                mean[ch] = m;
                var[ch] = v;
            }

            // ç§»å‹•å¹³å‡ã‚’æ›´æ–°
            self.running_mean = (1.0 - self.momentum) * &self.running_mean + self.momentum * &mean;
            self.running_var = (1.0 - self.momentum) * &self.running_var + self.momentum * &var;

            // æ­£è¦åŒ–ã¨ã‚¹ã‚±ãƒ¼ãƒ«ãƒ»ã‚·ãƒ•ãƒˆ
            let mut y = Array4::zeros(x.dim());
            for ch in 0..c {
                let x_ch = x.slice(s![.., ch, .., ..]);
                let normalized = (&x_ch - mean[ch]) / (var[ch] + self.eps).sqrt();
                let scaled = normalized * self.gamma[ch] + self.beta[ch];
                y.slice_mut(s![.., ch, .., ..]).assign(&scaled);
            }

            (y, Some((mean, var)))
        } else {
            // æ¨è«–æ™‚: ç§»å‹•å¹³å‡ã‚’ä½¿ç”¨
            let mut y = Array4::zeros(x.dim());
            for ch in 0..c {
                let x_ch = x.slice(s![.., ch, .., ..]);
                let normalized = (&x_ch - self.running_mean[ch]) 
                    / (self.running_var[ch] + self.eps).sqrt();
                let scaled = normalized * self.gamma[ch] + self.beta[ch];
                y.slice_mut(s![.., ch, .., ..]).assign(&scaled);
            }

            (y, None)
        }
    }

    pub fn backward(
        &self,
        x: &Array4<f32>,
        grad_output: &Array4<f32>,
        mean: &Array1<f32>,
        var: &Array1<f32>,
    ) -> (Array4<f32>, Array1<f32>, Array1<f32>) {
        let (n, c, h, w) = x.dim();
        let nhw = (n * h * w) as f32;

        let mut grad_input = Array4::zeros(x.dim());
        let mut grad_gamma = Array1::zeros(c);
        let mut grad_beta = Array1::zeros(c);

        for ch in 0..c {
            let x_ch = x.slice(s![.., ch, .., ..]);
            let grad_out_ch = grad_output.slice(s![.., ch, .., ..]);

            // x_normalized ã‚’å†è¨ˆç®—
            let x_normalized = (&x_ch - mean[ch]) / (var[ch] + self.eps).sqrt();

            // grad_gamma, grad_beta
            grad_gamma[ch] = (&grad_out_ch * &x_normalized).sum();
            grad_beta[ch] = grad_out_ch.sum();

            // grad_x_normalized
            let grad_x_norm = &grad_out_ch * self.gamma[ch];

            // grad_var
            let grad_var = (&grad_x_norm * (&x_ch - mean[ch])).sum()
                * -0.5 * (var[ch] + self.eps).powf(-1.5);

            // grad_mean
            let grad_mean = grad_x_norm.sum() * (-1.0 / (var[ch] + self.eps).sqrt())
                + grad_var * (-2.0 * (&x_ch - mean[ch]).sum() / nhw);

            // grad_input
            let grad_in_ch = &grad_x_norm / (var[ch] + self.eps).sqrt()
                + grad_var * 2.0 * (&x_ch - mean[ch]) / nhw
                + grad_mean / nhw;

            grad_input.slice_mut(s![.., ch, .., ..]).assign(&grad_in_ch);
        }

        (grad_input, grad_gamma, grad_beta)
    }
}
```

**GPU å®Ÿè£…ã®æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆ**ï¼š

1. **ä¸¦åˆ—ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³**: å¹³å‡ã¨åˆ†æ•£ã®è¨ˆç®—ã¯ã€GPU ã®ä¸¦åˆ—ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½¿ã†ã“ã¨ã§é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚
2. **ãƒ¯ãƒ¼ãƒ—å†…åŒæœŸ**: å°ã•ãªãƒãƒ£ãƒãƒ«æ•°ã®å ´åˆã€ãƒ¯ãƒ¼ãƒ—å†…ã®ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§å”èª¿ã—ã¦ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã“ã¨ã§ã€shared memory ã®åˆ©ç”¨ã‚’æœ€å°åŒ–ã§ãã¾ã™ã€‚
3. **ã‚«ãƒ¼ãƒãƒ«èåˆ**: BatchNorm ã¨å‰å¾Œã®æ¼”ç®—ï¼ˆç•³ã¿è¾¼ã¿ã€ReLU ãªã©ï¼‰ã‚’èåˆã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚

**cuDNN ã‚’ä½¿ã£ãŸå®Ÿè£…ï¼ˆtch-rsï¼‰**ï¼š

```rust
use tch::{nn, Tensor, Device};

// tch-rs (PyTorch ã® Rust ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°) ã‚’ä½¿ç”¨
let vs = nn::VarStore::new(Device::Cuda(0));
let bn = nn::batch_norm2d(&vs.root(), 64, Default::default());

let x = Tensor::randn(&[32, 64, 28, 28], (tch::Kind::Float, Device::Cuda(0)));
let y = bn.forward(&x);
```

### 10.2.2 Layer Normalizationï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–ï¼‰

Layer Normalization ã¯ã€Transformer ãªã©ã®ãƒ¢ãƒ‡ãƒ«ã§åºƒãä½¿ã‚ã‚Œã‚‹æ­£è¦åŒ–æ‰‹æ³•ã§ã€ãƒãƒƒãƒæ¬¡å…ƒã§ã¯ãªãç‰¹å¾´é‡æ¬¡å…ƒã§æ­£è¦åŒ–ã‚’è¡Œã„ã¾ã™ã€‚

**æ•°å¼å®šç¾©**ï¼š

1. å„ã‚µãƒ³ãƒ—ãƒ«ã®å¹³å‡ã¨åˆ†æ•£ã‚’è¨ˆç®—ï¼ˆç‰¹å¾´é‡æ¬¡å…ƒå…¨ä½“ï¼‰ï¼š
$$
\mu = \frac{1}{D} \sum_{i=1}^{D} x_i
$$
$$
\sigma^2 = \frac{1}{D} \sum_{i=1}^{D} (x_i - \mu)^2
$$

2. æ­£è¦åŒ–ï¼š
$$
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
$$

3. ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚·ãƒ•ãƒˆï¼š
$$
y_i = \gamma \hat{x}_i + \beta
$$

**Pythonï¼ˆPyTorchï¼‰å®Ÿè£…**ï¼š

```python
import torch
import torch.nn as nn

ln = nn.LayerNorm(normalized_shape=512, eps=1e-5)

x = torch.randn(32, 128, 512)  # (batch, seq_len, features)
y = ln(x)

# æ‰‹å‹•å®Ÿè£…
def layer_norm_forward(x, gamma, beta, eps=1e-5):
    # x: (N, ..., D)
    mean = x.mean(dim=-1, keepdim=True)
    var = x.var(dim=-1, keepdim=True, unbiased=False)
    
    x_normalized = (x - mean) / torch.sqrt(var + eps)
    y = gamma * x_normalized + beta
    
    return y, mean, var
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{Array, ArrayD, Array1, Axis};

pub struct LayerNorm {
    normalized_shape: Vec<usize>,
    gamma: Array1<f32>,
    beta: Array1<f32>,
    eps: f32,
}

impl LayerNorm {
    pub fn new(normalized_shape: Vec<usize>, eps: f32) -> Self {
        let size = normalized_shape.iter().product();
        Self {
            normalized_shape,
            gamma: Array1::ones(size),
            beta: Array1::zeros(size),
            eps,
        }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> (ArrayD<f32>, ArrayD<f32>, ArrayD<f32>) {
        // æœ€å¾Œã®æ¬¡å…ƒã§æ­£è¦åŒ–
        let last_axis = x.ndim() - 1;
        
        // å¹³å‡ã¨åˆ†æ•£ã‚’è¨ˆç®—
        let mean = x.mean_axis(Axis(last_axis)).unwrap();
        let var = x.var_axis(Axis(last_axis), 0.0);
        
        // æ­£è¦åŒ–
        let mean_broadcast = mean.insert_axis(Axis(last_axis));
        let var_broadcast = var.insert_axis(Axis(last_axis));
        
        let x_normalized = (x - &mean_broadcast) / (var_broadcast + self.eps).mapv(|v| v.sqrt());
        
        // ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã‚·ãƒ•ãƒˆ
        let y = &x_normalized * &self.gamma.view() + &self.beta.view();
        
        (y, mean, var)
    }

    pub fn backward(
        &self,
        x: &ArrayD<f32>,
        grad_output: &ArrayD<f32>,
        mean: &ArrayD<f32>,
        var: &ArrayD<f32>,
    ) -> (ArrayD<f32>, Array1<f32>, Array1<f32>) {
        // å®Ÿè£…ã¯ BatchNorm ã¨é¡ä¼¼
        // è©³ç´°ã¯çœç•¥
        todo!("LayerNorm backward implementation")
    }
}
```

### 10.2.3 Group Normalization ã¨ Instance Normalization

**Group Normalization**ï¼šãƒãƒ£ãƒãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã€ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«æ­£è¦åŒ–ã—ã¾ã™ã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå°ã•ã„å ´åˆã«æœ‰åŠ¹ã§ã™ã€‚

**Instance Normalization**ï¼šå„ã‚µãƒ³ãƒ—ãƒ«ãƒ»å„ãƒãƒ£ãƒãƒ«ã”ã¨ã«æ­£è¦åŒ–ã—ã¾ã™ã€‚ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€ãªã©ã§ä½¿ã‚ã‚Œã¾ã™ã€‚

ã“ã‚Œã‚‰ã®å®Ÿè£…ã¯ BatchNorm ã‚„ LayerNorm ã®å¤‰ç¨®ã¨ã—ã¦å®Ÿè£…ã§ãã¾ã™ã€‚

---

## 10.3 ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã®å®Ÿè£…ï¼ˆMaxPool, AvgPoolï¼‰

ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã¯ã€ç‰¹å¾´ãƒãƒƒãƒ—ã®ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’è¡Œã„ã€è¨ˆç®—é‡å‰Šæ¸›ã¨ä¸å¤‰æ€§ã®ç²å¾—ã‚’ç›®çš„ã¨ã—ã¾ã™ã€‚

### 10.3.1 Max Poolingï¼ˆæœ€å¤§å€¤ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼‰

Max Pooling ã¯ã€å„ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®æœ€å¤§å€¤ã‚’å–ã‚‹æ¼”ç®—ã§ã™ã€‚

**æ•°å¼å®šç¾©**ï¼š
$$
y_{n,c,h,w} = \max_{0 \leq i < k_h, 0 \leq j < k_w} x_{n,c,h \cdot s + i, w \cdot s + j}
$$

ã“ã“ã§ã€$k_h, k_w$ ã¯ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã€$s$ ã¯ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã§ã™ã€‚

**Pythonï¼ˆPyTorchï¼‰å®Ÿè£…**ï¼š

```python
import torch
import torch.nn as nn

maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

x = torch.randn(32, 64, 28, 28)
y = maxpool(x)  # (32, 64, 14, 14)

# æ‰‹å‹•å®Ÿè£…
def max_pool2d_forward(x, kernel_size, stride):
    N, C, H, W = x.shape
    kh, kw = kernel_size
    sh, sw = stride
    
    out_h = (H - kh) // sh + 1
    out_w = (W - kw) // sw + 1
    
    y = torch.zeros(N, C, out_h, out_w)
    
    for n in range(N):
        for c in range(C):
            for h in range(out_h):
                for w in range(out_w):
                    h_start = h * sh
                    w_start = w * sw
                    window = x[n, c, h_start:h_start+kh, w_start:w_start+kw]
                    y[n, c, h, w] = window.max()
    
    return y
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{Array4, s};

pub fn max_pool2d(
    x: &Array4<f32>,
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> (Array4<f32>, Array4<usize>) {
    let (n, c, h, w) = x.dim();
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let out_h = (h - kh) / sh + 1;
    let out_w = (w - kw) / sw + 1;
    
    let mut y = Array4::zeros((n, c, out_h, out_w));
    let mut indices = Array4::zeros((n, c, out_h, out_w));
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..out_h {
                for wi in 0..out_w {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    
                    let window = x.slice(s![
                        ni..ni+1,
                        ci..ci+1,
                        h_start..h_start+kh,
                        w_start..w_start+kw
                    ]);
                    
                    let (max_val, max_idx) = window
                        .iter()
                        .enumerate()
                        .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
                        .unwrap();
                    
                    y[[ni, ci, hi, wi]] = *max_val;
                    indices[[ni, ci, hi, wi]] = max_idx;
                }
            }
        }
    }
    
    (y, indices)
}

pub fn max_pool2d_backward(
    grad_output: &Array4<f32>,
    indices: &Array4<usize>,
    input_shape: (usize, usize, usize, usize),
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> Array4<f32> {
    let (n, c, h, w) = input_shape;
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let mut grad_input = Array4::zeros((n, c, h, w));
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..grad_output.dim().2 {
                for wi in 0..grad_output.dim().3 {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    
                    let idx = indices[[ni, ci, hi, wi]];
                    let h_offset = idx / kw;
                    let w_offset = idx % kw;
                    
                    grad_input[[ni, ci, h_start + h_offset, w_start + w_offset]] 
                        += grad_output[[ni, ci, hi, wi]];
                }
            }
        }
    }
    
    grad_input
}
```

**GPU ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…ï¼ˆCUDAï¼‰**ï¼š

```cuda
__global__ void max_pool2d_forward_kernel(
    const float* x,
    float* y,
    int* indices,
    int N, int C, int H, int W,
    int out_h, int out_w,
    int kh, int kw,
    int sh, int sw
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total = N * C * out_h * out_w;
    
    if (idx < total) {
        int wi = idx % out_w;
        int hi = (idx / out_w) % out_h;
        int ci = (idx / (out_w * out_h)) % C;
        int ni = idx / (out_w * out_h * C);
        
        int h_start = hi * sh;
        int w_start = wi * sw;
        
        float max_val = -INFINITY;
        int max_idx = 0;
        
        for (int i = 0; i < kh; i++) {
            for (int j = 0; j < kw; j++) {
                int h_pos = h_start + i;
                int w_pos = w_start + j;
                int x_idx = ((ni * C + ci) * H + h_pos) * W + w_pos;
                
                if (x[x_idx] > max_val) {
                    max_val = x[x_idx];
                    max_idx = i * kw + j;
                }
            }
        }
        
        y[idx] = max_val;
        indices[idx] = max_idx;
    }
}
```

### 10.3.2 Average Poolingï¼ˆå¹³å‡å€¤ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼‰

Average Pooling ã¯ã€å„ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®å¹³å‡å€¤ã‚’å–ã‚‹æ¼”ç®—ã§ã™ã€‚

**æ•°å¼å®šç¾©**ï¼š
$$
y_{n,c,h,w} = \frac{1}{k_h \cdot k_w} \sum_{i=0}^{k_h-1} \sum_{j=0}^{k_w-1} x_{n,c,h \cdot s + i, w \cdot s + j}
$$

**Python å®Ÿè£…**ï¼š

```python
import torch.nn as nn

avgpool = nn.AvgPool2d(kernel_size=2, stride=2)
x = torch.randn(32, 64, 28, 28)
y = avgpool(x)  # (32, 64, 14, 14)
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{Array4, s};

pub fn avg_pool2d(
    x: &Array4<f32>,
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> Array4<f32> {
    let (n, c, h, w) = x.dim();
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let out_h = (h - kh) / sh + 1;
    let out_w = (w - kw) / sw + 1;
    
    let mut y = Array4::zeros((n, c, out_h, out_w));
    let scale = 1.0 / (kh * kw) as f32;
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..out_h {
                for wi in 0..out_w {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    
                    let window = x.slice(s![
                        ni..ni+1,
                        ci..ci+1,
                        h_start..h_start+kh,
                        w_start..w_start+kw
                    ]);
                    
                    y[[ni, ci, hi, wi]] = window.sum() * scale;
                }
            }
        }
    }
    
    y
}

pub fn avg_pool2d_backward(
    grad_output: &Array4<f32>,
    input_shape: (usize, usize, usize, usize),
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> Array4<f32> {
    let (n, c, h, w) = input_shape;
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let mut grad_input = Array4::zeros((n, c, h, w));
    let scale = 1.0 / (kh * kw) as f32;
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..grad_output.dim().2 {
                for wi in 0..grad_output.dim().3 {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    let grad = grad_output[[ni, ci, hi, wi]] * scale;
                    
                    for i in 0..kh {
                        for j in 0..kw {
                            grad_input[[ni, ci, h_start + i, w_start + j]] += grad;
                        }
                    }
                }
            }
        }
    }
    
    grad_input
}
```

### 10.3.3 Adaptive Pooling

Adaptive Pooling ã¯ã€å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã¨ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã‚’èª¿æ•´ã—ã¦ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚

```python
import torch.nn as nn

# å‡ºåŠ›ã‚’1x1ã«ã™ã‚‹ï¼ˆGlobal Average Poolingï¼‰
adaptive_avgpool = nn.AdaptiveAvgPool2d((1, 1))
x = torch.randn(32, 512, 7, 7)
y = adaptive_avgpool(x)  # (32, 512, 1, 1)
```

---

## 10.4 ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã¨æ­£å‰‡åŒ–

ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã¯ã€å­¦ç¿’æ™‚ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ã“ã¨ã§ã€éå­¦ç¿’ã‚’é˜²ãæ­£å‰‡åŒ–æ‰‹æ³•ã§ã™ã€‚

### 10.4.1 ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®åŸºæœ¬å®Ÿè£…

**æ•°å¼å®šç¾©ï¼ˆå­¦ç¿’æ™‚ï¼‰**ï¼š
$$
y_i = \begin{cases}
\frac{x_i}{1 - p} & \text{with probability } 1 - p \\
0 & \text{with probability } p
\end{cases}
$$

**æ•°å¼å®šç¾©ï¼ˆæ¨è«–æ™‚ï¼‰**ï¼š
$$
y_i = x_i
$$

**Python å®Ÿè£…**ï¼š

```python
import torch
import torch.nn as nn

dropout = nn.Dropout(p=0.5)

# å­¦ç¿’æ™‚
x = torch.randn(32, 512)
y = dropout(x)

# æ¨è«–æ™‚
dropout.eval()
y = dropout(x)  # x ã¨åŒã˜

# æ‰‹å‹•å®Ÿè£…
def dropout_forward(x, p, training=True):
    if not training:
        return x
    
    mask = (torch.rand_like(x) > p).float()
    return x * mask / (1 - p)

def dropout_backward(grad_output, mask, p):
    return grad_output * mask / (1 - p)
```

**Rust å®Ÿè£…**ï¼š

```rust
use ndarray::{ArrayD, Array};
use rand::Rng;
use rand::distributions::{Distribution, Uniform};

pub struct Dropout {
    p: f32,
    training: bool,
}

impl Dropout {
    pub fn new(p: f32) -> Self {
        assert!(p >= 0.0 && p < 1.0, "Dropout probability must be in [0, 1)");
        Self { p, training: true }
    }

    pub fn train(&mut self) {
        self.training = true;
    }

    pub fn eval(&mut self) {
        self.training = false;
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> (ArrayD<f32>, ArrayD<f32>) {
        if !self.training {
            return (x.clone(), Array::ones(x.raw_dim()));
        }

        let mut rng = rand::thread_rng();
        let dist = Uniform::new(0.0, 1.0);
        
        let mask = x.mapv(|_| {
            if dist.sample(&mut rng) > self.p {
                1.0 / (1.0 - self.p)
            } else {
                0.0
            }
        });

        let y = x * &mask;
        (y, mask)
    }

    pub fn backward(&self, grad_output: &ArrayD<f32>, mask: &ArrayD<f32>) -> ArrayD<f32> {
        if !self.training {
            return grad_output.clone();
        }

        grad_output * mask
    }
}
```

**GPU ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…ï¼ˆCUDAï¼‰**ï¼š

```cuda
#include <curand_kernel.h>

__global__ void dropout_forward_kernel(
    const float* x,
    float* y,
    unsigned char* mask,
    float p,
    int n,
    unsigned long long seed
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        curandState state;
        curand_init(seed, idx, 0, &state);
        
        float rand_val = curand_uniform(&state);
        float scale = 1.0f / (1.0f - p);
        
        if (rand_val > p) {
            y[idx] = x[idx] * scale;
            mask[idx] = 1;
        } else {
            y[idx] = 0.0f;
            mask[idx] = 0;
        }
    }
}

__global__ void dropout_backward_kernel(
    const float* grad_output,
    const unsigned char* mask,
    float* grad_input,
    float p,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        float scale = 1.0f / (1.0f - p);
        grad_input[idx] = grad_output[idx] * mask[idx] * scale;
    }
}
```

### 10.4.2 DropConnect ã¨ DropBlock

**DropConnect**: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãŒãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ã®ã«å¯¾ã—ã€DropConnect ã¯é‡ã¿æ¥ç¶šã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ç„¡åŠ¹åŒ–ã—ã¾ã™ã€‚

**DropBlock**: ç”»åƒèªè­˜ã«ãŠã„ã¦ã€ç©ºé–“çš„ã«é€£ç¶šã—ãŸãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªæ­£å‰‡åŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

```python
import torch
import torch.nn as nn

# DropBlock (torchvision.ops ã«ã‚ã‚‹)
from torchvision.ops import DropBlock2d

dropblock = DropBlock2d(p=0.1, block_size=7)
x = torch.randn(32, 64, 56, 56)
y = dropblock(x)
```

### 10.4.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| æ­£å‰‡åŒ–æ‰‹æ³• | è¨ˆç®—ã‚³ã‚¹ãƒˆ | ãƒ¡ãƒ¢ãƒªã‚³ã‚¹ãƒˆ | ä¸»ãªç”¨é€” |
|-----------|----------|------------|---------|
| **Dropout** | ä½ï¼ˆä¹±æ•°ç”Ÿæˆã®ã¿ï¼‰ | ãƒã‚¹ã‚¯ä¿å­˜ | å…¨çµåˆå±¤ |
| **DropConnect** | ä¸­ï¼ˆé‡ã¿å˜ä½ï¼‰ | ãƒã‚¹ã‚¯ä¿å­˜ | å…¨çµåˆå±¤ |
| **DropBlock** | ä¸­ï¼ˆãƒ–ãƒ­ãƒƒã‚¯å˜ä½ï¼‰ | ãƒã‚¹ã‚¯ä¿å­˜ | CNN |
| **BatchNorm** | é«˜ï¼ˆçµ±è¨ˆé‡è¨ˆç®—ï¼‰ | å¹³å‡ãƒ»åˆ†æ•£ä¿å­˜ | CNN, MLP |
| **LayerNorm** | é«˜ï¼ˆçµ±è¨ˆé‡è¨ˆç®—ï¼‰ | å¹³å‡ãƒ»åˆ†æ•£ä¿å­˜ | Transformer |

---

## 10.5 ã¾ã¨ã‚

æœ¬ç« ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åŸºæœ¬çš„ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆæ´»æ€§åŒ–é–¢æ•°ã€æ­£è¦åŒ–å±¤ã€ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼‰ã‚’ã€Python ã¨ Rust ã®ä¸¡æ–¹ã§å®Ÿè£…ã—ã¾ã—ãŸã€‚

**ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ**ï¼š

1. **æ´»æ€§åŒ–é–¢æ•°**: ReLUã€Sigmoidã€Tanhã€GELUã€Swish ãªã©ã®å®Ÿè£…ã¨ã€æ•°å€¤å®‰å®šæ€§ã®è€ƒæ…®
2. **æ­£è¦åŒ–å±¤**: BatchNorm ã¨ LayerNorm ã®å®Ÿè£…ã€å­¦ç¿’æ™‚ã¨æ¨è«–æ™‚ã®é•ã„
3. **ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤**: MaxPool ã¨ AvgPool ã®å®Ÿè£…ã€å‹¾é…è¨ˆç®—ã«ãŠã‘ã‚‹æ³¨æ„ç‚¹
4. **ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ**: å­¦ç¿’æ™‚ã®ãƒ©ãƒ³ãƒ€ãƒ ç„¡åŠ¹åŒ–ã¨æ¨è«–æ™‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**Rust ã§ã®å®Ÿè£…ã®åˆ©ç‚¹**ï¼š

- **å‹å®‰å…¨æ€§**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«æ¬¡å…ƒã®ä¸ä¸€è‡´ãªã©ã®ãƒã‚°ã‚’æ¤œå‡º
- **ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§**: æ‰€æœ‰æ¨©ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®é˜²æ­¢
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–ã«ã‚ˆã‚‹é«˜é€Ÿãªå®Ÿè¡Œ

**æ¬¡ç« ã¸ã®æ¥ç¶š**ï¼š

æ¬¡ã®ç¬¬ 11 ç« ã§ã¯ã€æå¤±é–¢æ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®Ÿè£…ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã€å­¦ç¿’ã®ç›®çš„é–¢æ•°ã¨ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

---

## å‚è€ƒæ–‡çŒ®

- Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ICML.
- Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016). Layer Normalization. arXiv:1607.06450.
- Hendrycks, D., & Gimpel, K. (2016). Gaussian Error Linear Units (GELUs). arXiv:1606.08415.
- Ramachandran, P., Zoph, B., & Le, Q. V. (2017). Searching for Activation Functions. arXiv:1710.05941.
- Srivastava, N., et al. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. JMLR.
---

[ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹](../README.md) | [â¬…ï¸ ç¬¬9ç« : ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ](04-09-ãƒ†ãƒ³ã‚½ãƒ«ãƒ»ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­è¨ˆ.md) | [â¡ï¸ ç¬¬11ç« : æå¤±é–¢æ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®Ÿè£…](04-11-æå¤±é–¢æ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®Ÿè£….md)