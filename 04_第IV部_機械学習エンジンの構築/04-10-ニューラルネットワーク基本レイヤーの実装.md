# 第 10 章：ニューラルネットワーク基本レイヤーの実装

本章では、ニューラルネットワークを構成する基本的なレイヤー（活性化関数、正規化層、プーリング層、ドロップアウト）を Rust で実装します。これらのレイヤーは、どのような深層学習モデルにも共通して使われる基礎的な構成要素であり、GPU 上で効率的に実装することが学習・推論性能に直結します。

Python（PyTorch/NumPy）との比較を通じて、Rust での型安全な実装と GPU 最適化の手法を学びます。

---

## 10.1 活性化関数の実装と GPU 最適化

活性化関数は、ニューラルネットワークに非線形性を導入する重要な要素です。本節では、代表的な活性化関数（ReLU、Sigmoid、Tanh、GELU、Swish）を実装し、その勾配計算と GPU 最適化について詳しく解説します。

### 10.1.1 ReLU（Rectified Linear Unit）

ReLU は最も広く使われる活性化関数で、計算コストが低く、勾配消失問題を緩和します。

**数式定義**：
$$
\text{ReLU}(x) = \max(0, x)
$$

**勾配**：
$$
\frac{\partial \text{ReLU}(x)}{\partial x} = \begin{cases}
1 & \text{if } x > 0 \\
0 & \text{otherwise}
\end{cases}
$$

**Python（NumPy）実装**：

```python
import numpy as np

def relu_forward(x):
    """ReLU forward pass"""
    return np.maximum(0, x)

def relu_backward(x, grad_output):
    """ReLU backward pass"""
    grad_input = grad_output * (x > 0)
    return grad_input

# 使用例
x = np.array([[-1.0, 2.0], [3.0, -4.0]])
y = relu_forward(x)  # [[0., 2.], [3., 0.]]

grad_output = np.ones_like(y)
grad_input = relu_backward(x, grad_output)  # [[0., 1.], [1., 0.]]
```

**Rust（ndarray）実装**：

```rust
use ndarray::{Array, ArrayD, Zip};

pub fn relu_forward(x: &ArrayD<f32>) -> ArrayD<f32> {
    x.mapv(|v| v.max(0.0))
}

pub fn relu_backward(x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    let mut grad_input = Array::zeros(x.raw_dim());
    Zip::from(&mut grad_input)
        .and(x)
        .and(grad_output)
        .for_each(|grad_in, &x_val, &grad_out| {
            *grad_in = if x_val > 0.0 { grad_out } else { 0.0 };
        });
    grad_input
}
```

**GPU カーネル実装（CUDA）**：

ReLU は要素ごとの演算（element-wise operation）なので、GPU で並列化しやすい演算です。

```cuda
// ReLU forward kernel
__global__ void relu_forward_kernel(const float* x, float* y, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        y[idx] = fmaxf(0.0f, x[idx]);
    }
}

// ReLU backward kernel
__global__ void relu_backward_kernel(
    const float* x,
    const float* grad_output,
    float* grad_input,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        grad_input[idx] = (x[idx] > 0.0f) ? grad_output[idx] : 0.0f;
    }
}
```

**Rust から CUDA カーネルを呼び出す（cudarc 使用）**：

```rust
use cudarc::driver::*;
use std::sync::Arc;

pub struct ReLULayer {
    device: Arc<CudaDevice>,
}

impl ReLULayer {
    pub fn new(device: Arc<CudaDevice>) -> Result<Self, CudaError> {
        Ok(Self { device })
    }

    pub fn forward(&self, x: &CudaSlice<f32>) -> Result<CudaSlice<f32>, CudaError> {
        let n = x.len();
        let mut y = self.device.alloc_zeros::<f32>(n)?;

        // カーネル起動パラメータ
        let threads = 256;
        let blocks = (n + threads - 1) / threads;

        // PTXまたはCUDAソースからカーネルをロード（事前コンパイル済みと仮定）
        let kernel = self.device.get_func("relu_module", "relu_forward_kernel")?;
        
        unsafe {
            kernel.launch(
                LaunchConfig {
                    grid_dim: (blocks as u32, 1, 1),
                    block_dim: (threads as u32, 1, 1),
                    shared_mem_bytes: 0,
                },
                (&x, &mut y, n as i32),
            )?;
        }

        Ok(y)
    }

    pub fn backward(
        &self,
        x: &CudaSlice<f32>,
        grad_output: &CudaSlice<f32>,
    ) -> Result<CudaSlice<f32>, CudaError> {
        let n = x.len();
        let mut grad_input = self.device.alloc_zeros::<f32>(n)?;

        let threads = 256;
        let blocks = (n + threads - 1) / threads;

        let kernel = self.device.get_func("relu_module", "relu_backward_kernel")?;
        
        unsafe {
            kernel.launch(
                LaunchConfig {
                    grid_dim: (blocks as u32, 1, 1),
                    block_dim: (threads as u32, 1, 1),
                    shared_mem_bytes: 0,
                },
                (&x, &grad_output, &mut grad_input, n as i32),
            )?;
        }

        Ok(grad_input)
    }
}
```

### 10.1.2 Leaky ReLU と PReLU

ReLU の変種として、負の値に対しても小さな勾配を持たせる Leaky ReLU と、負の傾きを学習可能なパラメータとする PReLU があります。

**Leaky ReLU**：
$$
\text{LeakyReLU}(x) = \begin{cases}
x & \text{if } x > 0 \\
\alpha x & \text{otherwise}
\end{cases}
$$

通常、$\alpha = 0.01$ が使われます。

**PReLU（Parametric ReLU）**：
$$
\text{PReLU}(x) = \begin{cases}
x & \text{if } x > 0 \\
\alpha x & \text{otherwise}
\end{cases}
$$

$\alpha$ は学習可能なパラメータです。

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

# Leaky ReLU
class LeakyReLU(nn.Module):
    def __init__(self, alpha=0.01):
        super().__init__()
        self.alpha = alpha
    
    def forward(self, x):
        return torch.where(x > 0, x, self.alpha * x)

# PReLU
prelu = nn.PReLU(num_parameters=1, init=0.25)
x = torch.randn(2, 3)
y = prelu(x)
```

**Rust 実装**：

```rust
use ndarray::{Array, ArrayD, Zip};

pub struct LeakyReLU {
    alpha: f32,
}

impl LeakyReLU {
    pub fn new(alpha: f32) -> Self {
        Self { alpha }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> ArrayD<f32> {
        x.mapv(|v| if v > 0.0 { v } else { self.alpha * v })
    }

    pub fn backward(&self, x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
        let mut grad_input = Array::zeros(x.raw_dim());
        Zip::from(&mut grad_input)
            .and(x)
            .and(grad_output)
            .for_each(|grad_in, &x_val, &grad_out| {
                *grad_in = if x_val > 0.0 { grad_out } else { self.alpha * grad_out };
            });
        grad_input
    }
}

pub struct PReLU {
    alpha: ArrayD<f32>,  // 学習可能なパラメータ
}

impl PReLU {
    pub fn new(num_parameters: usize, init: f32) -> Self {
        let alpha = Array::from_elem(vec![num_parameters], init);
        Self { alpha }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> ArrayD<f32> {
        // チャネルごとに異なるalphaを適用する実装が必要
        // ここでは簡略化のため単一のalphaを仮定
        let alpha_val = self.alpha[[0]];
        x.mapv(|v| if v > 0.0 { v } else { alpha_val * v })
    }

    pub fn backward(
        &self,
        x: &ArrayD<f32>,
        grad_output: &ArrayD<f32>,
    ) -> (ArrayD<f32>, ArrayD<f32>) {
        // grad_input と grad_alpha を計算
        let alpha_val = self.alpha[[0]];
        let mut grad_input = Array::zeros(x.raw_dim());
        let mut grad_alpha_sum = 0.0f32;

        Zip::from(&mut grad_input)
            .and(x)
            .and(grad_output)
            .for_each(|grad_in, &x_val, &grad_out| {
                if x_val > 0.0 {
                    *grad_in = grad_out;
                } else {
                    *grad_in = alpha_val * grad_out;
                    grad_alpha_sum += x_val * grad_out;
                }
            });

        let mut grad_alpha = Array::zeros(self.alpha.raw_dim());
        grad_alpha[[0]] = grad_alpha_sum;

        (grad_input, grad_alpha)
    }
}
```

### 10.1.3 Sigmoid と Tanh

Sigmoid と Tanh は古典的な活性化関数で、出力範囲が制限されています。

**Sigmoid**：
$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$

**勾配**：
$$
\frac{\partial \sigma(x)}{\partial x} = \sigma(x) \cdot (1 - \sigma(x))
$$

**Tanh**：
$$
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
$$

**勾配**：
$$
\frac{\partial \tanh(x)}{\partial x} = 1 - \tanh^2(x)
$$

**Python 実装**：

```python
import numpy as np

def sigmoid_forward(x):
    return 1.0 / (1.0 + np.exp(-x))

def sigmoid_backward(y, grad_output):
    # y は forward の出力を再利用（計算効率化）
    grad_input = grad_output * y * (1.0 - y)
    return grad_input

def tanh_forward(x):
    return np.tanh(x)

def tanh_backward(y, grad_output):
    # y は forward の出力を再利用
    grad_input = grad_output * (1.0 - y ** 2)
    return grad_input
```

**Rust 実装**：

```rust
use ndarray::{Array, ArrayD, Zip};

pub fn sigmoid_forward(x: &ArrayD<f32>) -> ArrayD<f32> {
    x.mapv(|v| 1.0 / (1.0 + (-v).exp()))
}

pub fn sigmoid_backward(y: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    // y は forward の出力
    let mut grad_input = Array::zeros(y.raw_dim());
    Zip::from(&mut grad_input)
        .and(y)
        .and(grad_output)
        .for_each(|grad_in, &y_val, &grad_out| {
            *grad_in = grad_out * y_val * (1.0 - y_val);
        });
    grad_input
}

pub fn tanh_forward(x: &ArrayD<f32>) -> ArrayD<f32> {
    x.mapv(|v| v.tanh())
}

pub fn tanh_backward(y: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    let mut grad_input = Array::zeros(y.raw_dim());
    Zip::from(&mut grad_input)
        .and(y)
        .and(grad_output)
        .for_each(|grad_in, &y_val, &grad_out| {
            *grad_in = grad_out * (1.0 - y_val * y_val);
        });
    grad_input
}
```

**数値安定性の注意**：

Sigmoid では、$x$ が非常に大きい（または小さい）場合、`exp(-x)` がオーバーフロー（またはアンダーフロー）する可能性があります。安定版の実装：

```rust
pub fn sigmoid_stable(x: f32) -> f32 {
    if x >= 0.0 {
        1.0 / (1.0 + (-x).exp())
    } else {
        let exp_x = x.exp();
        exp_x / (1.0 + exp_x)
    }
}
```

### 10.1.4 GELU（Gaussian Error Linear Unit）

GELU は、Transformer などの最新モデルで広く使われる活性化関数です。

**数式定義**：
$$
\text{GELU}(x) = x \cdot \Phi(x)
$$

ここで、$\Phi(x)$ は標準正規分布の累積分布関数（CDF）です。

**近似版**（計算効率化）：
$$
\text{GELU}(x) \approx 0.5 x \left(1 + \tanh\left(\sqrt{\frac{2}{\pi}} \left(x + 0.044715 x^3\right)\right)\right)
$$

**勾配**（近似版）：

複雑な導出は省略しますが、自動微分を使うのが実用的です。

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

gelu = nn.GELU()
x = torch.randn(2, 3)
y = gelu(x)

# 近似版の手動実装
def gelu_approx(x):
    return 0.5 * x * (1.0 + torch.tanh(
        torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * x ** 3)
    ))
```

**Rust 実装**：

```rust
use ndarray::ArrayD;
use std::f32::consts::PI;

pub fn gelu_approx(x: &ArrayD<f32>) -> ArrayD<f32> {
    let sqrt_2_pi = (2.0 / PI).sqrt();
    x.mapv(|v| {
        let inner = sqrt_2_pi * (v + 0.044715 * v.powi(3));
        0.5 * v * (1.0 + inner.tanh())
    })
}

pub fn gelu_backward(x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
    // 数値微分または自動微分フレームワークの利用を推奨
    // ここでは概念的な実装
    let sqrt_2_pi = (2.0 / PI).sqrt();
    let mut grad_input = ArrayD::zeros(x.raw_dim());
    
    for (i, &x_val) in x.iter().enumerate() {
        let inner = sqrt_2_pi * (x_val + 0.044715 * x_val.powi(3));
        let tanh_val = inner.tanh();
        let sech2 = 1.0 - tanh_val.powi(2);
        
        let d_inner = sqrt_2_pi * (1.0 + 3.0 * 0.044715 * x_val.powi(2));
        let grad = 0.5 * (1.0 + tanh_val) + 0.5 * x_val * sech2 * d_inner;
        
        grad_input[[i]] = grad * grad_output[[i]];
    }
    
    grad_input
}
```

### 10.1.5 Swish（SiLU）

Swish は Google が提案した活性化関数で、ReLU よりも滑らかな特性を持ちます。

**数式定義**：
$$
\text{Swish}(x) = x \cdot \sigma(\beta x)
$$

$\beta = 1$ の場合は SiLU（Sigmoid Linear Unit）と呼ばれます。

**勾配**：
$$
\frac{\partial \text{Swish}(x)}{\partial x} = \sigma(\beta x) + \beta x \cdot \sigma(\beta x) \cdot (1 - \sigma(\beta x))
$$

**Python 実装**：

```python
import torch

def swish(x, beta=1.0):
    return x * torch.sigmoid(beta * x)

def swish_backward(x, grad_output, beta=1.0):
    sigmoid_val = torch.sigmoid(beta * x)
    grad = sigmoid_val + beta * x * sigmoid_val * (1 - sigmoid_val)
    return grad_output * grad
```

**Rust 実装**：

```rust
use ndarray::{Array, ArrayD, Zip};

pub struct Swish {
    beta: f32,
}

impl Swish {
    pub fn new(beta: f32) -> Self {
        Self { beta }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> ArrayD<f32> {
        x.mapv(|v| {
            let sigmoid = 1.0 / (1.0 + (-self.beta * v).exp());
            v * sigmoid
        })
    }

    pub fn backward(&self, x: &ArrayD<f32>, grad_output: &ArrayD<f32>) -> ArrayD<f32> {
        let mut grad_input = Array::zeros(x.raw_dim());
        Zip::from(&mut grad_input)
            .and(x)
            .and(grad_output)
            .for_each(|grad_in, &x_val, &grad_out| {
                let sigmoid = 1.0 / (1.0 + (-self.beta * x_val).exp());
                let grad = sigmoid + self.beta * x_val * sigmoid * (1.0 - sigmoid);
                *grad_in = grad_out * grad;
            });
        grad_input
    }
}
```

### 10.1.6 パフォーマンス比較

| 活性化関数 | 計算複雑度 | メモリアクセス | 主な用途 |
|-----------|----------|--------------|---------|
| **ReLU** | 非常に低い（比較のみ） | 1 read, 1 write | CNN, 汎用 |
| **Leaky ReLU** | 低い（乗算1回） | 1 read, 1 write | CNN, 汎用 |
| **Sigmoid** | 中（exp 1回） | 1 read, 1 write | 出力層（2値分類） |
| **Tanh** | 中（exp 2回） | 1 read, 1 write | RNN, 正規化 |
| **GELU** | 高（tanh, 累乗） | 1 read, 1 write | Transformer |
| **Swish** | 中（sigmoid） | 1 read, 1 write | CNN, EfficientNet |

**GPU 最適化のポイント**：

1. **カーネル融合**: 活性化関数は通常、畳み込みや行列積の直後に適用されるため、これらの演算と融合することで、中間結果の GPU メモリへの書き込み・読み込みを削減できます。
2. **ベクトル化**: CUDA では `float4` などのベクトル型を使い、複数の要素を一度に処理することで、メモリ帯域を効率的に利用できます。
3. **数値安定性**: Sigmoid や Tanh では、入力値の範囲に応じて計算方法を切り替えることで、オーバーフロー/アンダーフローを防ぎます。

---

## 10.2 正規化層の実装（BatchNorm, LayerNorm）

正規化層は、深層ニューラルネットワークの学習を安定化させ、収束を高速化する重要な技術です。本節では、Batch Normalization と Layer Normalization の実装と GPU 最適化について解説します。

### 10.2.1 Batch Normalization（バッチ正規化）

Batch Normalization（BatchNorm）は、ミニバッチ内の統計量を使って、各レイヤーの入力を正規化します。

**数式定義（学習時）**：

1. ミニバッチの平均と分散を計算：
$$
\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i
$$
$$
\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2
$$

2. 正規化：
$$
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
$$

3. スケールとシフト（学習可能なパラメータ $\gamma, \beta$）：
$$
y_i = \gamma \hat{x}_i + \beta
$$

**数式定義（推論時）**：

推論時は、学習中に計算した移動平均（running mean, running variance）を使用します。

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

# 2D畳み込み用のBatchNorm
bn = nn.BatchNorm2d(num_features=64, eps=1e-5, momentum=0.1)

x = torch.randn(32, 64, 28, 28)  # (batch, channels, height, width)
y = bn(x)

# 手動実装（学習時）
def batch_norm_2d_forward(x, gamma, beta, eps=1e-5):
    # x: (N, C, H, W)
    N, C, H, W = x.shape
    
    # チャネルごとに統計量を計算
    mean = x.mean(dim=(0, 2, 3), keepdim=True)  # (1, C, 1, 1)
    var = x.var(dim=(0, 2, 3), keepdim=True, unbiased=False)
    
    # 正規化
    x_normalized = (x - mean) / torch.sqrt(var + eps)
    
    # スケールとシフト
    y = gamma.view(1, C, 1, 1) * x_normalized + beta.view(1, C, 1, 1)
    
    return y, mean, var
```

**Rust（ndarray）実装**：

```rust
use ndarray::{Array, Array1, Array4, Axis, Zip, s};

pub struct BatchNorm2d {
    num_features: usize,
    gamma: Array1<f32>,  // スケールパラメータ
    beta: Array1<f32>,   // シフトパラメータ
    running_mean: Array1<f32>,
    running_var: Array1<f32>,
    momentum: f32,
    eps: f32,
    training: bool,
}

impl BatchNorm2d {
    pub fn new(num_features: usize, eps: f32, momentum: f32) -> Self {
        Self {
            num_features,
            gamma: Array1::ones(num_features),
            beta: Array1::zeros(num_features),
            running_mean: Array1::zeros(num_features),
            running_var: Array1::ones(num_features),
            momentum,
            eps,
            training: true,
        }
    }

    pub fn forward(&mut self, x: &Array4<f32>) -> (Array4<f32>, Option<(Array1<f32>, Array1<f32>)>) {
        let (n, c, h, w) = x.dim();
        assert_eq!(c, self.num_features);

        if self.training {
            // 学習時: ミニバッチ統計量を計算
            let mut mean = Array1::zeros(c);
            let mut var = Array1::zeros(c);

            // チャネルごとに平均と分散を計算
            for ch in 0..c {
                let channel_data = x.slice(s![.., ch, .., ..]);
                let m = channel_data.mean().unwrap();
                let v = channel_data.var(0.0);
                mean[ch] = m;
                var[ch] = v;
            }

            // 移動平均を更新
            self.running_mean = (1.0 - self.momentum) * &self.running_mean + self.momentum * &mean;
            self.running_var = (1.0 - self.momentum) * &self.running_var + self.momentum * &var;

            // 正規化とスケール・シフト
            let mut y = Array4::zeros(x.dim());
            for ch in 0..c {
                let x_ch = x.slice(s![.., ch, .., ..]);
                let normalized = (&x_ch - mean[ch]) / (var[ch] + self.eps).sqrt();
                let scaled = normalized * self.gamma[ch] + self.beta[ch];
                y.slice_mut(s![.., ch, .., ..]).assign(&scaled);
            }

            (y, Some((mean, var)))
        } else {
            // 推論時: 移動平均を使用
            let mut y = Array4::zeros(x.dim());
            for ch in 0..c {
                let x_ch = x.slice(s![.., ch, .., ..]);
                let normalized = (&x_ch - self.running_mean[ch]) 
                    / (self.running_var[ch] + self.eps).sqrt();
                let scaled = normalized * self.gamma[ch] + self.beta[ch];
                y.slice_mut(s![.., ch, .., ..]).assign(&scaled);
            }

            (y, None)
        }
    }

    pub fn backward(
        &self,
        x: &Array4<f32>,
        grad_output: &Array4<f32>,
        mean: &Array1<f32>,
        var: &Array1<f32>,
    ) -> (Array4<f32>, Array1<f32>, Array1<f32>) {
        let (n, c, h, w) = x.dim();
        let nhw = (n * h * w) as f32;

        let mut grad_input = Array4::zeros(x.dim());
        let mut grad_gamma = Array1::zeros(c);
        let mut grad_beta = Array1::zeros(c);

        for ch in 0..c {
            let x_ch = x.slice(s![.., ch, .., ..]);
            let grad_out_ch = grad_output.slice(s![.., ch, .., ..]);

            // x_normalized を再計算
            let x_normalized = (&x_ch - mean[ch]) / (var[ch] + self.eps).sqrt();

            // grad_gamma, grad_beta
            grad_gamma[ch] = (&grad_out_ch * &x_normalized).sum();
            grad_beta[ch] = grad_out_ch.sum();

            // grad_x_normalized
            let grad_x_norm = &grad_out_ch * self.gamma[ch];

            // grad_var
            let grad_var = (&grad_x_norm * (&x_ch - mean[ch])).sum()
                * -0.5 * (var[ch] + self.eps).powf(-1.5);

            // grad_mean
            let grad_mean = grad_x_norm.sum() * (-1.0 / (var[ch] + self.eps).sqrt())
                + grad_var * (-2.0 * (&x_ch - mean[ch]).sum() / nhw);

            // grad_input
            let grad_in_ch = &grad_x_norm / (var[ch] + self.eps).sqrt()
                + grad_var * 2.0 * (&x_ch - mean[ch]) / nhw
                + grad_mean / nhw;

            grad_input.slice_mut(s![.., ch, .., ..]).assign(&grad_in_ch);
        }

        (grad_input, grad_gamma, grad_beta)
    }
}
```

**GPU 実装の最適化ポイント**：

1. **並列リダクション**: 平均と分散の計算は、GPU の並列リダクションを使うことで高速化できます。
2. **ワープ内同期**: 小さなチャネル数の場合、ワープ内のスレッド間で協調してリダクションを行うことで、shared memory の利用を最小化できます。
3. **カーネル融合**: BatchNorm と前後の演算（畳み込み、ReLU など）を融合することで、メモリアクセスを削減できます。

**cuDNN を使った実装（tch-rs）**：

```rust
use tch::{nn, Tensor, Device};

// tch-rs (PyTorch の Rust バインディング) を使用
let vs = nn::VarStore::new(Device::Cuda(0));
let bn = nn::batch_norm2d(&vs.root(), 64, Default::default());

let x = Tensor::randn(&[32, 64, 28, 28], (tch::Kind::Float, Device::Cuda(0)));
let y = bn.forward(&x);
```

### 10.2.2 Layer Normalization（レイヤー正規化）

Layer Normalization は、Transformer などのモデルで広く使われる正規化手法で、バッチ次元ではなく特徴量次元で正規化を行います。

**数式定義**：

1. 各サンプルの平均と分散を計算（特徴量次元全体）：
$$
\mu = \frac{1}{D} \sum_{i=1}^{D} x_i
$$
$$
\sigma^2 = \frac{1}{D} \sum_{i=1}^{D} (x_i - \mu)^2
$$

2. 正規化：
$$
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
$$

3. スケールとシフト：
$$
y_i = \gamma \hat{x}_i + \beta
$$

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

ln = nn.LayerNorm(normalized_shape=512, eps=1e-5)

x = torch.randn(32, 128, 512)  # (batch, seq_len, features)
y = ln(x)

# 手動実装
def layer_norm_forward(x, gamma, beta, eps=1e-5):
    # x: (N, ..., D)
    mean = x.mean(dim=-1, keepdim=True)
    var = x.var(dim=-1, keepdim=True, unbiased=False)
    
    x_normalized = (x - mean) / torch.sqrt(var + eps)
    y = gamma * x_normalized + beta
    
    return y, mean, var
```

**Rust 実装**：

```rust
use ndarray::{Array, ArrayD, Array1, Axis};

pub struct LayerNorm {
    normalized_shape: Vec<usize>,
    gamma: Array1<f32>,
    beta: Array1<f32>,
    eps: f32,
}

impl LayerNorm {
    pub fn new(normalized_shape: Vec<usize>, eps: f32) -> Self {
        let size = normalized_shape.iter().product();
        Self {
            normalized_shape,
            gamma: Array1::ones(size),
            beta: Array1::zeros(size),
            eps,
        }
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> (ArrayD<f32>, ArrayD<f32>, ArrayD<f32>) {
        // 最後の次元で正規化
        let last_axis = x.ndim() - 1;
        
        // 平均と分散を計算
        let mean = x.mean_axis(Axis(last_axis)).unwrap();
        let var = x.var_axis(Axis(last_axis), 0.0);
        
        // 正規化
        let mean_broadcast = mean.insert_axis(Axis(last_axis));
        let var_broadcast = var.insert_axis(Axis(last_axis));
        
        let x_normalized = (x - &mean_broadcast) / (var_broadcast + self.eps).mapv(|v| v.sqrt());
        
        // スケールとシフト
        let y = &x_normalized * &self.gamma.view() + &self.beta.view();
        
        (y, mean, var)
    }

    pub fn backward(
        &self,
        x: &ArrayD<f32>,
        grad_output: &ArrayD<f32>,
        mean: &ArrayD<f32>,
        var: &ArrayD<f32>,
    ) -> (ArrayD<f32>, Array1<f32>, Array1<f32>) {
        // 実装は BatchNorm と類似
        // 詳細は省略
        todo!("LayerNorm backward implementation")
    }
}
```

### 10.2.3 Group Normalization と Instance Normalization

**Group Normalization**：チャネルをグループに分け、グループごとに正規化します。バッチサイズが小さい場合に有効です。

**Instance Normalization**：各サンプル・各チャネルごとに正規化します。スタイル転送などで使われます。

これらの実装は BatchNorm や LayerNorm の変種として実装できます。

---

## 10.3 プーリング層の実装（MaxPool, AvgPool）

プーリング層は、特徴マップのダウンサンプリングを行い、計算量削減と不変性の獲得を目的とします。

### 10.3.1 Max Pooling（最大値プーリング）

Max Pooling は、各プーリングウィンドウ内の最大値を取る演算です。

**数式定義**：
$$
y_{n,c,h,w} = \max_{0 \leq i < k_h, 0 \leq j < k_w} x_{n,c,h \cdot s + i, w \cdot s + j}
$$

ここで、$k_h, k_w$ はカーネルサイズ、$s$ はストライドです。

**Python（PyTorch）実装**：

```python
import torch
import torch.nn as nn

maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

x = torch.randn(32, 64, 28, 28)
y = maxpool(x)  # (32, 64, 14, 14)

# 手動実装
def max_pool2d_forward(x, kernel_size, stride):
    N, C, H, W = x.shape
    kh, kw = kernel_size
    sh, sw = stride
    
    out_h = (H - kh) // sh + 1
    out_w = (W - kw) // sw + 1
    
    y = torch.zeros(N, C, out_h, out_w)
    
    for n in range(N):
        for c in range(C):
            for h in range(out_h):
                for w in range(out_w):
                    h_start = h * sh
                    w_start = w * sw
                    window = x[n, c, h_start:h_start+kh, w_start:w_start+kw]
                    y[n, c, h, w] = window.max()
    
    return y
```

**Rust 実装**：

```rust
use ndarray::{Array4, s};

pub fn max_pool2d(
    x: &Array4<f32>,
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> (Array4<f32>, Array4<usize>) {
    let (n, c, h, w) = x.dim();
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let out_h = (h - kh) / sh + 1;
    let out_w = (w - kw) / sw + 1;
    
    let mut y = Array4::zeros((n, c, out_h, out_w));
    let mut indices = Array4::zeros((n, c, out_h, out_w));
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..out_h {
                for wi in 0..out_w {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    
                    let window = x.slice(s![
                        ni..ni+1,
                        ci..ci+1,
                        h_start..h_start+kh,
                        w_start..w_start+kw
                    ]);
                    
                    let (max_val, max_idx) = window
                        .iter()
                        .enumerate()
                        .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
                        .unwrap();
                    
                    y[[ni, ci, hi, wi]] = *max_val;
                    indices[[ni, ci, hi, wi]] = max_idx;
                }
            }
        }
    }
    
    (y, indices)
}

pub fn max_pool2d_backward(
    grad_output: &Array4<f32>,
    indices: &Array4<usize>,
    input_shape: (usize, usize, usize, usize),
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> Array4<f32> {
    let (n, c, h, w) = input_shape;
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let mut grad_input = Array4::zeros((n, c, h, w));
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..grad_output.dim().2 {
                for wi in 0..grad_output.dim().3 {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    
                    let idx = indices[[ni, ci, hi, wi]];
                    let h_offset = idx / kw;
                    let w_offset = idx % kw;
                    
                    grad_input[[ni, ci, h_start + h_offset, w_start + w_offset]] 
                        += grad_output[[ni, ci, hi, wi]];
                }
            }
        }
    }
    
    grad_input
}
```

**GPU カーネル実装（CUDA）**：

```cuda
__global__ void max_pool2d_forward_kernel(
    const float* x,
    float* y,
    int* indices,
    int N, int C, int H, int W,
    int out_h, int out_w,
    int kh, int kw,
    int sh, int sw
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total = N * C * out_h * out_w;
    
    if (idx < total) {
        int wi = idx % out_w;
        int hi = (idx / out_w) % out_h;
        int ci = (idx / (out_w * out_h)) % C;
        int ni = idx / (out_w * out_h * C);
        
        int h_start = hi * sh;
        int w_start = wi * sw;
        
        float max_val = -INFINITY;
        int max_idx = 0;
        
        for (int i = 0; i < kh; i++) {
            for (int j = 0; j < kw; j++) {
                int h_pos = h_start + i;
                int w_pos = w_start + j;
                int x_idx = ((ni * C + ci) * H + h_pos) * W + w_pos;
                
                if (x[x_idx] > max_val) {
                    max_val = x[x_idx];
                    max_idx = i * kw + j;
                }
            }
        }
        
        y[idx] = max_val;
        indices[idx] = max_idx;
    }
}
```

### 10.3.2 Average Pooling（平均値プーリング）

Average Pooling は、各プーリングウィンドウ内の平均値を取る演算です。

**数式定義**：
$$
y_{n,c,h,w} = \frac{1}{k_h \cdot k_w} \sum_{i=0}^{k_h-1} \sum_{j=0}^{k_w-1} x_{n,c,h \cdot s + i, w \cdot s + j}
$$

**Python 実装**：

```python
import torch.nn as nn

avgpool = nn.AvgPool2d(kernel_size=2, stride=2)
x = torch.randn(32, 64, 28, 28)
y = avgpool(x)  # (32, 64, 14, 14)
```

**Rust 実装**：

```rust
use ndarray::{Array4, s};

pub fn avg_pool2d(
    x: &Array4<f32>,
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> Array4<f32> {
    let (n, c, h, w) = x.dim();
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let out_h = (h - kh) / sh + 1;
    let out_w = (w - kw) / sw + 1;
    
    let mut y = Array4::zeros((n, c, out_h, out_w));
    let scale = 1.0 / (kh * kw) as f32;
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..out_h {
                for wi in 0..out_w {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    
                    let window = x.slice(s![
                        ni..ni+1,
                        ci..ci+1,
                        h_start..h_start+kh,
                        w_start..w_start+kw
                    ]);
                    
                    y[[ni, ci, hi, wi]] = window.sum() * scale;
                }
            }
        }
    }
    
    y
}

pub fn avg_pool2d_backward(
    grad_output: &Array4<f32>,
    input_shape: (usize, usize, usize, usize),
    kernel_size: (usize, usize),
    stride: (usize, usize),
) -> Array4<f32> {
    let (n, c, h, w) = input_shape;
    let (kh, kw) = kernel_size;
    let (sh, sw) = stride;
    
    let mut grad_input = Array4::zeros((n, c, h, w));
    let scale = 1.0 / (kh * kw) as f32;
    
    for ni in 0..n {
        for ci in 0..c {
            for hi in 0..grad_output.dim().2 {
                for wi in 0..grad_output.dim().3 {
                    let h_start = hi * sh;
                    let w_start = wi * sw;
                    let grad = grad_output[[ni, ci, hi, wi]] * scale;
                    
                    for i in 0..kh {
                        for j in 0..kw {
                            grad_input[[ni, ci, h_start + i, w_start + j]] += grad;
                        }
                    }
                }
            }
        }
    }
    
    grad_input
}
```

### 10.3.3 Adaptive Pooling

Adaptive Pooling は、出力サイズを指定すると、自動的にカーネルサイズとストライドを調整してプーリングを行います。

```python
import torch.nn as nn

# 出力を1x1にする（Global Average Pooling）
adaptive_avgpool = nn.AdaptiveAvgPool2d((1, 1))
x = torch.randn(32, 512, 7, 7)
y = adaptive_avgpool(x)  # (32, 512, 1, 1)
```

---

## 10.4 ドロップアウトと正則化

ドロップアウトは、学習時にランダムにニューロンを無効化することで、過学習を防ぐ正則化手法です。

### 10.4.1 ドロップアウトの基本実装

**数式定義（学習時）**：
$$
y_i = \begin{cases}
\frac{x_i}{1 - p} & \text{with probability } 1 - p \\
0 & \text{with probability } p
\end{cases}
$$

**数式定義（推論時）**：
$$
y_i = x_i
$$

**Python 実装**：

```python
import torch
import torch.nn as nn

dropout = nn.Dropout(p=0.5)

# 学習時
x = torch.randn(32, 512)
y = dropout(x)

# 推論時
dropout.eval()
y = dropout(x)  # x と同じ

# 手動実装
def dropout_forward(x, p, training=True):
    if not training:
        return x
    
    mask = (torch.rand_like(x) > p).float()
    return x * mask / (1 - p)

def dropout_backward(grad_output, mask, p):
    return grad_output * mask / (1 - p)
```

**Rust 実装**：

```rust
use ndarray::{ArrayD, Array};
use rand::Rng;
use rand::distributions::{Distribution, Uniform};

pub struct Dropout {
    p: f32,
    training: bool,
}

impl Dropout {
    pub fn new(p: f32) -> Self {
        assert!(p >= 0.0 && p < 1.0, "Dropout probability must be in [0, 1)");
        Self { p, training: true }
    }

    pub fn train(&mut self) {
        self.training = true;
    }

    pub fn eval(&mut self) {
        self.training = false;
    }

    pub fn forward(&self, x: &ArrayD<f32>) -> (ArrayD<f32>, ArrayD<f32>) {
        if !self.training {
            return (x.clone(), Array::ones(x.raw_dim()));
        }

        let mut rng = rand::thread_rng();
        let dist = Uniform::new(0.0, 1.0);
        
        let mask = x.mapv(|_| {
            if dist.sample(&mut rng) > self.p {
                1.0 / (1.0 - self.p)
            } else {
                0.0
            }
        });

        let y = x * &mask;
        (y, mask)
    }

    pub fn backward(&self, grad_output: &ArrayD<f32>, mask: &ArrayD<f32>) -> ArrayD<f32> {
        if !self.training {
            return grad_output.clone();
        }

        grad_output * mask
    }
}
```

**GPU カーネル実装（CUDA）**：

```cuda
#include <curand_kernel.h>

__global__ void dropout_forward_kernel(
    const float* x,
    float* y,
    unsigned char* mask,
    float p,
    int n,
    unsigned long long seed
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        curandState state;
        curand_init(seed, idx, 0, &state);
        
        float rand_val = curand_uniform(&state);
        float scale = 1.0f / (1.0f - p);
        
        if (rand_val > p) {
            y[idx] = x[idx] * scale;
            mask[idx] = 1;
        } else {
            y[idx] = 0.0f;
            mask[idx] = 0;
        }
    }
}

__global__ void dropout_backward_kernel(
    const float* grad_output,
    const unsigned char* mask,
    float* grad_input,
    float p,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < n) {
        float scale = 1.0f / (1.0f - p);
        grad_input[idx] = grad_output[idx] * mask[idx] * scale;
    }
}
```

### 10.4.2 DropConnect と DropBlock

**DropConnect**: ドロップアウトがニューロンを無効化するのに対し、DropConnect は重み接続をランダムに無効化します。

**DropBlock**: 画像認識において、空間的に連続したブロックをドロップアウトすることで、より効果的な正則化を実現します。

```python
import torch
import torch.nn as nn

# DropBlock (torchvision.ops にある)
from torchvision.ops import DropBlock2d

dropblock = DropBlock2d(p=0.1, block_size=7)
x = torch.randn(32, 64, 56, 56)
y = dropblock(x)
```

### 10.4.3 パフォーマンス比較

| 正則化手法 | 計算コスト | メモリコスト | 主な用途 |
|-----------|----------|------------|---------|
| **Dropout** | 低（乱数生成のみ） | マスク保存 | 全結合層 |
| **DropConnect** | 中（重み単位） | マスク保存 | 全結合層 |
| **DropBlock** | 中（ブロック単位） | マスク保存 | CNN |
| **BatchNorm** | 高（統計量計算） | 平均・分散保存 | CNN, MLP |
| **LayerNorm** | 高（統計量計算） | 平均・分散保存 | Transformer |

---

## 10.5 まとめ

本章では、ニューラルネットワークの基本的なレイヤー（活性化関数、正規化層、プーリング層、ドロップアウト）を、Python と Rust の両方で実装しました。

**主要なポイント**：

1. **活性化関数**: ReLU、Sigmoid、Tanh、GELU、Swish などの実装と、数値安定性の考慮
2. **正規化層**: BatchNorm と LayerNorm の実装、学習時と推論時の違い
3. **プーリング層**: MaxPool と AvgPool の実装、勾配計算における注意点
4. **ドロップアウト**: 学習時のランダム無効化と推論時のスケーリング

**Rust での実装の利点**：

- **型安全性**: コンパイル時に次元の不一致などのバグを検出
- **メモリ安全性**: 所有権システムによるメモリリークの防止
- **パフォーマンス**: ゼロコスト抽象化による高速な実行

**次章への接続**：

次の第 11 章では、損失関数とメトリクスの実装について詳しく解説し、学習の目的関数とモデル評価の手法を学びます。

---

## 参考文献

- Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ICML.
- Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016). Layer Normalization. arXiv:1607.06450.
- Hendrycks, D., & Gimpel, K. (2016). Gaussian Error Linear Units (GELUs). arXiv:1606.08415.
- Ramachandran, P., Zoph, B., & Le, Q. V. (2017). Searching for Activation Functions. arXiv:1710.05941.
- Srivastava, N., et al. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. JMLR.

